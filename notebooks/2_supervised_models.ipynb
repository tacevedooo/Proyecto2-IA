{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4340e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librer√≠as necesarias\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "# diccionario para guardar todas las m√©tricas\n",
    "metricas = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86804070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Height_m</th>\n",
       "      <th>Max_BPM</th>\n",
       "      <th>Avg_BPM</th>\n",
       "      <th>Resting_BPM</th>\n",
       "      <th>Session_Duration_hours</th>\n",
       "      <th>Calories_Burned</th>\n",
       "      <th>Workout_Type</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.14</td>\n",
       "      <td>101.05</td>\n",
       "      <td>1.95</td>\n",
       "      <td>171.17</td>\n",
       "      <td>130.81</td>\n",
       "      <td>68.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>959.43</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.17</td>\n",
       "      <td>41.63</td>\n",
       "      <td>1.78</td>\n",
       "      <td>167.33</td>\n",
       "      <td>158.46</td>\n",
       "      <td>63.95</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1424.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.07</td>\n",
       "      <td>63.81</td>\n",
       "      <td>1.78</td>\n",
       "      <td>187.86</td>\n",
       "      <td>137.11</td>\n",
       "      <td>60.93</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1766.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.30</td>\n",
       "      <td>59.77</td>\n",
       "      <td>1.78</td>\n",
       "      <td>183.83</td>\n",
       "      <td>120.32</td>\n",
       "      <td>60.01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1028.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.99</td>\n",
       "      <td>57.60</td>\n",
       "      <td>1.56</td>\n",
       "      <td>166.25</td>\n",
       "      <td>151.82</td>\n",
       "      <td>67.97</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1295.80</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Weight_kg  Height_m  Max_BPM  Avg_BPM  Resting_BPM  \\\n",
       "0  21.14     101.05      1.95   171.17   130.81        68.96   \n",
       "1  44.17      41.63      1.78   167.33   158.46        63.95   \n",
       "2  20.07      63.81      1.78   187.86   137.11        60.93   \n",
       "3  36.30      59.77      1.78   183.83   120.32        60.01   \n",
       "4  51.99      57.60      1.56   166.25   151.82        67.97   \n",
       "\n",
       "   Session_Duration_hours  Calories_Burned  Workout_Type  Gender_Female  \\\n",
       "0                    0.97           959.43             2            0.0   \n",
       "1                    1.48          1424.35             0            0.0   \n",
       "2                    1.70          1766.64             0            1.0   \n",
       "3                    0.85          1028.50             1            1.0   \n",
       "4                    1.66          1295.80             3            0.0   \n",
       "\n",
       "   Gender_Male  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. Carga del Conjunto de Datos ---\n",
    "data = pd.read_csv(\"../data/subset/clean_subset_lifestyledata_rows5200_seed5200.csv\")\n",
    "\n",
    "# --- 2. Codificaci√≥n de Etiquetas (Label Encoding) ---\n",
    "label_encoder = LabelEncoder()\n",
    "# Se transforma la variable objetivo 'Workout_Type' a valores num√©ricos.\n",
    "data['Workout_Type'] = label_encoder.fit_transform(data['Workout_Type'])\n",
    "\n",
    "# --- 3. Codificaci√≥n One-Hot (One-Hot Encoding) ---\n",
    "# Se define la lista de columnas categ√≥ricas nominales a transformar.\n",
    "nominal_cols = ['Gender']\n",
    "# sparse_output=False: Devuelve una matriz densa (array de NumPy) en lugar de una dispersa.\n",
    "# handle_unknown='ignore': Si aparece una categor√≠a no vista durante la transformaci√≥n, la ignora.\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# Esto crea nuevas columnas binarias para cada categor√≠a.\n",
    "encoded = ohe.fit_transform(data[nominal_cols])\n",
    "# Se convierte la matriz resultante en un DataFrame con nombres de columna apropiados.\n",
    "encoded_df = pd.DataFrame(encoded, columns=ohe.get_feature_names_out(nominal_cols))\n",
    "\n",
    "# --- 4. Combinaci√≥n de los Datos Procesados ---\n",
    "# Se elimina la columna original 'Gender' del DataFrame principal.\n",
    "# reset_index(drop=True) asegura que los √≠ndices se alineen correctamente para la concatenaci√≥n.\n",
    "data = data.drop(columns=nominal_cols).reset_index(drop=True)\n",
    "encoded_df = encoded_df.reset_index(drop=True)\n",
    "\n",
    "# Se concatenan el DataFrame original y el nuevo DataFrame con las columnas codificadas.\n",
    "# axis=1 indica que la uni√≥n se realiza por columnas.\n",
    "data = pd.concat([data, encoded_df], axis=1)\n",
    "\n",
    "# --- 5. Visualizaci√≥n ---\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3d8ea8",
   "metadata": {},
   "source": [
    "# √Årbol de Decisiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b928020a",
   "metadata": {},
   "source": [
    "#### 1. √Årbol de Decisiones - CC:SI - ED:NO - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b46c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== üß† CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini\n",
      "Accuracy: 0.7327, Precision: 0.7412, Recall: 0.7327, F1-Score: 0.7350\n",
      "\n",
      "Modelo: Entrop√≠a\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "Modelo: Entrop√≠a Podado\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini\n",
      "Accuracy: 0.7452, Precision: 0.7431, Recall: 0.7452, F1-Score: 0.7438\n",
      "\n",
      "Modelo: Entrop√≠a\n",
      "Accuracy: 0.7875, Precision: 0.7968, Recall: 0.7875, F1-Score: 0.7892\n",
      "\n",
      "Modelo: Entrop√≠a Podado\n",
      "Accuracy: 0.7875, Precision: 0.7968, Recall: 0.7875, F1-Score: 0.7892\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini\n",
      "Accuracy: 0.7587, Precision: 0.7538, Recall: 0.7587, F1-Score: 0.7559\n",
      "\n",
      "Modelo: Entrop√≠a\n",
      "Accuracy: 0.7837, Precision: 0.8018, Recall: 0.7837, F1-Score: 0.7823\n",
      "\n",
      "Modelo: Entrop√≠a Podado\n",
      "Accuracy: 0.7837, Precision: 0.8018, Recall: 0.7837, F1-Score: 0.7823\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Datos base\n",
    "# ================================================================\n",
    "data_tree_1 = data.copy()\n",
    "X = data_tree_1.drop(\"Workout_Type\", axis=1)\n",
    "y = data_tree_1[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  # tres seeds diferentes\n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== üß† CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # Dividir datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Modelo 1: √Årbol con Gini ---\n",
    "    modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=seed)\n",
    "    modelo_gini.fit(X_train, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "    # --- Modelo 2: √Årbol con Entrop√≠a ---\n",
    "    modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "    modelo_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "    # --- Modelo 3: Entrop√≠a con poda ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=seed)\n",
    "    modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "    # --- Calcular m√©tricas ---\n",
    "    modelos = {\n",
    "        \"Gini\": y_pred_gini,\n",
    "        \"Entrop√≠a\": y_pred_entropy,\n",
    "        \"Entrop√≠a Podado\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        \n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66526514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gr√°ficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fbf08",
   "metadata": {},
   "source": [
    "#### 2. √Årbol de Decisiones - CC:SI - ED:NO - Outliers:NO - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c9b6a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== üß† CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Balanced\n",
      "Accuracy: 0.7327, Precision: 0.7412, Recall: 0.7327, F1-Score: 0.7350\n",
      "\n",
      "Modelo: Entrop√≠a_Balanced\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Balanced\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Balanced\n",
      "Accuracy: 0.7375, Precision: 0.7338, Recall: 0.7375, F1-Score: 0.7348\n",
      "\n",
      "Modelo: Entrop√≠a_Balanced\n",
      "Accuracy: 0.7740, Precision: 0.7726, Recall: 0.7740, F1-Score: 0.7720\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Balanced\n",
      "Accuracy: 0.7740, Precision: 0.7726, Recall: 0.7740, F1-Score: 0.7720\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Balanced\n",
      "Accuracy: 0.7365, Precision: 0.7361, Recall: 0.7365, F1-Score: 0.7243\n",
      "\n",
      "Modelo: Entrop√≠a_Balanced\n",
      "Accuracy: 0.7846, Precision: 0.8026, Recall: 0.7846, F1-Score: 0.7833\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Balanced\n",
      "Accuracy: 0.7846, Precision: 0.8026, Recall: 0.7846, F1-Score: 0.7833\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Datos base\n",
    "# ================================================================\n",
    "data_tree_2 = data.copy()\n",
    "X = data_tree_2.drop(\"Workout_Type\", axis=1)\n",
    "y = data_tree_2[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras con class_weight='balanced'\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  # Tres seeds diferentes\n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== üß† CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # Dividir datos (80/20 estratificado)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Modelo 1: √Årbol con Gini (class_weight='balanced') ---\n",
    "    modelo_gini = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_gini.fit(X_train, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "    # --- Modelo 2: √Årbol con Entrop√≠a (class_weight='balanced') ---\n",
    "    modelo_entropy = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "    # --- Modelo 3: Entrop√≠a con poda (class_weight='balanced') ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=5, # Poda\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "    # --- Calcular m√©tricas ---\n",
    "    modelos = {\n",
    "        \"Gini_Balanced\": y_pred_gini,\n",
    "        \"Entrop√≠a_Balanced\": y_pred_entropy,\n",
    "        \"Entrop√≠a_Podado_Balanced\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular m√©tricas, usando zero_division=0 para un manejo robusto\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1df9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gr√°ficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e13b9",
   "metadata": {},
   "source": [
    "#### 3. √Årbol de Decisiones - CC:SI - ED:NO - Outliers:SI - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6028ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (5200, 11)\n",
      "Tama√±o sin outliers: (5055, 11)\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Clean\n",
      "Accuracy: 0.7399, Precision: 0.7479, Recall: 0.7399, F1-Score: 0.7403\n",
      "\n",
      "Modelo: Entrop√≠a_Clean\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Clean\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Clean\n",
      "Accuracy: 0.7933, Precision: 0.8097, Recall: 0.7933, F1-Score: 0.7919\n",
      "\n",
      "Modelo: Entrop√≠a_Clean\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Clean\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Clean\n",
      "Accuracy: 0.7923, Precision: 0.7979, Recall: 0.7923, F1-Score: 0.7928\n",
      "\n",
      "Modelo: Entrop√≠a_Clean\n",
      "Accuracy: 0.8200, Precision: 0.8163, Recall: 0.8200, F1-Score: 0.8177\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Clean\n",
      "Accuracy: 0.8180, Precision: 0.8149, Recall: 0.8180, F1-Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Datos base\n",
    "# ================================================================\n",
    "data_tree_3 = data.copy()\n",
    "\n",
    "# seleccionar solo las columnas num√©ricas\n",
    "num_cols = data_tree_3.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# calcular Q1, Q3 y el rango intercuart√≠lico (IQR)\n",
    "Q1 = data_tree_3[num_cols].quantile(0.25)\n",
    "Q3 = data_tree_3[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# crear una m√°scara booleana que identifique las filas SIN outliers\n",
    "mask = ~((data_tree_3[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_tree_3[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# filtrar los datos limpios\n",
    "data_clean = data_tree_3[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tama√±o original:\", data_tree_3.shape)\n",
    "print(\"Tama√±o sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Separar X e y con datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== üß† CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Modelo 1: √Årbol con Gini ---\n",
    "    modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=seed)\n",
    "    modelo_gini.fit(X_train, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "    # --- Modelo 2: √Årbol con Entrop√≠a ---\n",
    "    modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "    modelo_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "    # --- Modelo 3: Entrop√≠a con poda ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=seed)\n",
    "    modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "    # --- Calcular m√©tricas ---\n",
    "    modelos = {\n",
    "        \"Gini_Clean\": y_pred_gini,\n",
    "        \"Entrop√≠a_Clean\": y_pred_entropy,\n",
    "        \"Entrop√≠a_Podado_Clean\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular m√©tricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513b99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gr√°ficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fd4e1",
   "metadata": {},
   "source": [
    "#### 4. √Årbol de Decisiones - CC:SI - ED:NO - Outliers:SI - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4a2c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (5200, 11)\n",
      "Tama√±o sin outliers: (5055, 11)\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Balanced\n",
      "Accuracy: 0.7745, Precision: 0.7935, Recall: 0.7745, F1-Score: 0.7710\n",
      "\n",
      "Modelo: Entrop√≠a_Clean_Balanced\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Clean_Balanced\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Balanced\n",
      "Accuracy: 0.7933, Precision: 0.8097, Recall: 0.7933, F1-Score: 0.7919\n",
      "\n",
      "Modelo: Entrop√≠a_Clean_Balanced\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Clean_Balanced\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Balanced\n",
      "Accuracy: 0.7943, Precision: 0.7994, Recall: 0.7943, F1-Score: 0.7946\n",
      "\n",
      "Modelo: Entrop√≠a_Clean_Balanced\n",
      "Accuracy: 0.8190, Precision: 0.8156, Recall: 0.8190, F1-Score: 0.8168\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Clean_Balanced\n",
      "Accuracy: 0.8180, Precision: 0.8149, Recall: 0.8180, F1-Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Datos base\n",
    "# ================================================================\n",
    "data_tree_4 = data.copy()\n",
    "\n",
    "# seleccionar solo las columnas num√©ricas\n",
    "num_cols = data_tree_4.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# calcular Q1, Q3 y el rango intercuart√≠lico (IQR)\n",
    "Q1 = data_tree_4[num_cols].quantile(0.25)\n",
    "Q3 = data_tree_4[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# crear una m√°scara booleana que identifique las filas SIN outliers\n",
    "mask = ~((data_tree_4[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_tree_4[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# filtrar los datos limpios\n",
    "data_clean = data_tree_4[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tama√±o original:\", data_tree_4.shape)\n",
    "print(\"Tama√±o sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Separar X e y con datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  #\n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== üß† CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Modelo 1: √Årbol con Gini + Balanced ---\n",
    "    modelo_gini = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_gini.fit(X_train, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "    # --- Modelo 2: √Årbol con Entrop√≠a + Balanced ---\n",
    "    modelo_entropy = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    modelo_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "    # --- Modelo 3: Entrop√≠a con poda + Balanced ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=5, # Poda\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "    # --- Calcular m√©tricas ---\n",
    "    modelos = {\n",
    "        \"Gini_Clean_Balanced\": y_pred_gini,\n",
    "        \"Entrop√≠a_Clean_Balanced\": y_pred_entropy,\n",
    "        \"Entrop√≠a_Podado_Clean_Balanced\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular m√©tricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c517ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gr√°ficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb43b18",
   "metadata": {},
   "source": [
    "#### 5. √Årbol de Decisiones - CC:SI - ED:SI - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d316eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== üß† CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Scaled\n",
      "Accuracy: 0.7327, Precision: 0.7412, Recall: 0.7327, F1-Score: 0.7350\n",
      "\n",
      "Modelo: Entrop√≠a_Scaled\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Scaled\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Scaled\n",
      "Accuracy: 0.7452, Precision: 0.7431, Recall: 0.7452, F1-Score: 0.7438\n",
      "\n",
      "Modelo: Entrop√≠a_Scaled\n",
      "Accuracy: 0.7875, Precision: 0.7968, Recall: 0.7875, F1-Score: 0.7892\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Scaled\n",
      "Accuracy: 0.7875, Precision: 0.7968, Recall: 0.7875, F1-Score: 0.7892\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Scaled\n",
      "Accuracy: 0.7587, Precision: 0.7538, Recall: 0.7587, F1-Score: 0.7559\n",
      "\n",
      "Modelo: Entrop√≠a_Scaled\n",
      "Accuracy: 0.7837, Precision: 0.8018, Recall: 0.7837, F1-Score: 0.7823\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Scaled\n",
      "Accuracy: 0.7837, Precision: 0.8018, Recall: 0.7837, F1-Score: 0.7823\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Datos base\n",
    "# ================================================================\n",
    "data_tree_5 = data.copy()\n",
    "\n",
    "# Se definen las caracter√≠sticas (X) y la variable objetivo (y)\n",
    "X = data_tree_5.drop(\"Workout_Type\", axis=1)\n",
    "y = data_tree_5[\"Workout_Type\"]\n",
    "\n",
    "# Definir el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== üß† CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # 1. Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 2. Preprocesamiento: Escalado solo de columnas num√©ricas (excluyendo 'Gender')\n",
    "    numeric_cols = [col for col in X_train.columns if col not in ['Gender']] \n",
    "\n",
    "    # Hacer copias para el escalado\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    # Escalar\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    # 3. Entrenamiento y Predicci√≥n de Modelos\n",
    "    \n",
    "    # --- Modelo 1: √Årbol con Gini ---\n",
    "    modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=seed)\n",
    "    modelo_gini.fit(X_train_scaled, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 2: √Årbol con Entrop√≠a ---\n",
    "    modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "    modelo_entropy.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 3: Entrop√≠a con poda ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=seed)\n",
    "    modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # 4. Calcular m√©tricas\n",
    "    modelos = {\n",
    "        \"Gini_Scaled\": y_pred_gini,\n",
    "        \"Entrop√≠a_Scaled\": y_pred_entropy,\n",
    "        \"Entrop√≠a_Podado_Scaled\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular m√©tricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3e83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gr√°ficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6489eb76",
   "metadata": {},
   "source": [
    "#### 6. √Årbol de Decisiones - CC:SI - ED:SI - Outliers:NO - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c9b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== üß† CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Scaled_Balanced\n",
      "Accuracy: 0.7327, Precision: 0.7412, Recall: 0.7327, F1-Score: 0.7350\n",
      "\n",
      "Modelo: Entrop√≠a_Scaled_Balanced\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Scaled_Balanced\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Scaled_Balanced\n",
      "Accuracy: 0.7375, Precision: 0.7338, Recall: 0.7375, F1-Score: 0.7348\n",
      "\n",
      "Modelo: Entrop√≠a_Scaled_Balanced\n",
      "Accuracy: 0.7740, Precision: 0.7726, Recall: 0.7740, F1-Score: 0.7720\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Scaled_Balanced\n",
      "Accuracy: 0.7740, Precision: 0.7726, Recall: 0.7740, F1-Score: 0.7720\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Scaled_Balanced\n",
      "Accuracy: 0.7365, Precision: 0.7361, Recall: 0.7365, F1-Score: 0.7243\n",
      "\n",
      "Modelo: Entrop√≠a_Scaled_Balanced\n",
      "Accuracy: 0.7846, Precision: 0.8026, Recall: 0.7846, F1-Score: 0.7833\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Scaled_Balanced\n",
      "Accuracy: 0.7846, Precision: 0.8026, Recall: 0.7846, F1-Score: 0.7833\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Datos base\n",
    "# ================================================================\n",
    "data_tree_6 = data.copy()\n",
    "\n",
    "# Se definen las caracter√≠sticas (X) y la variable objetivo (y)\n",
    "X = data_tree_6.drop(\"Workout_Type\", axis=1)\n",
    "y = data_tree_6[\"Workout_Type\"]\n",
    "\n",
    "# Definir el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== üß† CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # 1. Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 2. Preprocesamiento: Escalado solo de columnas num√©ricas\n",
    "    numeric_cols = [col for col in X_train.columns if col not in ['Gender']] # Se asume 'Gender' es la √∫nica no num√©rica relevante aqu√≠\n",
    "\n",
    "    # Hacer copias para el escalado\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    # Escalar\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    # 3. Entrenamiento y Predicci√≥n de Modelos (con class_weight='balanced')\n",
    "\n",
    "    # --- Modelo 1: √Årbol con Gini + Balanced ---\n",
    "    modelo_gini = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_gini.fit(X_train_scaled, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 2: √Årbol con Entrop√≠a + Balanced ---\n",
    "    modelo_entropy = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 3: Entrop√≠a con poda + Balanced ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=5, # Poda\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # 4. Calcular m√©tricas\n",
    "    modelos = {\n",
    "        \"Gini_Scaled_Balanced\": y_pred_gini,\n",
    "        \"Entrop√≠a_Scaled_Balanced\": y_pred_entropy,\n",
    "        \"Entrop√≠a_Podado_Scaled_Balanced\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular m√©tricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d16c0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gr√°ficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23e255",
   "metadata": {},
   "source": [
    "#### 7. √Årbol de Decisiones - CC:SI - ED:SI - Outliers:SI - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f175ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (5200, 11)\n",
      "Tama√±o sin outliers: (5055, 11)\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled\n",
      "Accuracy: 0.7399, Precision: 0.7479, Recall: 0.7399, F1-Score: 0.7403\n",
      "\n",
      "Modelo: Entrop√≠a_Clean_Scaled\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Clean_Scaled\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled\n",
      "Accuracy: 0.7933, Precision: 0.8097, Recall: 0.7933, F1-Score: 0.7919\n",
      "\n",
      "Modelo: Entrop√≠a_Clean_Scaled\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Clean_Scaled\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled\n",
      "Accuracy: 0.7923, Precision: 0.7979, Recall: 0.7923, F1-Score: 0.7928\n",
      "\n",
      "Modelo: Entrop√≠a_Clean_Scaled\n",
      "Accuracy: 0.8200, Precision: 0.8163, Recall: 0.8200, F1-Score: 0.8177\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Clean_Scaled\n",
      "Accuracy: 0.8180, Precision: 0.8149, Recall: 0.8180, F1-Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Datos base\n",
    "# ================================================================\n",
    "data_tree_7 = data.copy()\n",
    "\n",
    "# seleccionar solo las columnas num√©ricas\n",
    "num_cols = data_tree_7.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# calcular Q1, Q3 y el rango intercuart√≠lico (IQR)\n",
    "Q1 = data_tree_7[num_cols].quantile(0.25)\n",
    "Q3 = data_tree_7[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# crear una m√°scara booleana que identifique las filas SIN outliers\n",
    "mask = ~((data_tree_7[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_tree_7[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# filtrar los datos limpios\n",
    "data_clean = data_tree_7[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tama√±o original:\", data_tree_7.shape)\n",
    "print(\"Tama√±o sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Separar X e y con datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# Definir el escalador\n",
    "scaler = StandardScaler()\n",
    "# Definir columnas a escalar (asumiendo 'Gender' es la √∫nica no num√©rica en X)\n",
    "numeric_cols = [col for col in X.columns if col not in ['Gender']]\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  # Tres seeds diferentes\n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== üß† CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # 1. Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 2. Preprocesamiento: Escalado\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    # Ajustar y transformar solo las columnas num√©ricas\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "\n",
    "    # 3. Entrenamiento y Predicci√≥n de Modelos\n",
    "\n",
    "    # --- Modelo 1: √Årbol con Gini ---\n",
    "    modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=seed)\n",
    "    modelo_gini.fit(X_train_scaled, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 2: √Årbol con Entrop√≠a ---\n",
    "    modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "    modelo_entropy.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 3: Entrop√≠a con poda ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=seed)\n",
    "    modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # 4. Calcular m√©tricas\n",
    "    modelos = {\n",
    "        \"Gini_Clean_Scaled\": y_pred_gini,\n",
    "        \"Entrop√≠a_Clean_Scaled\": y_pred_entropy,\n",
    "        \"Entrop√≠a_Podado_Clean_Scaled\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular m√©tricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52a3bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gr√°ficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc5a64",
   "metadata": {},
   "source": [
    "#### 8. √Årbol de Decisiones - CC:SI - ED:SI - Outliers:SI - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e235d4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (5200, 11)\n",
      "Tama√±o sin outliers: (5055, 11)\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7745, Precision: 0.7935, Recall: 0.7745, F1-Score: 0.7710\n",
      "\n",
      "Modelo: Entrop√≠a_Clean_Scaled_Balanced\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Clean_Scaled_Balanced\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7933, Precision: 0.8097, Recall: 0.7933, F1-Score: 0.7919\n",
      "\n",
      "Modelo: Entrop√≠a_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "=========== üß† CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7943, Precision: 0.7994, Recall: 0.7943, F1-Score: 0.7946\n",
      "\n",
      "Modelo: Entrop√≠a_Clean_Scaled_Balanced\n",
      "Accuracy: 0.8190, Precision: 0.8156, Recall: 0.8190, F1-Score: 0.8168\n",
      "\n",
      "Modelo: Entrop√≠a_Podado_Clean_Scaled_Balanced\n",
      "Accuracy: 0.8180, Precision: 0.8149, Recall: 0.8180, F1-Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Datos base\n",
    "# ================================================================\n",
    "data_tree_8 = data.copy()\n",
    "\n",
    "# 1. Eliminar outliers (IQR)\n",
    "num_cols = data_tree_8.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_tree_8[num_cols].quantile(0.25)\n",
    "Q3 = data_tree_8[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "mask = ~((data_tree_8[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_tree_8[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "data_clean = data_tree_8[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tama√±o original:\", data_tree_8.shape)\n",
    "print(\"Tama√±o sin outliers:\", data_clean.shape)\n",
    "\n",
    "# 2. Separar X e y\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# Definir el escalador y las columnas num√©ricas (excluyendo 'Gender')\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = [col for col in X.columns if col not in ['Gender']]\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== üß† CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # 1. Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 2. Aplicar Escalado (fit/transform en train, transform en test)\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "\n",
    "    # 3. Entrenamiento y Predicci√≥n de Modelos (con class_weight='balanced')\n",
    "\n",
    "    # --- Modelo 1: Gini + Balanced ---\n",
    "    modelo_gini = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    modelo_gini.fit(X_train_scaled, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 2: Entrop√≠a + Balanced ---\n",
    "    modelo_entropy = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    modelo_entropy.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 3: Entrop√≠a con poda + Balanced ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=5, # Poda\n",
    "        random_state=seed,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # 4. Calcular m√©tricas\n",
    "    modelos = {\n",
    "        \"Gini_Clean_Scaled_Balanced\": y_pred_gini,\n",
    "        \"Entrop√≠a_Clean_Scaled_Balanced\": y_pred_entropy,\n",
    "        \"Entrop√≠a_Podado_Clean_Scaled_Balanced\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular m√©tricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ae62506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gr√°ficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a77f2",
   "metadata": {},
   "source": [
    "# K Vecinos M√°s Cercanos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec0da7f",
   "metadata": {},
   "source": [
    "#### 1. KNN - CC:SI - ED:NO - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8748d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.7365\n",
      "üîπ Mejor K (Manhattan): 1 | Max Acc: 0.7913\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1):\n",
      "Accuracy: 0.7365, Precision: 0.7362, Recall: 0.7365, F1-Score: 0.7362\n",
      "-> Evaluaci√≥n Manhattan (k=1):\n",
      "Accuracy: 0.7913, Precision: 0.7919, Recall: 0.7913, F1-Score: 0.7916\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.7423\n",
      "üîπ Mejor K (Manhattan): 1 | Max Acc: 0.7981\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1):\n",
      "Accuracy: 0.7423, Precision: 0.7452, Recall: 0.7423, F1-Score: 0.7429\n",
      "-> Evaluaci√≥n Manhattan (k=1):\n",
      "Accuracy: 0.7981, Precision: 0.8021, Recall: 0.7981, F1-Score: 0.7988\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.7596\n",
      "üîπ Mejor K (Manhattan): 1 | Max Acc: 0.8115\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1):\n",
      "Accuracy: 0.7596, Precision: 0.7602, Recall: 0.7596, F1-Score: 0.7596\n",
      "-> Evaluaci√≥n Manhattan (k=1):\n",
      "Accuracy: 0.8115, Precision: 0.8125, Recall: 0.8115, F1-Score: 0.8116\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Preparaci√≥n de los datos\n",
    "# ================================================================\n",
    "data_knn_1 = data.copy()\n",
    "\n",
    "X = data_knn_1.drop(\"Workout_Type\", axis=1)\n",
    "y = data_knn_1[\"Workout_Type\"]\n",
    "\n",
    "# Definici√≥n de la funci√≥n de evaluaci√≥n\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'M√©trica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"üß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # üîé B√∫squeda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"üîπ Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"üîπ Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # üß† Evaluaci√≥n final con los K √≥ptimos\n",
    "    print(\"\\n--- Evaluaci√≥n Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluaci√≥n Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluaci√≥n Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "795a5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d2508",
   "metadata": {},
   "source": [
    "#### 2. KNN - CC:SI - ED:NO - Outliers:NO - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "007f3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 1 (random_state=111) - Balanced\n",
      "=================================================\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.7365\n",
      "üîπ Mejor K (Manhattan): 1 | Max Acc: 0.7913\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1, weights='distance'):\n",
      "Accuracy: 0.7365, Precision: 0.7362, Recall: 0.7365, F1-Score: 0.7362\n",
      "-> Evaluaci√≥n Manhattan (k=1, weights='distance'):\n",
      "Accuracy: 0.7913, Precision: 0.7919, Recall: 0.7913, F1-Score: 0.7916\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 2 (random_state=222) - Balanced\n",
      "=================================================\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.7423\n",
      "üîπ Mejor K (Manhattan): 1 | Max Acc: 0.7981\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1, weights='distance'):\n",
      "Accuracy: 0.7423, Precision: 0.7452, Recall: 0.7423, F1-Score: 0.7429\n",
      "-> Evaluaci√≥n Manhattan (k=1, weights='distance'):\n",
      "Accuracy: 0.7981, Precision: 0.8021, Recall: 0.7981, F1-Score: 0.7988\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 3 (random_state=333) - Balanced\n",
      "=================================================\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.7596\n",
      "üîπ Mejor K (Manhattan): 1 | Max Acc: 0.8115\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1, weights='distance'):\n",
      "Accuracy: 0.7596, Precision: 0.7602, Recall: 0.7596, F1-Score: 0.7596\n",
      "-> Evaluaci√≥n Manhattan (k=1, weights='distance'):\n",
      "Accuracy: 0.8115, Precision: 0.8125, Recall: 0.8115, F1-Score: 0.8116\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Preparaci√≥n de los datos\n",
    "# ================================================================\n",
    "data_knn_2 = data.copy()\n",
    "\n",
    "X = data_knn_2.drop(\"Workout_Type\", axis=1)\n",
    "y = data_knn_2[\"Workout_Type\"]\n",
    "\n",
    "# Definici√≥n de la funci√≥n de evaluaci√≥n\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo KNN usando weights='distance'.\"\"\"\n",
    "    # weights='distance' prioriza los vecinos m√°s cercanos, actuando como un balanceo ponderado.\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'M√©trica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Weights': 'distance',\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"üß† CASO DE PRUEBA {i} (random_state={seed}) - Balanced\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # üîé B√∫squeda de mejores K para el split actual (usando weights='distance')\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"üîπ Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"üîπ Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # üß† Evaluaci√≥n final con los K √≥ptimos\n",
    "    print(\"\\n--- Evaluaci√≥n Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluaci√≥n Euclidiana (k={best_k_euclidean}, weights='distance'):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluaci√≥n Manhattan (k={best_k_manhattan}, weights='distance'):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04c6fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37249453",
   "metadata": {},
   "source": [
    "#### 3. KNN - CC:SI - ED:NO - Outliers:SI - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c38f8d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (5200, 11)\n",
      "Tama√±o sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.7498\n",
      "üîπ Mejor K (Manhattan): 1 | Max Acc: 0.7903\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1):\n",
      "Accuracy: 0.7498, Precision: 0.7512, Recall: 0.7498, F1-Score: 0.7499\n",
      "-> Evaluaci√≥n Manhattan (k=1):\n",
      "Accuracy: 0.7903, Precision: 0.7902, Recall: 0.7903, F1-Score: 0.7902\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.7626\n",
      "üîπ Mejor K (Manhattan): 1 | Max Acc: 0.8101\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1):\n",
      "Accuracy: 0.7626, Precision: 0.7626, Recall: 0.7626, F1-Score: 0.7621\n",
      "-> Evaluaci√≥n Manhattan (k=1):\n",
      "Accuracy: 0.8101, Precision: 0.8097, Recall: 0.8101, F1-Score: 0.8096\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.7478\n",
      "üîπ Mejor K (Manhattan): 1 | Max Acc: 0.7903\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1):\n",
      "Accuracy: 0.7478, Precision: 0.7475, Recall: 0.7478, F1-Score: 0.7474\n",
      "-> Evaluaci√≥n Manhattan (k=1):\n",
      "Accuracy: 0.7903, Precision: 0.7904, Recall: 0.7903, F1-Score: 0.7903\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Preparaci√≥n de los datos\n",
    "# ================================================================\n",
    "data_knn_3 = data.copy()\n",
    "\n",
    "# 1Ô∏è‚É£ Eliminaci√≥n de outliers (IQR)\n",
    "num_cols = data_knn_1.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_knn_3[num_cols].quantile(0.25)\n",
    "Q3 = data_knn_3[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_knn_3[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_knn_3[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_knn_3[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tama√±o original:\", data_knn_3.shape)\n",
    "print(\"Tama√±o sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# ‚öôÔ∏è Funci√≥n de evaluaci√≥n\n",
    "# ================================================================\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'M√©trica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"üß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # üîé B√∫squeda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"üîπ Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"üîπ Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # üß† Evaluaci√≥n final con los K √≥ptimos\n",
    "    print(\"\\n--- Evaluaci√≥n Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluaci√≥n Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluaci√≥n Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d3976e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7821734",
   "metadata": {},
   "source": [
    "#### 4. KNN - CC:SI - ED:NO - Outliers:SI - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1dbbee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (5200, 11)\n",
      "Tama√±o sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.7498\n",
      "üîπ Mejor K (Manhattan): 1 | Max Acc: 0.7903\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1):\n",
      "Accuracy: 0.7498, Precision: 0.7512, Recall: 0.7498, F1-Score: 0.7499\n",
      "-> Evaluaci√≥n Manhattan (k=1):\n",
      "Accuracy: 0.7903, Precision: 0.7902, Recall: 0.7903, F1-Score: 0.7902\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.7626\n",
      "üîπ Mejor K (Manhattan): 1 | Max Acc: 0.8101\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1):\n",
      "Accuracy: 0.7626, Precision: 0.7626, Recall: 0.7626, F1-Score: 0.7621\n",
      "-> Evaluaci√≥n Manhattan (k=1):\n",
      "Accuracy: 0.8101, Precision: 0.8097, Recall: 0.8101, F1-Score: 0.8096\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.7478\n",
      "üîπ Mejor K (Manhattan): 1 | Max Acc: 0.7903\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1):\n",
      "Accuracy: 0.7478, Precision: 0.7475, Recall: 0.7478, F1-Score: 0.7474\n",
      "-> Evaluaci√≥n Manhattan (k=1):\n",
      "Accuracy: 0.7903, Precision: 0.7904, Recall: 0.7903, F1-Score: 0.7903\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Preparaci√≥n de los datos\n",
    "# ================================================================\n",
    "data_knn_4 = data.copy()\n",
    "\n",
    "# 1Ô∏è‚É£ Eliminaci√≥n de outliers (IQR)\n",
    "num_cols = data_knn_4.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_knn_4[num_cols].quantile(0.25)\n",
    "Q3 = data_knn_4[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_knn_4[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_knn_4[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_knn_4[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tama√±o original:\", data_knn_4.shape)\n",
    "print(\"Tama√±o sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# ‚öôÔ∏è Funci√≥n de evaluaci√≥n\n",
    "# ================================================================\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'M√©trica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"üß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # üîé B√∫squeda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"üîπ Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"üîπ Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # üß† Evaluaci√≥n final con los K √≥ptimos\n",
    "    print(\"\\n--- Evaluaci√≥n Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluaci√≥n Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluaci√≥n Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a099a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2c544",
   "metadata": {},
   "source": [
    "#### 5. KNN - CC:SI - ED:SI - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c973a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "üü¢ MODELO KNN CON NORMALIZACI√ìN\n",
      "=================================================\n",
      "\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "üîπ Mejor K (Euclidiana): 65 | Max Acc: 0.5260\n",
      "üîπ Mejor K (Manhattan): 38 | Max Acc: 0.5962\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=65):\n",
      "Accuracy: 0.5260, Precision: 0.5209, Recall: 0.5260, F1-Score: 0.5189\n",
      "-> Evaluaci√≥n Manhattan (k=38):\n",
      "Accuracy: 0.5962, Precision: 0.5989, Recall: 0.5962, F1-Score: 0.5950\n",
      "\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.5173\n",
      "üîπ Mejor K (Manhattan): 50 | Max Acc: 0.5981\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1):\n",
      "Accuracy: 0.5173, Precision: 0.5373, Recall: 0.5173, F1-Score: 0.5242\n",
      "-> Evaluaci√≥n Manhattan (k=50):\n",
      "Accuracy: 0.5981, Precision: 0.5967, Recall: 0.5981, F1-Score: 0.5958\n",
      "\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "üîπ Mejor K (Euclidiana): 47 | Max Acc: 0.5231\n",
      "üîπ Mejor K (Manhattan): 57 | Max Acc: 0.5981\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=47):\n",
      "Accuracy: 0.5231, Precision: 0.5205, Recall: 0.5231, F1-Score: 0.5200\n",
      "-> Evaluaci√≥n Manhattan (k=57):\n",
      "Accuracy: 0.5981, Precision: 0.5921, Recall: 0.5981, F1-Score: 0.5927\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Preparaci√≥n de los datos\n",
    "# ================================================================\n",
    "data_knn_5 = data.copy()\n",
    "\n",
    "X = data_knn_5.drop(\"Workout_Type\", axis=1)\n",
    "y = data_knn_5[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# ‚öôÔ∏è Funci√≥n de evaluaci√≥n\n",
    "# ================================================================\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'M√©trica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras (CON NORMALIZACI√ìN)\n",
    "# ================================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "print(\"\\n=================================================\")\n",
    "print(\"üü¢ MODELO KNN CON NORMALIZACI√ìN\")\n",
    "print(\"=================================================\")\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\nüß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    \n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Normalizaci√≥n de los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # üîé B√∫squeda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "            knn.fit(X_train_scaled, y_train)\n",
    "            y_pred = knn.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"üîπ Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"üîπ Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # üß† Evaluaci√≥n final con los K √≥ptimos\n",
    "    print(\"\\n--- Evaluaci√≥n Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluaci√≥n Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluaci√≥n Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a24f7297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff133c",
   "metadata": {},
   "source": [
    "#### 6. KNN - CC:SI - ED:SI - Outliers:NO - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "üü¢ MODELO KNN CON NORMALIZACI√ìN\n",
      "=================================================\n",
      "\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "üîπ Mejor K (Euclidiana): 83 | Max Acc: 0.6654\n",
      "üîπ Mejor K (Manhattan): 96 | Max Acc: 0.6596\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=83):\n",
      "Accuracy: 0.6654, Precision: 0.6673, Recall: 0.6654, F1-Score: 0.6639\n",
      "-> Evaluaci√≥n Manhattan (k=96):\n",
      "Accuracy: 0.6596, Precision: 0.6577, Recall: 0.6596, F1-Score: 0.6559\n",
      "\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "üîπ Mejor K (Euclidiana): 75 | Max Acc: 0.6558\n",
      "üîπ Mejor K (Manhattan): 65 | Max Acc: 0.6683\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=75):\n",
      "Accuracy: 0.6558, Precision: 0.6606, Recall: 0.6558, F1-Score: 0.6568\n",
      "-> Evaluaci√≥n Manhattan (k=65):\n",
      "Accuracy: 0.6683, Precision: 0.6711, Recall: 0.6683, F1-Score: 0.6689\n",
      "\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "üîπ Mejor K (Euclidiana): 52 | Max Acc: 0.6808\n",
      "üîπ Mejor K (Manhattan): 89 | Max Acc: 0.6933\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=52):\n",
      "Accuracy: 0.6808, Precision: 0.6879, Recall: 0.6808, F1-Score: 0.6828\n",
      "-> Evaluaci√≥n Manhattan (k=89):\n",
      "Accuracy: 0.6933, Precision: 0.6949, Recall: 0.6933, F1-Score: 0.6921\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Preparaci√≥n de los datos\n",
    "# ================================================================\n",
    "data_knn_6 = data.copy()\n",
    "\n",
    "X = data_knn_6.drop(\"Workout_Type\", axis=1)\n",
    "y = data_knn_6[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# ‚öôÔ∏è Funci√≥n de evaluaci√≥n\n",
    "# ================================================================\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'M√©trica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras (CON NORMALIZACI√ìN)\n",
    "# ================================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "print(\"\\n=================================================\")\n",
    "print(\"üü¢ MODELO KNN CON NORMALIZACI√ìN\")\n",
    "print(\"=================================================\")\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\nüß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    \n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Normalizaci√≥n de los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # üîé B√∫squeda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train_scaled, y_train)\n",
    "            y_pred = knn.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"üîπ Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"üîπ Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # üß† Evaluaci√≥n final con los K √≥ptimos\n",
    "    print(\"\\n--- Evaluaci√≥n Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluaci√≥n Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluaci√≥n Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c04a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c0fe9",
   "metadata": {},
   "source": [
    "#### 7. KNN - CC:SI - ED:SI - Outliers:SI - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99643951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (5200, 11)\n",
      "Tama√±o sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "üü¢ MODELO KNN CON NORMALIZACI√ìN\n",
      "=================================================\n",
      "\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "üîπ Mejor K (Euclidiana): 81 | Max Acc: 0.5114\n",
      "üîπ Mejor K (Manhattan): 58 | Max Acc: 0.5816\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=81):\n",
      "Accuracy: 0.5114, Precision: 0.5252, Recall: 0.5114, F1-Score: 0.5071\n",
      "-> Evaluaci√≥n Manhattan (k=58):\n",
      "Accuracy: 0.5816, Precision: 0.5865, Recall: 0.5816, F1-Score: 0.5788\n",
      "\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "üîπ Mejor K (Euclidiana): 1 | Max Acc: 0.5589\n",
      "üîπ Mejor K (Manhattan): 61 | Max Acc: 0.6261\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=1):\n",
      "Accuracy: 0.5589, Precision: 0.5733, Recall: 0.5589, F1-Score: 0.5634\n",
      "-> Evaluaci√≥n Manhattan (k=61):\n",
      "Accuracy: 0.6261, Precision: 0.6353, Recall: 0.6261, F1-Score: 0.6251\n",
      "\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "üîπ Mejor K (Euclidiana): 66 | Max Acc: 0.5302\n",
      "üîπ Mejor K (Manhattan): 55 | Max Acc: 0.6053\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=66):\n",
      "Accuracy: 0.5302, Precision: 0.5349, Recall: 0.5302, F1-Score: 0.5273\n",
      "-> Evaluaci√≥n Manhattan (k=55):\n",
      "Accuracy: 0.6053, Precision: 0.6088, Recall: 0.6053, F1-Score: 0.6020\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Preparaci√≥n de los datos\n",
    "# ================================================================\n",
    "data_knn_7 = data.copy()\n",
    "\n",
    "# 1Ô∏è‚É£ Eliminaci√≥n de outliers (IQR)\n",
    "num_cols = data_knn_7.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_knn_7[num_cols].quantile(0.25)\n",
    "Q3 = data_knn_7[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_knn_7[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_knn_7[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_knn_7[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tama√±o original:\", data_knn_7.shape)\n",
    "print(\"Tama√±o sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# ‚öôÔ∏è Funci√≥n de evaluaci√≥n\n",
    "# ================================================================\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'M√©trica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras (CON NORMALIZACI√ìN)\n",
    "# ================================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "print(\"\\n=================================================\")\n",
    "print(\"üü¢ MODELO KNN CON NORMALIZACI√ìN\")\n",
    "print(\"=================================================\")\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\nüß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    \n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Normalizaci√≥n de los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # üîé B√∫squeda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "            knn.fit(X_train_scaled, y_train)\n",
    "            y_pred = knn.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"üîπ Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"üîπ Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # üß† Evaluaci√≥n final con los K √≥ptimos\n",
    "    print(\"\\n--- Evaluaci√≥n Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluaci√≥n Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluaci√≥n Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47625411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6420d9",
   "metadata": {},
   "source": [
    "#### 8. KNN - CC:SI - ED:SI - Outliers:SI - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc264c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (5200, 11)\n",
      "Tama√±o sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "üü¢ MODELO KNN CON NORMALIZACI√ìN\n",
      "=================================================\n",
      "\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "üîπ Mejor K (Euclidiana): 75 | Max Acc: 0.6597\n",
      "üîπ Mejor K (Manhattan): 59 | Max Acc: 0.6617\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=75):\n",
      "Accuracy: 0.6597, Precision: 0.6615, Recall: 0.6597, F1-Score: 0.6579\n",
      "-> Evaluaci√≥n Manhattan (k=59):\n",
      "Accuracy: 0.6617, Precision: 0.6650, Recall: 0.6617, F1-Score: 0.6607\n",
      "\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "üîπ Mejor K (Euclidiana): 89 | Max Acc: 0.6993\n",
      "üîπ Mejor K (Manhattan): 81 | Max Acc: 0.7112\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=89):\n",
      "Accuracy: 0.6993, Precision: 0.7081, Recall: 0.6993, F1-Score: 0.6996\n",
      "-> Evaluaci√≥n Manhattan (k=81):\n",
      "Accuracy: 0.7112, Precision: 0.7190, Recall: 0.7112, F1-Score: 0.7110\n",
      "\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "üîπ Mejor K (Euclidiana): 89 | Max Acc: 0.6617\n",
      "üîπ Mejor K (Manhattan): 96 | Max Acc: 0.6696\n",
      "\n",
      "--- Evaluaci√≥n Final ---\n",
      "-> Evaluaci√≥n Euclidiana (k=89):\n",
      "Accuracy: 0.6617, Precision: 0.6707, Recall: 0.6617, F1-Score: 0.6619\n",
      "-> Evaluaci√≥n Manhattan (k=96):\n",
      "Accuracy: 0.6696, Precision: 0.6716, Recall: 0.6696, F1-Score: 0.6668\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# üìÇ Preparaci√≥n de los datos\n",
    "# ================================================================\n",
    "data_knn_8 = data.copy()\n",
    "\n",
    "# 1Ô∏è‚É£ Eliminaci√≥n de outliers (IQR)\n",
    "num_cols = data_knn_8.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_knn_8[num_cols].quantile(0.25)\n",
    "Q3 = data_knn_8[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_knn_8[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_knn_8[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_knn_8[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tama√±o original:\", data_knn_8.shape)\n",
    "print(\"Tama√±o sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# ‚öôÔ∏è Funci√≥n de evaluaci√≥n\n",
    "# ================================================================\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'M√©trica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# üîÅ Tres muestras (CON NORMALIZACI√ìN)\n",
    "# ================================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "print(\"\\n=================================================\")\n",
    "print(\"üü¢ MODELO KNN CON NORMALIZACI√ìN\")\n",
    "print(\"=================================================\")\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\nüß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    \n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Normalizaci√≥n de los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # üîé B√∫squeda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train_scaled, y_train)\n",
    "            y_pred = knn.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"üîπ Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"üîπ Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # üß† Evaluaci√≥n final con los K √≥ptimos\n",
    "    print(\"\\n--- Evaluaci√≥n Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluaci√≥n Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluaci√≥n Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ade277e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f72f1",
   "metadata": {},
   "source": [
    "## M√°quinas de Soporte Vectorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed95ff8",
   "metadata": {},
   "source": [
    "#### 1. MSV - CC:SI - ED:NO - Outliers:NO - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55740212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.4673\n",
      "   Precision: 0.3698\n",
      "   Recall:    0.4673\n",
      "   F1-Score:  0.3952\n",
      "\n",
      "üîπ One-vs-One (random_state=111)\n",
      "   Accuracy:  0.4990\n",
      "   Precision: 0.4767\n",
      "   Recall:    0.4990\n",
      "   F1-Score:  0.4767\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.4558\n",
      "   Precision: 0.4063\n",
      "   Recall:    0.4558\n",
      "   F1-Score:  0.3958\n",
      "\n",
      "üîπ One-vs-One (random_state=222)\n",
      "   Accuracy:  0.4808\n",
      "   Precision: 0.4689\n",
      "   Recall:    0.4808\n",
      "   F1-Score:  0.4642\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.4663\n",
      "   Precision: 0.4106\n",
      "   Recall:    0.4663\n",
      "   F1-Score:  0.4007\n",
      "\n",
      "üîπ One-vs-One (random_state=333)\n",
      "   Accuracy:  0.5221\n",
      "   Precision: 0.5103\n",
      "   Recall:    0.5221\n",
      "   F1-Score:  0.4992\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_1 = data.copy()\n",
    "\n",
    "X = data_msv_1.drop(\"Workout_Type\", axis=1)\n",
    "y = data_msv_1[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definici√≥n de la funci√≥n de evaluaci√≥n\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nüîπ {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# üîÅ Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"üß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-Rest\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train, X_test, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-One\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train, X_test, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ea8390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7106e",
   "metadata": {},
   "source": [
    "#### 2. MSV - CC:SI - ED:NO - Outliers:NO - Balanceo:SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd42c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "‚öñÔ∏è  CASO DE PRUEBA 1 (random_state=111) - MODELOS BALANCEADOS\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=111) [BALANCEADO]\n",
      "   Accuracy:  0.4048\n",
      "   Precision: 0.4287\n",
      "   Recall:    0.4048\n",
      "   F1-Score:  0.3999\n",
      "\n",
      "üîπ One-vs-One (random_state=111) [BALANCEADO]\n",
      "   Accuracy:  0.4856\n",
      "   Precision: 0.4699\n",
      "   Recall:    0.4856\n",
      "   F1-Score:  0.4507\n",
      "\n",
      "=================================================\n",
      "‚öñÔ∏è  CASO DE PRUEBA 2 (random_state=222) - MODELOS BALANCEADOS\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=222) [BALANCEADO]\n",
      "   Accuracy:  0.4221\n",
      "   Precision: 0.4297\n",
      "   Recall:    0.4221\n",
      "   F1-Score:  0.4094\n",
      "\n",
      "üîπ One-vs-One (random_state=222) [BALANCEADO]\n",
      "   Accuracy:  0.4904\n",
      "   Precision: 0.4809\n",
      "   Recall:    0.4904\n",
      "   F1-Score:  0.4728\n",
      "\n",
      "=================================================\n",
      "‚öñÔ∏è  CASO DE PRUEBA 3 (random_state=333) - MODELOS BALANCEADOS\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=333) [BALANCEADO]\n",
      "   Accuracy:  0.4413\n",
      "   Precision: 0.4451\n",
      "   Recall:    0.4413\n",
      "   F1-Score:  0.4318\n",
      "\n",
      "üîπ One-vs-One (random_state=333) [BALANCEADO]\n",
      "   Accuracy:  0.5173\n",
      "   Precision: 0.4932\n",
      "   Recall:    0.5173\n",
      "   F1-Score:  0.4887\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_2 = data.copy()\n",
    "\n",
    "X = data_msv_2.drop(\"Workout_Type\", axis=1)\n",
    "y = data_msv_2[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definici√≥n de la funci√≥n de evaluaci√≥n\n",
    "# =================================================\n",
    "def evaluar_modelo_svm_balanceado(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo SVM con balanceo de clases.\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nüîπ {tipo_modelo} (random_state={seed}) [BALANCEADO]\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Balanceado': True,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# üîÅ Tres muestras (random states)\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_balanceados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"‚öñÔ∏è  CASO DE PRUEBA {i} (random_state={seed}) - MODELOS BALANCEADOS\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-Rest\n",
    "    resultados_balanceados.append(\n",
    "        evaluar_modelo_svm_balanceado(X_train, X_test, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-One\n",
    "    resultados_balanceados.append(\n",
    "        evaluar_modelo_svm_balanceado(X_train, X_test, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ff26b",
   "metadata": {},
   "source": [
    "#### 3. MSV - CC:SI - ED:NO - Outliers:SI - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db02240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (5200, 11)\n",
      "Tama√±o sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.4253\n",
      "   Precision: 0.3690\n",
      "   Recall:    0.4253\n",
      "   F1-Score:  0.3733\n",
      "\n",
      "üîπ One-vs-One (random_state=111)\n",
      "   Accuracy:  0.4797\n",
      "   Precision: 0.4648\n",
      "   Recall:    0.4797\n",
      "   F1-Score:  0.4595\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.4510\n",
      "   Precision: 0.4147\n",
      "   Recall:    0.4510\n",
      "   F1-Score:  0.3779\n",
      "\n",
      "üîπ One-vs-One (random_state=222)\n",
      "   Accuracy:  0.4758\n",
      "   Precision: 0.4621\n",
      "   Recall:    0.4758\n",
      "   F1-Score:  0.4515\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.3798\n",
      "   Precision: 0.3325\n",
      "   Recall:    0.3798\n",
      "   F1-Score:  0.3068\n",
      "\n",
      "üîπ One-vs-One (random_state=333)\n",
      "   Accuracy:  0.4896\n",
      "   Precision: 0.4720\n",
      "   Recall:    0.4896\n",
      "   F1-Score:  0.4657\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_3 = data.copy()\n",
    "\n",
    "# 1Ô∏è‚É£ Eliminaci√≥n de outliers (IQR)\n",
    "num_cols = data_msv_3.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_msv_3[num_cols].quantile(0.25)\n",
    "Q3 = data_msv_3[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_msv_3[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_msv_3[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_msv_3[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tama√±o original:\", data_msv_3.shape)\n",
    "print(\"Tama√±o sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definici√≥n de la funci√≥n de evaluaci√≥n\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nüîπ {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# üîÅ Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"üß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-Rest\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train, X_test, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-One\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train, X_test, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23064b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ab53dc",
   "metadata": {},
   "source": [
    "#### 4. MSV - CC:SI - ED:NO - Outliers:SI - Balanceo:SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58cc8ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (5200, 11)\n",
      "Tama√±o sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.4273\n",
      "   Precision: 0.4255\n",
      "   Recall:    0.4273\n",
      "   F1-Score:  0.4104\n",
      "\n",
      "üîπ One-vs-One (random_state=111)\n",
      "   Accuracy:  0.4955\n",
      "   Precision: 0.4616\n",
      "   Recall:    0.4955\n",
      "   F1-Score:  0.4530\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.4332\n",
      "   Precision: 0.4327\n",
      "   Recall:    0.4332\n",
      "   F1-Score:  0.4214\n",
      "\n",
      "üîπ One-vs-One (random_state=222)\n",
      "   Accuracy:  0.4679\n",
      "   Precision: 0.4405\n",
      "   Recall:    0.4679\n",
      "   F1-Score:  0.4202\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.4263\n",
      "   Precision: 0.4249\n",
      "   Recall:    0.4263\n",
      "   F1-Score:  0.4148\n",
      "\n",
      "üîπ One-vs-One (random_state=333)\n",
      "   Accuracy:  0.4698\n",
      "   Precision: 0.4108\n",
      "   Recall:    0.4698\n",
      "   F1-Score:  0.4025\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_4 = data.copy()\n",
    "\n",
    "# 1Ô∏è‚É£ Eliminaci√≥n de outliers (IQR)\n",
    "num_cols = data_msv_4.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_msv_4[num_cols].quantile(0.25)\n",
    "Q3 = data_msv_4[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_msv_4[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_msv_4[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_msv_4[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tama√±o original:\", data_msv_4.shape)\n",
    "print(\"Tama√±o sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definici√≥n de la funci√≥n de evaluaci√≥n\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nüîπ {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# üîÅ Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"üß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-Rest\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train, X_test, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-One\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train, X_test, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782deb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db7471",
   "metadata": {},
   "source": [
    "#### 5. MSV - CC:SI - ED:SI - Outliers:NO - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3c4ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.6279\n",
      "   Precision: 0.6055\n",
      "   Recall:    0.6279\n",
      "   F1-Score:  0.5646\n",
      "\n",
      "üîπ One-vs-One (random_state=111)\n",
      "   Accuracy:  0.8010\n",
      "   Precision: 0.8054\n",
      "   Recall:    0.8010\n",
      "   F1-Score:  0.8012\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.6327\n",
      "   Precision: 0.6580\n",
      "   Recall:    0.6327\n",
      "   F1-Score:  0.5696\n",
      "\n",
      "üîπ One-vs-One (random_state=222)\n",
      "   Accuracy:  0.8192\n",
      "   Precision: 0.8235\n",
      "   Recall:    0.8192\n",
      "   F1-Score:  0.8190\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.6279\n",
      "   Precision: 0.6340\n",
      "   Recall:    0.6279\n",
      "   F1-Score:  0.5624\n",
      "\n",
      "üîπ One-vs-One (random_state=333)\n",
      "   Accuracy:  0.8135\n",
      "   Precision: 0.8170\n",
      "   Recall:    0.8135\n",
      "   F1-Score:  0.8137\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_5 = data.copy()\n",
    "\n",
    "X = data_msv_5.drop(\"Workout_Type\", axis=1)\n",
    "y = data_msv_5[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definici√≥n de la funci√≥n de evaluaci√≥n\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nüîπ {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# üîÅ Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"üß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # =================================================\n",
    "    # üîπ Normalizaci√≥n de los datos\n",
    "    # =================================================\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # =================================================\n",
    "    # Modelos SVM\n",
    "    # =================================================\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1298fc",
   "metadata": {},
   "source": [
    "#### 6. MSV - CC:SI - ED:SI - Outliers:NO - Balanceo:SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b583a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.6529\n",
      "   Precision: 0.7146\n",
      "   Recall:    0.6529\n",
      "   F1-Score:  0.6655\n",
      "\n",
      "üîπ One-vs-One (random_state=111)\n",
      "   Accuracy:  0.7962\n",
      "   Precision: 0.8030\n",
      "   Recall:    0.7962\n",
      "   F1-Score:  0.7968\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.6442\n",
      "   Precision: 0.7122\n",
      "   Recall:    0.6442\n",
      "   F1-Score:  0.6534\n",
      "\n",
      "üîπ One-vs-One (random_state=222)\n",
      "   Accuracy:  0.8173\n",
      "   Precision: 0.8223\n",
      "   Recall:    0.8173\n",
      "   F1-Score:  0.8171\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.6663\n",
      "   Precision: 0.7391\n",
      "   Recall:    0.6663\n",
      "   F1-Score:  0.6776\n",
      "\n",
      "üîπ One-vs-One (random_state=333)\n",
      "   Accuracy:  0.8192\n",
      "   Precision: 0.8255\n",
      "   Recall:    0.8192\n",
      "   F1-Score:  0.8208\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_6 = data.copy()\n",
    "\n",
    "X = data_msv_6.drop(\"Workout_Type\", axis=1)\n",
    "y = data_msv_6[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definici√≥n de la funci√≥n de evaluaci√≥n\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nüîπ {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# üîÅ Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"üß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # =================================================\n",
    "    # üîπ Normalizaci√≥n de los datos\n",
    "    # =================================================\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # =================================================\n",
    "    # Modelos SVM\n",
    "    # =================================================\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78cba8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c097b5",
   "metadata": {},
   "source": [
    "#### 7. MSV - CC:SI - ED:SI - Outliers:SI - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a4150d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (5200, 11)\n",
      "Tama√±o sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.6380\n",
      "   Precision: 0.6437\n",
      "   Recall:    0.6380\n",
      "   F1-Score:  0.5819\n",
      "\n",
      "üîπ One-vs-One (random_state=111)\n",
      "   Accuracy:  0.7992\n",
      "   Precision: 0.8035\n",
      "   Recall:    0.7992\n",
      "   F1-Score:  0.7998\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.6320\n",
      "   Precision: 0.6379\n",
      "   Recall:    0.6320\n",
      "   F1-Score:  0.5723\n",
      "\n",
      "üîπ One-vs-One (random_state=222)\n",
      "   Accuracy:  0.8220\n",
      "   Precision: 0.8343\n",
      "   Recall:    0.8220\n",
      "   F1-Score:  0.8237\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.6340\n",
      "   Precision: 0.6220\n",
      "   Recall:    0.6340\n",
      "   F1-Score:  0.5767\n",
      "\n",
      "üîπ One-vs-One (random_state=333)\n",
      "   Accuracy:  0.8140\n",
      "   Precision: 0.8173\n",
      "   Recall:    0.8140\n",
      "   F1-Score:  0.8136\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_7 = data.copy()\n",
    "\n",
    "# 1Ô∏è‚É£ Eliminaci√≥n de outliers (IQR)\n",
    "num_cols = data_msv_7.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_msv_7[num_cols].quantile(0.25)\n",
    "Q3 = data_msv_7[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_msv_7[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_msv_7[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_msv_7[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tama√±o original:\", data_msv_7.shape)\n",
    "print(\"Tama√±o sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definici√≥n de la funci√≥n de evaluaci√≥n\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nüîπ {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# üîÅ Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"üß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # =================================================\n",
    "    # üîπ Normalizaci√≥n de los datos\n",
    "    # =================================================\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # =================================================\n",
    "    # Modelos SVM\n",
    "    # =================================================\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adfca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1490d9f8",
   "metadata": {},
   "source": [
    "#### 8. MSV - CC:SI - ED:SI - Outliers:SI - Balanceo:SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9df7c45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (5200, 11)\n",
      "Tama√±o sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.6538\n",
      "   Precision: 0.7064\n",
      "   Recall:    0.6538\n",
      "   F1-Score:  0.6627\n",
      "\n",
      "üîπ One-vs-One (random_state=111)\n",
      "   Accuracy:  0.8042\n",
      "   Precision: 0.8089\n",
      "   Recall:    0.8042\n",
      "   F1-Score:  0.8034\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.6934\n",
      "   Precision: 0.7506\n",
      "   Recall:    0.6934\n",
      "   F1-Score:  0.7009\n",
      "\n",
      "üîπ One-vs-One (random_state=222)\n",
      "   Accuracy:  0.8497\n",
      "   Precision: 0.8566\n",
      "   Recall:    0.8497\n",
      "   F1-Score:  0.8515\n",
      "\n",
      "=================================================\n",
      "üß† CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "üîπ One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.6864\n",
      "   Precision: 0.7197\n",
      "   Recall:    0.6864\n",
      "   F1-Score:  0.6926\n",
      "\n",
      "üîπ One-vs-One (random_state=333)\n",
      "   Accuracy:  0.8180\n",
      "   Precision: 0.8221\n",
      "   Recall:    0.8180\n",
      "   F1-Score:  0.8158\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_8 = data.copy()\n",
    "\n",
    "# 1Ô∏è‚É£ Eliminaci√≥n de outliers (IQR)\n",
    "num_cols = data_msv_8.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_msv_8[num_cols].quantile(0.25)\n",
    "Q3 = data_msv_8[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_msv_8[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_msv_8[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_msv_8[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tama√±o original:\", data_msv_8.shape)\n",
    "print(\"Tama√±o sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definici√≥n de la funci√≥n de evaluaci√≥n\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y eval√∫a un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nüîπ {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# üîÅ Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"üß† CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # Divisi√≥n de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # =================================================\n",
    "    # üîπ Normalizaci√≥n de los datos\n",
    "    # =================================================\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # =================================================\n",
    "    # Modelos SVM\n",
    "    # =================================================\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba7b6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario\n",
    "# TODO hacer la gr√°fica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b59172",
   "metadata": {},
   "source": [
    "## Redes Neuronales: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587065b7",
   "metadata": {},
   "source": [
    "#### 1. RN - CC:SI - ED:NO - Outliers:NO - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14b4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "üß© CASO DE PRUEBA (random_state=111)\n",
      "=================================================\n",
      "üîπ Entrenando con Optimizador=adam, Activaci√≥n=relu...\n",
      "üîπ Entrenando con Optimizador=adam, Activaci√≥n=tanh...\n",
      "üîπ Entrenando con Optimizador=adam, Activaci√≥n=sigmoid...\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# üß† Copia de los datos\n",
    "# =================================================\n",
    "data_rn_1 = data.copy()\n",
    "\n",
    "X = data_rn_1.drop(\"Workout_Type\", axis=1)\n",
    "y = data_rn_1[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# ‚öôÔ∏è Funci√≥n para entrenar y evaluar una red neuronal\n",
    "# =================================================\n",
    "def evaluar_red_neuronal(X_train, X_test, y_train, y_test, optimizer_name, activation_hidden, seed):\n",
    "    \"\"\"Entrena y eval√∫a una red neuronal con distintos optimizadores y activaciones, usando Early Stopping.\"\"\"\n",
    "    \n",
    "    # Seleccionar optimizador\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizador no soportado.\")\n",
    "\n",
    "    # Crear modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(8, activation=activation_hidden),\n",
    "        Dense(6, activation=activation_hidden),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compilar modelo\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,              # N√∫mero de epochs sin mejora antes de parar\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Entrenar modelo\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # M√©tricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Optimizador': optimizer_name,\n",
    "        'Activaci√≥n': activation_hidden,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Modelo': model\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# üîÅ Configuraci√≥n de experimentos\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "optimizadores = ['adam', 'sgd']\n",
    "activaciones = ['relu', 'tanh', 'sigmoid']\n",
    "resultados_totales = []\n",
    "\n",
    "# =================================================\n",
    "# üöÄ Pruebas con todas las combinaciones\n",
    "# =================================================\n",
    "for seed in random_states:\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"üß© CASO DE PRUEBA (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    for opt in optimizadores:\n",
    "        for act in activaciones:\n",
    "            print(f\"üîπ Entrenando con Optimizador={opt}, Activaci√≥n={act}...\")\n",
    "            resultados_totales.append(\n",
    "                evaluar_red_neuronal(X_train, X_test, y_train, y_test, opt, act, seed)\n",
    "            )\n",
    "\n",
    "# =================================================\n",
    "# üìä Resultados finales\n",
    "# =================================================\n",
    "resultados_df = pd.DataFrame(resultados_totales)\n",
    "\n",
    "# Ordenar por mejor F1-score\n",
    "mejor_modelo = resultados_df.sort_values(by='F1-Score', ascending=False).head(1)\n",
    "\n",
    "print(\"\\nüìä RESULTADOS DE TODOS LOS MODELOS:\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nüèÜ MEJOR MODELO ENCONTRADO:\")\n",
    "print(mejor_modelo.to_string(index=False))\n",
    "\n",
    "print(\"\\nüìê ARQUITECTURA DEL MEJOR MODELO:\")\n",
    "mejor_modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7172d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar m√©tricas en el diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e228ff",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
