{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4340e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# diccionario para guardar todas las métricas\n",
    "metricas = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86804070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Height_m</th>\n",
       "      <th>Max_BPM</th>\n",
       "      <th>Avg_BPM</th>\n",
       "      <th>Resting_BPM</th>\n",
       "      <th>Session_Duration_hours</th>\n",
       "      <th>Calories_Burned</th>\n",
       "      <th>Workout_Type</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.14</td>\n",
       "      <td>101.05</td>\n",
       "      <td>1.95</td>\n",
       "      <td>171.17</td>\n",
       "      <td>130.81</td>\n",
       "      <td>68.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>959.43</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.17</td>\n",
       "      <td>41.63</td>\n",
       "      <td>1.78</td>\n",
       "      <td>167.33</td>\n",
       "      <td>158.46</td>\n",
       "      <td>63.95</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1424.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.07</td>\n",
       "      <td>63.81</td>\n",
       "      <td>1.78</td>\n",
       "      <td>187.86</td>\n",
       "      <td>137.11</td>\n",
       "      <td>60.93</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1766.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.30</td>\n",
       "      <td>59.77</td>\n",
       "      <td>1.78</td>\n",
       "      <td>183.83</td>\n",
       "      <td>120.32</td>\n",
       "      <td>60.01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1028.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.99</td>\n",
       "      <td>57.60</td>\n",
       "      <td>1.56</td>\n",
       "      <td>166.25</td>\n",
       "      <td>151.82</td>\n",
       "      <td>67.97</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1295.80</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Weight_kg  Height_m  Max_BPM  Avg_BPM  Resting_BPM  \\\n",
       "0  21.14     101.05      1.95   171.17   130.81        68.96   \n",
       "1  44.17      41.63      1.78   167.33   158.46        63.95   \n",
       "2  20.07      63.81      1.78   187.86   137.11        60.93   \n",
       "3  36.30      59.77      1.78   183.83   120.32        60.01   \n",
       "4  51.99      57.60      1.56   166.25   151.82        67.97   \n",
       "\n",
       "   Session_Duration_hours  Calories_Burned  Workout_Type  Gender_Female  \\\n",
       "0                    0.97           959.43             2            0.0   \n",
       "1                    1.48          1424.35             0            0.0   \n",
       "2                    1.70          1766.64             0            1.0   \n",
       "3                    0.85          1028.50             1            1.0   \n",
       "4                    1.66          1295.80             3            0.0   \n",
       "\n",
       "   Gender_Male  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. Carga del Conjunto de Datos ---\n",
    "data = pd.read_csv(\"../data/subset/clean_subset_lifestyledata_rows5200_seed5200.csv\")\n",
    "\n",
    "# --- 2. Codificación de Etiquetas (Label Encoding) ---\n",
    "label_encoder = LabelEncoder()\n",
    "# Se transforma la variable objetivo 'Workout_Type' a valores numéricos.\n",
    "data['Workout_Type'] = label_encoder.fit_transform(data['Workout_Type'])\n",
    "\n",
    "# --- 3. Codificación One-Hot (One-Hot Encoding) ---\n",
    "# Se define la lista de columnas categóricas nominales a transformar.\n",
    "nominal_cols = ['Gender']\n",
    "# sparse_output=False: Devuelve una matriz densa (array de NumPy) en lugar de una dispersa.\n",
    "# handle_unknown='ignore': Si aparece una categoría no vista durante la transformación, la ignora.\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# Esto crea nuevas columnas binarias para cada categoría.\n",
    "encoded = ohe.fit_transform(data[nominal_cols])\n",
    "# Se convierte la matriz resultante en un DataFrame con nombres de columna apropiados.\n",
    "encoded_df = pd.DataFrame(encoded, columns=ohe.get_feature_names_out(nominal_cols))\n",
    "\n",
    "# --- 4. Combinación de los Datos Procesados ---\n",
    "# Se elimina la columna original 'Gender' del DataFrame principal.\n",
    "# reset_index(drop=True) asegura que los índices se alineen correctamente para la concatenación.\n",
    "data = data.drop(columns=nominal_cols).reset_index(drop=True)\n",
    "encoded_df = encoded_df.reset_index(drop=True)\n",
    "\n",
    "# Se concatenan el DataFrame original y el nuevo DataFrame con las columnas codificadas.\n",
    "# axis=1 indica que la unión se realiza por columnas.\n",
    "data = pd.concat([data, encoded_df], axis=1)\n",
    "\n",
    "# --- 5. Visualización ---\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3d8ea8",
   "metadata": {},
   "source": [
    "# Árbol de Decisiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b928020a",
   "metadata": {},
   "source": [
    "#### 1. Árbol de Decisiones - CC:SI - ED:NO - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b46c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini\n",
      "Accuracy: 0.7327, Precision: 0.7412, Recall: 0.7327, F1-Score: 0.7350\n",
      "\n",
      "Modelo: Entropía\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "Modelo: Entropía Podado\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini\n",
      "Accuracy: 0.7452, Precision: 0.7431, Recall: 0.7452, F1-Score: 0.7438\n",
      "\n",
      "Modelo: Entropía\n",
      "Accuracy: 0.7875, Precision: 0.7968, Recall: 0.7875, F1-Score: 0.7892\n",
      "\n",
      "Modelo: Entropía Podado\n",
      "Accuracy: 0.7875, Precision: 0.7968, Recall: 0.7875, F1-Score: 0.7892\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini\n",
      "Accuracy: 0.7587, Precision: 0.7538, Recall: 0.7587, F1-Score: 0.7559\n",
      "\n",
      "Modelo: Entropía\n",
      "Accuracy: 0.7837, Precision: 0.8018, Recall: 0.7837, F1-Score: 0.7823\n",
      "\n",
      "Modelo: Entropía Podado\n",
      "Accuracy: 0.7837, Precision: 0.8018, Recall: 0.7837, F1-Score: 0.7823\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_1 = data.copy()\n",
    "X = data_tree_1.drop(\"Workout_Type\", axis=1)\n",
    "y = data_tree_1[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333] \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # Dividir datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Modelo 1: Árbol con Gini ---\n",
    "    modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=seed)\n",
    "    modelo_gini.fit(X_train, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía ---\n",
    "    modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "    modelo_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=seed)\n",
    "    modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "    # --- Calcular métricas ---\n",
    "    modelos = {\n",
    "        \"Gini\": y_pred_gini,\n",
    "        \"Entropía\": y_pred_entropy,\n",
    "        \"Entropía Podado\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        \n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66526514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fbf08",
   "metadata": {},
   "source": [
    "#### 2. Árbol de Decisiones - CC:SI - ED:NO - Outliers:NO - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c9b6a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Balanced\n",
      "Accuracy: 0.7327, Precision: 0.7412, Recall: 0.7327, F1-Score: 0.7350\n",
      "\n",
      "Modelo: Entropía_Balanced\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "Modelo: Entropía_Podado_Balanced\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Balanced\n",
      "Accuracy: 0.7375, Precision: 0.7338, Recall: 0.7375, F1-Score: 0.7348\n",
      "\n",
      "Modelo: Entropía_Balanced\n",
      "Accuracy: 0.7740, Precision: 0.7726, Recall: 0.7740, F1-Score: 0.7720\n",
      "\n",
      "Modelo: Entropía_Podado_Balanced\n",
      "Accuracy: 0.7740, Precision: 0.7726, Recall: 0.7740, F1-Score: 0.7720\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Balanced\n",
      "Accuracy: 0.7365, Precision: 0.7361, Recall: 0.7365, F1-Score: 0.7243\n",
      "\n",
      "Modelo: Entropía_Balanced\n",
      "Accuracy: 0.7846, Precision: 0.8026, Recall: 0.7846, F1-Score: 0.7833\n",
      "\n",
      "Modelo: Entropía_Podado_Balanced\n",
      "Accuracy: 0.7846, Precision: 0.8026, Recall: 0.7846, F1-Score: 0.7833\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_2 = data.copy()\n",
    "X = data_tree_2.drop(\"Workout_Type\", axis=1)\n",
    "y = data_tree_2[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras con class_weight='balanced'\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  # Tres seeds diferentes\n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # Dividir datos (80/20 estratificado)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Modelo 1: Árbol con Gini (class_weight='balanced') ---\n",
    "    modelo_gini = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_gini.fit(X_train, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía (class_weight='balanced') ---\n",
    "    modelo_entropy = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda (class_weight='balanced') ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=5, # Poda\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "    # --- Calcular métricas ---\n",
    "    modelos = {\n",
    "        \"Gini_Balanced\": y_pred_gini,\n",
    "        \"Entropía_Balanced\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Balanced\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas, usando zero_division=0 para un manejo robusto\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1df9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e13b9",
   "metadata": {},
   "source": [
    "#### 3. Árbol de Decisiones - CC:SI - ED:NO - Outliers:SI - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6028ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Clean\n",
      "Accuracy: 0.7399, Precision: 0.7479, Recall: 0.7399, F1-Score: 0.7403\n",
      "\n",
      "Modelo: Entropía_Clean\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "Modelo: Entropía_Podado_Clean\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Clean\n",
      "Accuracy: 0.7933, Precision: 0.8097, Recall: 0.7933, F1-Score: 0.7919\n",
      "\n",
      "Modelo: Entropía_Clean\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "Modelo: Entropía_Podado_Clean\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Clean\n",
      "Accuracy: 0.7923, Precision: 0.7979, Recall: 0.7923, F1-Score: 0.7928\n",
      "\n",
      "Modelo: Entropía_Clean\n",
      "Accuracy: 0.8200, Precision: 0.8163, Recall: 0.8200, F1-Score: 0.8177\n",
      "\n",
      "Modelo: Entropía_Podado_Clean\n",
      "Accuracy: 0.8180, Precision: 0.8149, Recall: 0.8180, F1-Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_3 = data.copy()\n",
    "\n",
    "# seleccionar solo las columnas numéricas\n",
    "num_cols = data_tree_3.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# calcular Q1, Q3 y el rango intercuartílico (IQR)\n",
    "Q1 = data_tree_3[num_cols].quantile(0.25)\n",
    "Q3 = data_tree_3[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# crear una máscara booleana que identifique las filas SIN outliers\n",
    "mask = ~((data_tree_3[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_tree_3[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# filtrar los datos limpios\n",
    "data_clean = data_tree_3[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_tree_3.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Separar X e y con datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Modelo 1: Árbol con Gini ---\n",
    "    modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=seed)\n",
    "    modelo_gini.fit(X_train, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía ---\n",
    "    modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "    modelo_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=seed)\n",
    "    modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "    # --- Calcular métricas ---\n",
    "    modelos = {\n",
    "        \"Gini_Clean\": y_pred_gini,\n",
    "        \"Entropía_Clean\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Clean\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513b99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fd4e1",
   "metadata": {},
   "source": [
    "#### 4. Árbol de Decisiones - CC:SI - ED:NO - Outliers:SI - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4a2c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Balanced\n",
      "Accuracy: 0.7745, Precision: 0.7935, Recall: 0.7745, F1-Score: 0.7710\n",
      "\n",
      "Modelo: Entropía_Clean_Balanced\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Balanced\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Balanced\n",
      "Accuracy: 0.7933, Precision: 0.8097, Recall: 0.7933, F1-Score: 0.7919\n",
      "\n",
      "Modelo: Entropía_Clean_Balanced\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Balanced\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Balanced\n",
      "Accuracy: 0.7943, Precision: 0.7994, Recall: 0.7943, F1-Score: 0.7946\n",
      "\n",
      "Modelo: Entropía_Clean_Balanced\n",
      "Accuracy: 0.8190, Precision: 0.8156, Recall: 0.8190, F1-Score: 0.8168\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Balanced\n",
      "Accuracy: 0.8180, Precision: 0.8149, Recall: 0.8180, F1-Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_4 = data.copy()\n",
    "\n",
    "# seleccionar solo las columnas numéricas\n",
    "num_cols = data_tree_4.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# calcular Q1, Q3 y el rango intercuartílico (IQR)\n",
    "Q1 = data_tree_4[num_cols].quantile(0.25)\n",
    "Q3 = data_tree_4[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# crear una máscara booleana que identifique las filas SIN outliers\n",
    "mask = ~((data_tree_4[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_tree_4[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# filtrar los datos limpios\n",
    "data_clean = data_tree_4[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_tree_4.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Separar X e y con datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  #\n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Modelo 1: Árbol con Gini + Balanced ---\n",
    "    modelo_gini = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_gini.fit(X_train, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía + Balanced ---\n",
    "    modelo_entropy = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    modelo_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda + Balanced ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=5, # Poda\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "    # --- Calcular métricas ---\n",
    "    modelos = {\n",
    "        \"Gini_Clean_Balanced\": y_pred_gini,\n",
    "        \"Entropía_Clean_Balanced\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Clean_Balanced\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c517ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb43b18",
   "metadata": {},
   "source": [
    "#### 5. Árbol de Decisiones - CC:SI - ED:SI - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d316eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Scaled\n",
      "Accuracy: 0.7327, Precision: 0.7412, Recall: 0.7327, F1-Score: 0.7350\n",
      "\n",
      "Modelo: Entropía_Scaled\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "Modelo: Entropía_Podado_Scaled\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Scaled\n",
      "Accuracy: 0.7452, Precision: 0.7431, Recall: 0.7452, F1-Score: 0.7438\n",
      "\n",
      "Modelo: Entropía_Scaled\n",
      "Accuracy: 0.7875, Precision: 0.7968, Recall: 0.7875, F1-Score: 0.7892\n",
      "\n",
      "Modelo: Entropía_Podado_Scaled\n",
      "Accuracy: 0.7875, Precision: 0.7968, Recall: 0.7875, F1-Score: 0.7892\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Scaled\n",
      "Accuracy: 0.7587, Precision: 0.7538, Recall: 0.7587, F1-Score: 0.7559\n",
      "\n",
      "Modelo: Entropía_Scaled\n",
      "Accuracy: 0.7837, Precision: 0.8018, Recall: 0.7837, F1-Score: 0.7823\n",
      "\n",
      "Modelo: Entropía_Podado_Scaled\n",
      "Accuracy: 0.7837, Precision: 0.8018, Recall: 0.7837, F1-Score: 0.7823\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_5 = data.copy()\n",
    "\n",
    "# Se definen las características (X) y la variable objetivo (y)\n",
    "X = data_tree_5.drop(\"Workout_Type\", axis=1)\n",
    "y = data_tree_5[\"Workout_Type\"]\n",
    "\n",
    "# Definir el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # 1. Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 2. Preprocesamiento: Escalado solo de columnas numéricas (excluyendo 'Gender')\n",
    "    numeric_cols = [col for col in X_train.columns if col not in ['Gender']] \n",
    "\n",
    "    # Hacer copias para el escalado\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    # Escalar\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    # 3. Entrenamiento y Predicción de Modelos\n",
    "    \n",
    "    # --- Modelo 1: Árbol con Gini ---\n",
    "    modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=seed)\n",
    "    modelo_gini.fit(X_train_scaled, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía ---\n",
    "    modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "    modelo_entropy.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=seed)\n",
    "    modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # 4. Calcular métricas\n",
    "    modelos = {\n",
    "        \"Gini_Scaled\": y_pred_gini,\n",
    "        \"Entropía_Scaled\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Scaled\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3e83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6489eb76",
   "metadata": {},
   "source": [
    "#### 6. Árbol de Decisiones - CC:SI - ED:SI - Outliers:NO - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c9b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Scaled_Balanced\n",
      "Accuracy: 0.7327, Precision: 0.7412, Recall: 0.7327, F1-Score: 0.7350\n",
      "\n",
      "Modelo: Entropía_Scaled_Balanced\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "Modelo: Entropía_Podado_Scaled_Balanced\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Scaled_Balanced\n",
      "Accuracy: 0.7375, Precision: 0.7338, Recall: 0.7375, F1-Score: 0.7348\n",
      "\n",
      "Modelo: Entropía_Scaled_Balanced\n",
      "Accuracy: 0.7740, Precision: 0.7726, Recall: 0.7740, F1-Score: 0.7720\n",
      "\n",
      "Modelo: Entropía_Podado_Scaled_Balanced\n",
      "Accuracy: 0.7740, Precision: 0.7726, Recall: 0.7740, F1-Score: 0.7720\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Scaled_Balanced\n",
      "Accuracy: 0.7365, Precision: 0.7361, Recall: 0.7365, F1-Score: 0.7243\n",
      "\n",
      "Modelo: Entropía_Scaled_Balanced\n",
      "Accuracy: 0.7846, Precision: 0.8026, Recall: 0.7846, F1-Score: 0.7833\n",
      "\n",
      "Modelo: Entropía_Podado_Scaled_Balanced\n",
      "Accuracy: 0.7846, Precision: 0.8026, Recall: 0.7846, F1-Score: 0.7833\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_6 = data.copy()\n",
    "\n",
    "# Se definen las características (X) y la variable objetivo (y)\n",
    "X = data_tree_6.drop(\"Workout_Type\", axis=1)\n",
    "y = data_tree_6[\"Workout_Type\"]\n",
    "\n",
    "# Definir el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # 1. Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 2. Preprocesamiento: Escalado solo de columnas numéricas\n",
    "    numeric_cols = [col for col in X_train.columns if col not in ['Gender']] # Se asume 'Gender' es la única no numérica relevante aquí\n",
    "\n",
    "    # Hacer copias para el escalado\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    # Escalar\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    # 3. Entrenamiento y Predicción de Modelos (con class_weight='balanced')\n",
    "\n",
    "    # --- Modelo 1: Árbol con Gini + Balanced ---\n",
    "    modelo_gini = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_gini.fit(X_train_scaled, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía + Balanced ---\n",
    "    modelo_entropy = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda + Balanced ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=5, # Poda\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # 4. Calcular métricas\n",
    "    modelos = {\n",
    "        \"Gini_Scaled_Balanced\": y_pred_gini,\n",
    "        \"Entropía_Scaled_Balanced\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Scaled_Balanced\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d16c0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23e255",
   "metadata": {},
   "source": [
    "#### 7. Árbol de Decisiones - CC:SI - ED:SI - Outliers:SI - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f175ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled\n",
      "Accuracy: 0.7399, Precision: 0.7479, Recall: 0.7399, F1-Score: 0.7403\n",
      "\n",
      "Modelo: Entropía_Clean_Scaled\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Scaled\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled\n",
      "Accuracy: 0.7933, Precision: 0.8097, Recall: 0.7933, F1-Score: 0.7919\n",
      "\n",
      "Modelo: Entropía_Clean_Scaled\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Scaled\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled\n",
      "Accuracy: 0.7923, Precision: 0.7979, Recall: 0.7923, F1-Score: 0.7928\n",
      "\n",
      "Modelo: Entropía_Clean_Scaled\n",
      "Accuracy: 0.8200, Precision: 0.8163, Recall: 0.8200, F1-Score: 0.8177\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Scaled\n",
      "Accuracy: 0.8180, Precision: 0.8149, Recall: 0.8180, F1-Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_7 = data.copy()\n",
    "\n",
    "# seleccionar solo las columnas numéricas\n",
    "num_cols = data_tree_7.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# calcular Q1, Q3 y el rango intercuartílico (IQR)\n",
    "Q1 = data_tree_7[num_cols].quantile(0.25)\n",
    "Q3 = data_tree_7[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# crear una máscara booleana que identifique las filas SIN outliers\n",
    "mask = ~((data_tree_7[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_tree_7[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# filtrar los datos limpios\n",
    "data_clean = data_tree_7[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_tree_7.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Separar X e y con datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# Definir el escalador\n",
    "scaler = StandardScaler()\n",
    "# Definir columnas a escalar (asumiendo 'Gender' es la única no numérica en X)\n",
    "numeric_cols = [col for col in X.columns if col not in ['Gender']]\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  # Tres seeds diferentes\n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # 1. Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 2. Preprocesamiento: Escalado\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    # Ajustar y transformar solo las columnas numéricas\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "\n",
    "    # 3. Entrenamiento y Predicción de Modelos\n",
    "\n",
    "    # --- Modelo 1: Árbol con Gini ---\n",
    "    modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=seed)\n",
    "    modelo_gini.fit(X_train_scaled, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía ---\n",
    "    modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "    modelo_entropy.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=seed)\n",
    "    modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # 4. Calcular métricas\n",
    "    modelos = {\n",
    "        \"Gini_Clean_Scaled\": y_pred_gini,\n",
    "        \"Entropía_Clean_Scaled\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Clean_Scaled\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52a3bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc5a64",
   "metadata": {},
   "source": [
    "#### 8. Árbol de Decisiones - CC:SI - ED:SI - Outliers:SI - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e235d4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7745, Precision: 0.7935, Recall: 0.7745, F1-Score: 0.7710\n",
      "\n",
      "Modelo: Entropía_Clean_Scaled_Balanced\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Scaled_Balanced\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7933, Precision: 0.8097, Recall: 0.7933, F1-Score: 0.7919\n",
      "\n",
      "Modelo: Entropía_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7943, Precision: 0.7994, Recall: 0.7943, F1-Score: 0.7946\n",
      "\n",
      "Modelo: Entropía_Clean_Scaled_Balanced\n",
      "Accuracy: 0.8190, Precision: 0.8156, Recall: 0.8190, F1-Score: 0.8168\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Scaled_Balanced\n",
      "Accuracy: 0.8180, Precision: 0.8149, Recall: 0.8180, F1-Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_8 = data.copy()\n",
    "\n",
    "# 1. Eliminar outliers (IQR)\n",
    "num_cols = data_tree_8.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_tree_8[num_cols].quantile(0.25)\n",
    "Q3 = data_tree_8[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "mask = ~((data_tree_8[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_tree_8[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "data_clean = data_tree_8[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_tree_8.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# 2. Separar X e y\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# Definir el escalador y las columnas numéricas (excluyendo 'Gender')\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = [col for col in X.columns if col not in ['Gender']]\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # 1. Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 2. Aplicar Escalado (fit/transform en train, transform en test)\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "\n",
    "    # 3. Entrenamiento y Predicción de Modelos (con class_weight='balanced')\n",
    "\n",
    "    # --- Modelo 1: Gini + Balanced ---\n",
    "    modelo_gini = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    modelo_gini.fit(X_train_scaled, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 2: Entropía + Balanced ---\n",
    "    modelo_entropy = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    modelo_entropy.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda + Balanced ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=5, # Poda\n",
    "        random_state=seed,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # 4. Calcular métricas\n",
    "    modelos = {\n",
    "        \"Gini_Clean_Scaled_Balanced\": y_pred_gini,\n",
    "        \"Entropía_Clean_Scaled_Balanced\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Clean_Scaled_Balanced\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ae62506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a77f2",
   "metadata": {},
   "source": [
    "# K Vecinos Más Cercanos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec0da7f",
   "metadata": {},
   "source": [
    "#### 1. KNN - CC:SI - ED:NO - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8748d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7365\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.7913\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.7365, Precision: 0.7362, Recall: 0.7365, F1-Score: 0.7362\n",
      "-> Evaluación Manhattan (k=1):\n",
      "Accuracy: 0.7913, Precision: 0.7919, Recall: 0.7913, F1-Score: 0.7916\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7423\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.7981\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.7423, Precision: 0.7452, Recall: 0.7423, F1-Score: 0.7429\n",
      "-> Evaluación Manhattan (k=1):\n",
      "Accuracy: 0.7981, Precision: 0.8021, Recall: 0.7981, F1-Score: 0.7988\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7596\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.8115\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.7596, Precision: 0.7602, Recall: 0.7596, F1-Score: 0.7596\n",
      "-> Evaluación Manhattan (k=1):\n",
      "Accuracy: 0.8115, Precision: 0.8125, Recall: 0.8115, F1-Score: 0.8116\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Preparación de los datos\n",
    "# ================================================================\n",
    "data_knn_1 = data.copy()\n",
    "\n",
    "X = data_knn_1.drop(\"Workout_Type\", axis=1)\n",
    "y = data_knn_1[\"Workout_Type\"]\n",
    "\n",
    "# Definición de la función de evaluación\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Métrica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 🔎 Búsqueda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"🔹 Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"🔹 Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # 🧠 Evaluación final con los K óptimos\n",
    "    print(\"\\n--- Evaluación Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluación Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluación Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "795a5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d2508",
   "metadata": {},
   "source": [
    "#### 2. KNN - CC:SI - ED:NO - Outliers:NO - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111) - Balanced\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7365\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.7913\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1, weights='distance'):\n",
      "Accuracy: 0.7365, Precision: 0.7362, Recall: 0.7365, F1-Score: 0.7362\n",
      "-> Evaluación Manhattan (k=1, weights='distance'):\n",
      "Accuracy: 0.7913, Precision: 0.7919, Recall: 0.7913, F1-Score: 0.7916\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222) - Balanced\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7423\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.7981\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1, weights='distance'):\n",
      "Accuracy: 0.7423, Precision: 0.7452, Recall: 0.7423, F1-Score: 0.7429\n",
      "-> Evaluación Manhattan (k=1, weights='distance'):\n",
      "Accuracy: 0.7981, Precision: 0.8021, Recall: 0.7981, F1-Score: 0.7988\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333) - Balanced\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7596\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.8115\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1, weights='distance'):\n",
      "Accuracy: 0.7596, Precision: 0.7602, Recall: 0.7596, F1-Score: 0.7596\n",
      "-> Evaluación Manhattan (k=1, weights='distance'):\n",
      "Accuracy: 0.8115, Precision: 0.8125, Recall: 0.8115, F1-Score: 0.8116\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Preparación de los datos\n",
    "# ================================================================\n",
    "data_knn_2 = data.copy()\n",
    "\n",
    "X = data_knn_2.drop(\"Workout_Type\", axis=1)\n",
    "y = data_knn_2[\"Workout_Type\"]\n",
    "\n",
    "# Definición de la función de evaluación\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo KNN usando weights='distance'.\"\"\"\n",
    "    # weights='distance' prioriza los vecinos más cercanos, actuando como un balanceo ponderado.\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Métrica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Weights': 'distance',\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed}) - Balanced\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 🧩 Aplicar balanceo SOLO al conjunto de entrenamiento\n",
    "    smote = SMOTE(random_state=seed)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # 🔎 Búsqueda de mejores K para el split actual (usando weights='distance')\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"🔹 Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"🔹 Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # 🧠 Evaluación final con los K óptimos\n",
    "    print(\"\\n--- Evaluación Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluación Euclidiana (k={best_k_euclidean}, weights='distance'):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluación Manhattan (k={best_k_manhattan}, weights='distance'):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04c6fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37249453",
   "metadata": {},
   "source": [
    "#### 3. KNN - CC:SI - ED:NO - Outliers:SI - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f8d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7498\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.7903\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.7498, Precision: 0.7512, Recall: 0.7498, F1-Score: 0.7499\n",
      "-> Evaluación Manhattan (k=1):\n",
      "Accuracy: 0.7903, Precision: 0.7902, Recall: 0.7903, F1-Score: 0.7902\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7626\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.8101\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.7626, Precision: 0.7626, Recall: 0.7626, F1-Score: 0.7621\n",
      "-> Evaluación Manhattan (k=1):\n",
      "Accuracy: 0.8101, Precision: 0.8097, Recall: 0.8101, F1-Score: 0.8096\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7478\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.7903\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.7478, Precision: 0.7475, Recall: 0.7478, F1-Score: 0.7474\n",
      "-> Evaluación Manhattan (k=1):\n",
      "Accuracy: 0.7903, Precision: 0.7904, Recall: 0.7903, F1-Score: 0.7903\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Preparación de los datos\n",
    "# ================================================================\n",
    "data_knn_3 = data.copy()\n",
    "\n",
    "# 1️⃣ Eliminación de outliers (IQR)\n",
    "num_cols = data_knn_1.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_knn_3[num_cols].quantile(0.25)\n",
    "Q3 = data_knn_3[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_knn_3[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_knn_3[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_knn_3[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_knn_3.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# ⚙️ Función de evaluación\n",
    "# ================================================================\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Métrica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 🔎 Búsqueda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"🔹 Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"🔹 Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # 🧠 Evaluación final con los K óptimos\n",
    "    print(\"\\n--- Evaluación Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluación Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluación Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d3976e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7821734",
   "metadata": {},
   "source": [
    "#### 4. KNN - CC:SI - ED:NO - Outliers:SI - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dbbee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7498\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.7903\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.7498, Precision: 0.7512, Recall: 0.7498, F1-Score: 0.7499\n",
      "-> Evaluación Manhattan (k=1):\n",
      "Accuracy: 0.7903, Precision: 0.7902, Recall: 0.7903, F1-Score: 0.7902\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7626\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.8101\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.7626, Precision: 0.7626, Recall: 0.7626, F1-Score: 0.7621\n",
      "-> Evaluación Manhattan (k=1):\n",
      "Accuracy: 0.8101, Precision: 0.8097, Recall: 0.8101, F1-Score: 0.8096\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7478\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.7903\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.7478, Precision: 0.7475, Recall: 0.7478, F1-Score: 0.7474\n",
      "-> Evaluación Manhattan (k=1):\n",
      "Accuracy: 0.7903, Precision: 0.7904, Recall: 0.7903, F1-Score: 0.7903\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Preparación de los datos\n",
    "# ================================================================\n",
    "data_knn_4 = data.copy()\n",
    "\n",
    "# 1️⃣ Eliminación de outliers (IQR)\n",
    "num_cols = data_knn_4.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_knn_4[num_cols].quantile(0.25)\n",
    "Q3 = data_knn_4[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_knn_4[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_knn_4[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_knn_4[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_knn_4.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# ⚙️ Función de evaluación\n",
    "# ================================================================\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Métrica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 🧩 Aplicar balanceo SOLO al conjunto de entrenamiento\n",
    "    smote = SMOTE(random_state=seed)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # 🔎 Búsqueda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"🔹 Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"🔹 Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # 🧠 Evaluación final con los K óptimos\n",
    "    print(\"\\n--- Evaluación Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluación Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluación Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a099a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2c544",
   "metadata": {},
   "source": [
    "#### 5. KNN - CC:SI - ED:SI - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c973a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🟢 MODELO KNN CON NORMALIZACIÓN\n",
      "=================================================\n",
      "\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "🔹 Mejor K (Euclidiana): 65 | Max Acc: 0.5260\n",
      "🔹 Mejor K (Manhattan): 38 | Max Acc: 0.5962\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=65):\n",
      "Accuracy: 0.5260, Precision: 0.5209, Recall: 0.5260, F1-Score: 0.5189\n",
      "-> Evaluación Manhattan (k=38):\n",
      "Accuracy: 0.5962, Precision: 0.5989, Recall: 0.5962, F1-Score: 0.5950\n",
      "\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.5173\n",
      "🔹 Mejor K (Manhattan): 50 | Max Acc: 0.5981\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.5173, Precision: 0.5373, Recall: 0.5173, F1-Score: 0.5242\n",
      "-> Evaluación Manhattan (k=50):\n",
      "Accuracy: 0.5981, Precision: 0.5967, Recall: 0.5981, F1-Score: 0.5958\n",
      "\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "🔹 Mejor K (Euclidiana): 47 | Max Acc: 0.5231\n",
      "🔹 Mejor K (Manhattan): 57 | Max Acc: 0.5981\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=47):\n",
      "Accuracy: 0.5231, Precision: 0.5205, Recall: 0.5231, F1-Score: 0.5200\n",
      "-> Evaluación Manhattan (k=57):\n",
      "Accuracy: 0.5981, Precision: 0.5921, Recall: 0.5981, F1-Score: 0.5927\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Preparación de los datos\n",
    "# ================================================================\n",
    "data_knn_5 = data.copy()\n",
    "\n",
    "X = data_knn_5.drop(\"Workout_Type\", axis=1)\n",
    "y = data_knn_5[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# ⚙️ Función de evaluación\n",
    "# ================================================================\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Métrica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras (CON NORMALIZACIÓN)\n",
    "# ================================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "print(\"\\n=================================================\")\n",
    "print(\"🟢 MODELO KNN CON NORMALIZACIÓN\")\n",
    "print(\"=================================================\")\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    \n",
    "    # División de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Normalización de los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 🔎 Búsqueda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train_scaled, y_train)\n",
    "            y_pred = knn.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"🔹 Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"🔹 Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # 🧠 Evaluación final con los K óptimos\n",
    "    print(\"\\n--- Evaluación Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluación Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluación Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a24f7297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff133c",
   "metadata": {},
   "source": [
    "#### 6. KNN - CC:SI - ED:SI - Outliers:NO - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🟢 MODELO KNN CON NORMALIZACIÓN\n",
      "=================================================\n",
      "\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "🔹 Mejor K (Euclidiana): 83 | Max Acc: 0.6654\n",
      "🔹 Mejor K (Manhattan): 96 | Max Acc: 0.6596\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=83):\n",
      "Accuracy: 0.6654, Precision: 0.6673, Recall: 0.6654, F1-Score: 0.6639\n",
      "-> Evaluación Manhattan (k=96):\n",
      "Accuracy: 0.6596, Precision: 0.6577, Recall: 0.6596, F1-Score: 0.6559\n",
      "\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "🔹 Mejor K (Euclidiana): 75 | Max Acc: 0.6558\n",
      "🔹 Mejor K (Manhattan): 65 | Max Acc: 0.6683\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=75):\n",
      "Accuracy: 0.6558, Precision: 0.6606, Recall: 0.6558, F1-Score: 0.6568\n",
      "-> Evaluación Manhattan (k=65):\n",
      "Accuracy: 0.6683, Precision: 0.6711, Recall: 0.6683, F1-Score: 0.6689\n",
      "\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "🔹 Mejor K (Euclidiana): 52 | Max Acc: 0.6808\n",
      "🔹 Mejor K (Manhattan): 89 | Max Acc: 0.6933\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=52):\n",
      "Accuracy: 0.6808, Precision: 0.6879, Recall: 0.6808, F1-Score: 0.6828\n",
      "-> Evaluación Manhattan (k=89):\n",
      "Accuracy: 0.6933, Precision: 0.6949, Recall: 0.6933, F1-Score: 0.6921\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Preparación de los datos\n",
    "# ================================================================\n",
    "data_knn_6 = data.copy()\n",
    "\n",
    "X = data_knn_6.drop(\"Workout_Type\", axis=1)\n",
    "y = data_knn_6[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# ⚙️ Función de evaluación\n",
    "# ================================================================\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Métrica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras (CON NORMALIZACIÓN)\n",
    "# ================================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "print(\"\\n=================================================\")\n",
    "print(\"🟢 MODELO KNN CON NORMALIZACIÓN\")\n",
    "print(\"=================================================\")\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    \n",
    "    # División de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 🧩 Aplicar balanceo SOLO al conjunto de entrenamiento\n",
    "    smote = SMOTE(random_state=seed)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Normalización de los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 🔎 Búsqueda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train_scaled, y_train)\n",
    "            y_pred = knn.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"🔹 Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"🔹 Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # 🧠 Evaluación final con los K óptimos\n",
    "    print(\"\\n--- Evaluación Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluación Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluación Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c04a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c0fe9",
   "metadata": {},
   "source": [
    "#### 7. KNN - CC:SI - ED:SI - Outliers:SI - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99643951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "🟢 MODELO KNN CON NORMALIZACIÓN\n",
      "=================================================\n",
      "\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "🔹 Mejor K (Euclidiana): 81 | Max Acc: 0.5114\n",
      "🔹 Mejor K (Manhattan): 58 | Max Acc: 0.5816\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=81):\n",
      "Accuracy: 0.5114, Precision: 0.5252, Recall: 0.5114, F1-Score: 0.5071\n",
      "-> Evaluación Manhattan (k=58):\n",
      "Accuracy: 0.5816, Precision: 0.5865, Recall: 0.5816, F1-Score: 0.5788\n",
      "\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.5589\n",
      "🔹 Mejor K (Manhattan): 61 | Max Acc: 0.6261\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.5589, Precision: 0.5733, Recall: 0.5589, F1-Score: 0.5634\n",
      "-> Evaluación Manhattan (k=61):\n",
      "Accuracy: 0.6261, Precision: 0.6353, Recall: 0.6261, F1-Score: 0.6251\n",
      "\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "🔹 Mejor K (Euclidiana): 66 | Max Acc: 0.5302\n",
      "🔹 Mejor K (Manhattan): 55 | Max Acc: 0.6053\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=66):\n",
      "Accuracy: 0.5302, Precision: 0.5349, Recall: 0.5302, F1-Score: 0.5273\n",
      "-> Evaluación Manhattan (k=55):\n",
      "Accuracy: 0.6053, Precision: 0.6088, Recall: 0.6053, F1-Score: 0.6020\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Preparación de los datos\n",
    "# ================================================================\n",
    "data_knn_7 = data.copy()\n",
    "\n",
    "# 1️⃣ Eliminación de outliers (IQR)\n",
    "num_cols = data_knn_7.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_knn_7[num_cols].quantile(0.25)\n",
    "Q3 = data_knn_7[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_knn_7[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_knn_7[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_knn_7[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_knn_7.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# ⚙️ Función de evaluación\n",
    "# ================================================================\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Métrica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras (CON NORMALIZACIÓN)\n",
    "# ================================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "print(\"\\n=================================================\")\n",
    "print(\"🟢 MODELO KNN CON NORMALIZACIÓN\")\n",
    "print(\"=================================================\")\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    \n",
    "    # División de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Normalización de los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 🔎 Búsqueda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train_scaled, y_train)\n",
    "            y_pred = knn.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"🔹 Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"🔹 Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # 🧠 Evaluación final con los K óptimos\n",
    "    print(\"\\n--- Evaluación Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluación Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluación Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47625411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6420d9",
   "metadata": {},
   "source": [
    "#### 8. KNN - CC:SI - ED:SI - Outliers:SI - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc264c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "🟢 MODELO KNN CON NORMALIZACIÓN\n",
      "=================================================\n",
      "\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "🔹 Mejor K (Euclidiana): 75 | Max Acc: 0.6597\n",
      "🔹 Mejor K (Manhattan): 59 | Max Acc: 0.6617\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=75):\n",
      "Accuracy: 0.6597, Precision: 0.6615, Recall: 0.6597, F1-Score: 0.6579\n",
      "-> Evaluación Manhattan (k=59):\n",
      "Accuracy: 0.6617, Precision: 0.6650, Recall: 0.6617, F1-Score: 0.6607\n",
      "\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "🔹 Mejor K (Euclidiana): 89 | Max Acc: 0.6993\n",
      "🔹 Mejor K (Manhattan): 81 | Max Acc: 0.7112\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=89):\n",
      "Accuracy: 0.6993, Precision: 0.7081, Recall: 0.6993, F1-Score: 0.6996\n",
      "-> Evaluación Manhattan (k=81):\n",
      "Accuracy: 0.7112, Precision: 0.7190, Recall: 0.7112, F1-Score: 0.7110\n",
      "\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "🔹 Mejor K (Euclidiana): 89 | Max Acc: 0.6617\n",
      "🔹 Mejor K (Manhattan): 96 | Max Acc: 0.6696\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=89):\n",
      "Accuracy: 0.6617, Precision: 0.6707, Recall: 0.6617, F1-Score: 0.6619\n",
      "-> Evaluación Manhattan (k=96):\n",
      "Accuracy: 0.6696, Precision: 0.6716, Recall: 0.6696, F1-Score: 0.6668\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Preparación de los datos\n",
    "# ================================================================\n",
    "data_knn_8 = data.copy()\n",
    "\n",
    "# 1️⃣ Eliminación de outliers (IQR)\n",
    "num_cols = data_knn_8.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_knn_8[num_cols].quantile(0.25)\n",
    "Q3 = data_knn_8[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_knn_8[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_knn_8[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_knn_8[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_knn_8.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# ⚙️ Función de evaluación\n",
    "# ================================================================\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Métrica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras (CON NORMALIZACIÓN)\n",
    "# ================================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "print(\"\\n=================================================\")\n",
    "print(\"🟢 MODELO KNN CON NORMALIZACIÓN\")\n",
    "print(\"=================================================\")\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    \n",
    "    # División de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 🧩 Aplicar balanceo SOLO al conjunto de entrenamiento\n",
    "    smote = SMOTE(random_state=seed)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Normalización de los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 🔎 Búsqueda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train_scaled, y_train)\n",
    "            y_pred = knn.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"🔹 Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"🔹 Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # 🧠 Evaluación final con los K óptimos\n",
    "    print(\"\\n--- Evaluación Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluación Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluación Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train_scaled, X_test_scaled, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ade277e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f72f1",
   "metadata": {},
   "source": [
    "## Máquinas de Soporte Vectorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed95ff8",
   "metadata": {},
   "source": [
    "#### 1. MSV - CC:SI - ED:NO - Outliers:NO - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55740212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.4673\n",
      "   Precision: 0.3698\n",
      "   Recall:    0.4673\n",
      "   F1-Score:  0.3952\n",
      "\n",
      "🔹 One-vs-One (random_state=111)\n",
      "   Accuracy:  0.4990\n",
      "   Precision: 0.4767\n",
      "   Recall:    0.4990\n",
      "   F1-Score:  0.4767\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.4558\n",
      "   Precision: 0.4063\n",
      "   Recall:    0.4558\n",
      "   F1-Score:  0.3958\n",
      "\n",
      "🔹 One-vs-One (random_state=222)\n",
      "   Accuracy:  0.4808\n",
      "   Precision: 0.4689\n",
      "   Recall:    0.4808\n",
      "   F1-Score:  0.4642\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.4663\n",
      "   Precision: 0.4106\n",
      "   Recall:    0.4663\n",
      "   F1-Score:  0.4007\n",
      "\n",
      "🔹 One-vs-One (random_state=333)\n",
      "   Accuracy:  0.5221\n",
      "   Precision: 0.5103\n",
      "   Recall:    0.5221\n",
      "   F1-Score:  0.4992\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_1 = data.copy()\n",
    "\n",
    "X = data_msv_1.drop(\"Workout_Type\", axis=1)\n",
    "y = data_msv_1[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definición de la función de evaluación\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n🔹 {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-Rest\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train, X_test, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-One\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train, X_test, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ea8390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7106e",
   "metadata": {},
   "source": [
    "#### 2. MSV - CC:SI - ED:NO - Outliers:NO - Balanceo:SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd42c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "⚖️  CASO DE PRUEBA 1 (random_state=111) - MODELOS BALANCEADOS\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=111) [BALANCEADO]\n",
      "   Accuracy:  0.4048\n",
      "   Precision: 0.4287\n",
      "   Recall:    0.4048\n",
      "   F1-Score:  0.3999\n",
      "\n",
      "🔹 One-vs-One (random_state=111) [BALANCEADO]\n",
      "   Accuracy:  0.4856\n",
      "   Precision: 0.4699\n",
      "   Recall:    0.4856\n",
      "   F1-Score:  0.4507\n",
      "\n",
      "=================================================\n",
      "⚖️  CASO DE PRUEBA 2 (random_state=222) - MODELOS BALANCEADOS\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=222) [BALANCEADO]\n",
      "   Accuracy:  0.4221\n",
      "   Precision: 0.4297\n",
      "   Recall:    0.4221\n",
      "   F1-Score:  0.4094\n",
      "\n",
      "🔹 One-vs-One (random_state=222) [BALANCEADO]\n",
      "   Accuracy:  0.4904\n",
      "   Precision: 0.4809\n",
      "   Recall:    0.4904\n",
      "   F1-Score:  0.4728\n",
      "\n",
      "=================================================\n",
      "⚖️  CASO DE PRUEBA 3 (random_state=333) - MODELOS BALANCEADOS\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=333) [BALANCEADO]\n",
      "   Accuracy:  0.4413\n",
      "   Precision: 0.4451\n",
      "   Recall:    0.4413\n",
      "   F1-Score:  0.4318\n",
      "\n",
      "🔹 One-vs-One (random_state=333) [BALANCEADO]\n",
      "   Accuracy:  0.5173\n",
      "   Precision: 0.4932\n",
      "   Recall:    0.5173\n",
      "   F1-Score:  0.4887\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_2 = data.copy()\n",
    "\n",
    "X = data_msv_2.drop(\"Workout_Type\", axis=1)\n",
    "y = data_msv_2[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definición de la función de evaluación\n",
    "# =================================================\n",
    "def evaluar_modelo_svm_balanceado(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo SVM con balanceo de clases.\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n🔹 {tipo_modelo} (random_state={seed}) [BALANCEADO]\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Balanceado': True,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Tres muestras (random states)\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_balanceados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"⚖️  CASO DE PRUEBA {i} (random_state={seed}) - MODELOS BALANCEADOS\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-Rest\n",
    "    resultados_balanceados.append(\n",
    "        evaluar_modelo_svm_balanceado(X_train, X_test, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-One\n",
    "    resultados_balanceados.append(\n",
    "        evaluar_modelo_svm_balanceado(X_train, X_test, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ff26b",
   "metadata": {},
   "source": [
    "#### 3. MSV - CC:SI - ED:NO - Outliers:SI - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db02240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.4253\n",
      "   Precision: 0.3690\n",
      "   Recall:    0.4253\n",
      "   F1-Score:  0.3733\n",
      "\n",
      "🔹 One-vs-One (random_state=111)\n",
      "   Accuracy:  0.4797\n",
      "   Precision: 0.4648\n",
      "   Recall:    0.4797\n",
      "   F1-Score:  0.4595\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.4510\n",
      "   Precision: 0.4147\n",
      "   Recall:    0.4510\n",
      "   F1-Score:  0.3779\n",
      "\n",
      "🔹 One-vs-One (random_state=222)\n",
      "   Accuracy:  0.4758\n",
      "   Precision: 0.4621\n",
      "   Recall:    0.4758\n",
      "   F1-Score:  0.4515\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.3798\n",
      "   Precision: 0.3325\n",
      "   Recall:    0.3798\n",
      "   F1-Score:  0.3068\n",
      "\n",
      "🔹 One-vs-One (random_state=333)\n",
      "   Accuracy:  0.4896\n",
      "   Precision: 0.4720\n",
      "   Recall:    0.4896\n",
      "   F1-Score:  0.4657\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_3 = data.copy()\n",
    "\n",
    "# 1️⃣ Eliminación de outliers (IQR)\n",
    "num_cols = data_msv_3.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_msv_3[num_cols].quantile(0.25)\n",
    "Q3 = data_msv_3[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_msv_3[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_msv_3[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_msv_3[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_msv_3.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definición de la función de evaluación\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n🔹 {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-Rest\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train, X_test, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-One\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train, X_test, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23064b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ab53dc",
   "metadata": {},
   "source": [
    "#### 4. MSV - CC:SI - ED:NO - Outliers:SI - Balanceo:SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58cc8ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.4273\n",
      "   Precision: 0.4255\n",
      "   Recall:    0.4273\n",
      "   F1-Score:  0.4104\n",
      "\n",
      "🔹 One-vs-One (random_state=111)\n",
      "   Accuracy:  0.4955\n",
      "   Precision: 0.4616\n",
      "   Recall:    0.4955\n",
      "   F1-Score:  0.4530\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.4332\n",
      "   Precision: 0.4327\n",
      "   Recall:    0.4332\n",
      "   F1-Score:  0.4214\n",
      "\n",
      "🔹 One-vs-One (random_state=222)\n",
      "   Accuracy:  0.4679\n",
      "   Precision: 0.4405\n",
      "   Recall:    0.4679\n",
      "   F1-Score:  0.4202\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.4263\n",
      "   Precision: 0.4249\n",
      "   Recall:    0.4263\n",
      "   F1-Score:  0.4148\n",
      "\n",
      "🔹 One-vs-One (random_state=333)\n",
      "   Accuracy:  0.4698\n",
      "   Precision: 0.4108\n",
      "   Recall:    0.4698\n",
      "   F1-Score:  0.4025\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_4 = data.copy()\n",
    "\n",
    "# 1️⃣ Eliminación de outliers (IQR)\n",
    "num_cols = data_msv_4.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_msv_4[num_cols].quantile(0.25)\n",
    "Q3 = data_msv_4[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_msv_4[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_msv_4[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_msv_4[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_msv_4.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definición de la función de evaluación\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n🔹 {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-Rest\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train, X_test, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    # Modelo One-vs-One\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train, X_test, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782deb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db7471",
   "metadata": {},
   "source": [
    "#### 5. MSV - CC:SI - ED:SI - Outliers:NO - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3c4ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.6279\n",
      "   Precision: 0.6055\n",
      "   Recall:    0.6279\n",
      "   F1-Score:  0.5646\n",
      "\n",
      "🔹 One-vs-One (random_state=111)\n",
      "   Accuracy:  0.8010\n",
      "   Precision: 0.8054\n",
      "   Recall:    0.8010\n",
      "   F1-Score:  0.8012\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.6327\n",
      "   Precision: 0.6580\n",
      "   Recall:    0.6327\n",
      "   F1-Score:  0.5696\n",
      "\n",
      "🔹 One-vs-One (random_state=222)\n",
      "   Accuracy:  0.8192\n",
      "   Precision: 0.8235\n",
      "   Recall:    0.8192\n",
      "   F1-Score:  0.8190\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.6279\n",
      "   Precision: 0.6340\n",
      "   Recall:    0.6279\n",
      "   F1-Score:  0.5624\n",
      "\n",
      "🔹 One-vs-One (random_state=333)\n",
      "   Accuracy:  0.8135\n",
      "   Precision: 0.8170\n",
      "   Recall:    0.8135\n",
      "   F1-Score:  0.8137\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_5 = data.copy()\n",
    "\n",
    "X = data_msv_5.drop(\"Workout_Type\", axis=1)\n",
    "y = data_msv_5[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definición de la función de evaluación\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n🔹 {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # =================================================\n",
    "    # 🔹 Normalización de los datos\n",
    "    # =================================================\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # =================================================\n",
    "    # Modelos SVM\n",
    "    # =================================================\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1298fc",
   "metadata": {},
   "source": [
    "#### 6. MSV - CC:SI - ED:SI - Outliers:NO - Balanceo:SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b583a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.6529\n",
      "   Precision: 0.7146\n",
      "   Recall:    0.6529\n",
      "   F1-Score:  0.6655\n",
      "\n",
      "🔹 One-vs-One (random_state=111)\n",
      "   Accuracy:  0.7962\n",
      "   Precision: 0.8030\n",
      "   Recall:    0.7962\n",
      "   F1-Score:  0.7968\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.6442\n",
      "   Precision: 0.7122\n",
      "   Recall:    0.6442\n",
      "   F1-Score:  0.6534\n",
      "\n",
      "🔹 One-vs-One (random_state=222)\n",
      "   Accuracy:  0.8173\n",
      "   Precision: 0.8223\n",
      "   Recall:    0.8173\n",
      "   F1-Score:  0.8171\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.6663\n",
      "   Precision: 0.7391\n",
      "   Recall:    0.6663\n",
      "   F1-Score:  0.6776\n",
      "\n",
      "🔹 One-vs-One (random_state=333)\n",
      "   Accuracy:  0.8192\n",
      "   Precision: 0.8255\n",
      "   Recall:    0.8192\n",
      "   F1-Score:  0.8208\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_6 = data.copy()\n",
    "\n",
    "X = data_msv_6.drop(\"Workout_Type\", axis=1)\n",
    "y = data_msv_6[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definición de la función de evaluación\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n🔹 {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # =================================================\n",
    "    # 🔹 Normalización de los datos\n",
    "    # =================================================\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # =================================================\n",
    "    # Modelos SVM\n",
    "    # =================================================\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78cba8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c097b5",
   "metadata": {},
   "source": [
    "#### 7. MSV - CC:SI - ED:SI - Outliers:SI - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a4150d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.6380\n",
      "   Precision: 0.6437\n",
      "   Recall:    0.6380\n",
      "   F1-Score:  0.5819\n",
      "\n",
      "🔹 One-vs-One (random_state=111)\n",
      "   Accuracy:  0.7992\n",
      "   Precision: 0.8035\n",
      "   Recall:    0.7992\n",
      "   F1-Score:  0.7998\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.6320\n",
      "   Precision: 0.6379\n",
      "   Recall:    0.6320\n",
      "   F1-Score:  0.5723\n",
      "\n",
      "🔹 One-vs-One (random_state=222)\n",
      "   Accuracy:  0.8220\n",
      "   Precision: 0.8343\n",
      "   Recall:    0.8220\n",
      "   F1-Score:  0.8237\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.6340\n",
      "   Precision: 0.6220\n",
      "   Recall:    0.6340\n",
      "   F1-Score:  0.5767\n",
      "\n",
      "🔹 One-vs-One (random_state=333)\n",
      "   Accuracy:  0.8140\n",
      "   Precision: 0.8173\n",
      "   Recall:    0.8140\n",
      "   F1-Score:  0.8136\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_7 = data.copy()\n",
    "\n",
    "# 1️⃣ Eliminación de outliers (IQR)\n",
    "num_cols = data_msv_7.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_msv_7[num_cols].quantile(0.25)\n",
    "Q3 = data_msv_7[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_msv_7[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_msv_7[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_msv_7[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_msv_7.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definición de la función de evaluación\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n🔹 {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # =================================================\n",
    "    # 🔹 Normalización de los datos\n",
    "    # =================================================\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # =================================================\n",
    "    # Modelos SVM\n",
    "    # =================================================\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adfca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1490d9f8",
   "metadata": {},
   "source": [
    "#### 8. MSV - CC:SI - ED:SI - Outliers:SI - Balanceo:SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9df7c45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=111)\n",
      "   Accuracy:  0.6538\n",
      "   Precision: 0.7064\n",
      "   Recall:    0.6538\n",
      "   F1-Score:  0.6627\n",
      "\n",
      "🔹 One-vs-One (random_state=111)\n",
      "   Accuracy:  0.8042\n",
      "   Precision: 0.8089\n",
      "   Recall:    0.8042\n",
      "   F1-Score:  0.8034\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=222)\n",
      "   Accuracy:  0.6934\n",
      "   Precision: 0.7506\n",
      "   Recall:    0.6934\n",
      "   F1-Score:  0.7009\n",
      "\n",
      "🔹 One-vs-One (random_state=222)\n",
      "   Accuracy:  0.8497\n",
      "   Precision: 0.8566\n",
      "   Recall:    0.8497\n",
      "   F1-Score:  0.8515\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "\n",
      "🔹 One-vs-Rest (random_state=333)\n",
      "   Accuracy:  0.6864\n",
      "   Precision: 0.7197\n",
      "   Recall:    0.6864\n",
      "   F1-Score:  0.6926\n",
      "\n",
      "🔹 One-vs-One (random_state=333)\n",
      "   Accuracy:  0.8180\n",
      "   Precision: 0.8221\n",
      "   Recall:    0.8180\n",
      "   F1-Score:  0.8158\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_msv_8 = data.copy()\n",
    "\n",
    "# 1️⃣ Eliminación de outliers (IQR)\n",
    "num_cols = data_msv_8.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_msv_8[num_cols].quantile(0.25)\n",
    "Q3 = data_msv_8[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_msv_8[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_msv_8[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_msv_8[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_msv_8.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# Definición de la función de evaluación\n",
    "# =================================================\n",
    "def evaluar_modelo_svm(X_train, X_test, y_train, y_test, tipo_modelo, kernel, C, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo SVM (OVR u OVO).\"\"\"\n",
    "    if tipo_modelo == \"One-vs-Rest\":\n",
    "        clf = OneVsRestClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    else:\n",
    "        clf = OneVsOneClassifier(SVC(kernel=kernel, C=C, class_weight='balanced'))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n🔹 {tipo_modelo} (random_state={seed})\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Kernel': kernel,\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Tres muestras\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # =================================================\n",
    "    # 🔹 Normalización de los datos\n",
    "    # =================================================\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # =================================================\n",
    "    # Modelos SVM\n",
    "    # =================================================\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-Rest\", \"rbf\", 0.3, seed)\n",
    "    )\n",
    "\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo_svm(X_train_scaled, X_test_scaled, y_train, y_test, \"One-vs-One\", \"rbf\", 0.3, seed)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba7b6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de MSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b59172",
   "metadata": {},
   "source": [
    "## Redes Neuronales: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587065b7",
   "metadata": {},
   "source": [
    "#### 1. RN - CC:SI - ED:NO - Outliers:NO - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14b4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=111)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=222)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=333)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "📊 RESULTADOS DE TODOS LOS MODELOS:\n",
      " Random State Optimizador Activación  Accuracy  Precision   Recall  F1-Score\n",
      "          111        adam       relu  0.792308   0.811919 0.792308  0.788407\n",
      "          111        adam       tanh  0.464744   0.360998 0.464744  0.405303\n",
      "          111        adam    sigmoid  0.484615   0.479231 0.484615  0.425242\n",
      "          111         sgd       relu  0.252564   0.063789 0.252564  0.101853\n",
      "          111         sgd       tanh  0.258333   0.066736 0.258333  0.106071\n",
      "          111         sgd    sigmoid  0.258333   0.066736 0.258333  0.106071\n",
      "          222        adam       relu  0.419231   0.414253 0.419231  0.396269\n",
      "          222        adam       tanh  0.472436   0.434966 0.472436  0.413216\n",
      "          222        adam    sigmoid  0.482051   0.556015 0.482051  0.419025\n",
      "          222         sgd       relu  0.258333   0.066736 0.258333  0.106071\n",
      "          222         sgd       tanh  0.251923   0.063465 0.251923  0.101388\n",
      "          222         sgd    sigmoid  0.258333   0.066736 0.258333  0.106071\n",
      "          333        adam       relu  0.466026   0.374463 0.466026  0.395051\n",
      "          333        adam       tanh  0.496795   0.476148 0.496795  0.478439\n",
      "          333        adam    sigmoid  0.496795   0.430872 0.496795  0.428929\n",
      "          333         sgd       relu  0.258333   0.066736 0.258333  0.106071\n",
      "          333         sgd       tanh  0.251923   0.063465 0.251923  0.101388\n",
      "          333         sgd    sigmoid  0.258333   0.066736 0.258333  0.106071\n",
      "\n",
      "🏆 MEJOR MODELO ENCONTRADO:\n",
      " Random State Optimizador Activación  Accuracy  Precision   Recall  F1-Score\n",
      "          111        adam       relu  0.792308   0.811919 0.792308  0.788407\n",
      "\n",
      "📐 ARQUITECTURA DEL MEJOR MODELO:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_42\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_42\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_126 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_127 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_128 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,046</span> (4.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,046\u001b[0m (4.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">348</span> (1.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m348\u001b[0m (1.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">698</span> (2.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m698\u001b[0m (2.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================================================\n",
    "# 🧠 Copia de los datos\n",
    "# =================================================\n",
    "data_rn_1 = data.copy()\n",
    "\n",
    "X = data_rn_1.drop(\"Workout_Type\", axis=1)\n",
    "y = data_rn_1[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# ⚙️ Función para entrenar y evaluar una red neuronal\n",
    "# =================================================\n",
    "def evaluar_red_neuronal(X_train, X_test, y_train, y_test, optimizer_name, activation_hidden, seed):\n",
    "    \"\"\"Entrena y evalúa una red neuronal con distintos optimizadores y activaciones, usando Early Stopping.\"\"\"\n",
    "    \n",
    "    # Seleccionar optimizador\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizador no soportado.\")\n",
    "\n",
    "    # Crear modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(16, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(8, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compilar modelo\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Entrenar modelo\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Optimizador': optimizer_name,\n",
    "        'Activación': activation_hidden,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Modelo': model\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Configuración de experimentos\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "optimizadores = ['adam', 'sgd']\n",
    "activaciones = ['relu', 'tanh', 'sigmoid']\n",
    "resultados_totales = []\n",
    "\n",
    "# =================================================\n",
    "# 🚀 Pruebas con todas las combinaciones\n",
    "# =================================================\n",
    "for seed in random_states:\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧩 CASO DE PRUEBA (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    for opt in optimizadores:\n",
    "        for act in activaciones:\n",
    "            print(f\"🔹 Entrenando con Optimizador={opt}, Activación={act}...\")\n",
    "            resultados_totales.append(\n",
    "                evaluar_red_neuronal(X_train, X_test, y_train, y_test, opt, act, seed)\n",
    "            )\n",
    "\n",
    "# =================================================\n",
    "# 📊 Resultados finales\n",
    "# =================================================\n",
    "# Crear DataFrame SIN la columna 'Modelo' (para imprimir bien)\n",
    "resultados_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'Modelo'} for r in resultados_totales])\n",
    "\n",
    "# Buscar el mejor modelo según F1-Score\n",
    "mejor_fila = max(resultados_totales, key=lambda x: x['F1-Score'])\n",
    "mejor_modelo = mejor_fila['Modelo']\n",
    "\n",
    "print(\"\\n📊 RESULTADOS DE TODOS LOS MODELOS:\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n🏆 MEJOR MODELO ENCONTRADO:\")\n",
    "print(pd.DataFrame([mejor_fila]).drop(columns=['Modelo']).to_string(index=False))\n",
    "\n",
    "print(\"\\n📐 ARQUITECTURA DEL MEJOR MODELO:\")\n",
    "mejor_modelo.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7172d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e228ff",
   "metadata": {},
   "source": [
    "#### 2. RN - CC:SI - ED:NO - Outliers:NO - Balanceo:SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8171c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=111)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=222)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=333)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "Pesos de clase: {np.int64(0): np.float64(1.0556844547563806), np.int64(1): np.float64(0.988056460369164), np.int64(2): np.float64(0.9934497816593887), np.int64(3): np.float64(0.9670563230605739)}\n",
      "\n",
      "📊 RESULTADOS DE TODOS LOS MODELOS:\n",
      " Random State Optimizador Activación  Accuracy  Precision   Recall  F1-Score\n",
      "          111        adam       relu  0.404487   0.531187 0.404487  0.383998\n",
      "          111        adam       tanh  0.475000   0.434972 0.475000  0.404605\n",
      "          111        adam    sigmoid  0.476923   0.475662 0.476923  0.415949\n",
      "          111         sgd       relu  0.252564   0.063789 0.252564  0.101853\n",
      "          111         sgd       tanh  0.258333   0.066736 0.258333  0.106071\n",
      "          111         sgd    sigmoid  0.252564   0.063789 0.252564  0.101853\n",
      "          222        adam       relu  0.294231   0.481489 0.294231  0.202051\n",
      "          222        adam       tanh  0.489744   0.422991 0.489744  0.426818\n",
      "          222        adam    sigmoid  0.475641   0.430047 0.475641  0.415896\n",
      "          222         sgd       relu  0.258333   0.066736 0.258333  0.106071\n",
      "          222         sgd       tanh  0.237179   0.056254 0.237179  0.090939\n",
      "          222         sgd    sigmoid  0.251923   0.063465 0.251923  0.101388\n",
      "          333        adam       relu  0.475641   0.551775 0.475641  0.399550\n",
      "          333        adam       tanh  0.432051   0.269173 0.432051  0.295201\n",
      "          333        adam    sigmoid  0.422436   0.290220 0.422436  0.294137\n",
      "          333         sgd       relu  0.252564   0.063789 0.252564  0.101853\n",
      "          333         sgd       tanh  0.258333   0.066736 0.258333  0.106071\n",
      "          333         sgd    sigmoid  0.258333   0.066736 0.258333  0.106071\n",
      "\n",
      "🏆 MEJOR MODELO ENCONTRADO:\n",
      " Random State Optimizador Activación  Accuracy  Precision   Recall  F1-Score\n",
      "          222        adam       tanh  0.489744   0.422991 0.489744  0.426818\n",
      "\n",
      "📐 ARQUITECTURA DEL MEJOR MODELO:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,046</span> (4.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,046\u001b[0m (4.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">348</span> (1.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m348\u001b[0m (1.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">698</span> (2.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m698\u001b[0m (2.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================================================\n",
    "# 🧠 Copia de los datos\n",
    "# =================================================\n",
    "data_rn_2 = data.copy()\n",
    "\n",
    "X = data_rn_2.drop(\"Workout_Type\", axis=1)\n",
    "y = data_rn_2[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# ⚙️ Función para entrenar y evaluar una red neuronal\n",
    "# =================================================\n",
    "def evaluar_red_neuronal(X_train, X_test, y_train, y_test, optimizer_name, activation_hidden, seed):\n",
    "    \"\"\"Entrena y evalúa una red neuronal con distintos optimizadores y activaciones, usando Early Stopping.\"\"\"\n",
    "    \n",
    "    # Seleccionar optimizador\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizador no soportado.\")\n",
    "\n",
    "    # Crear modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(16, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(8, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compilar modelo\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Calcular pesos de clase automáticamente\n",
    "    clases = np.unique(y_train)\n",
    "    pesos = compute_class_weight('balanced', classes=clases, y=y_train)\n",
    "    class_weights = dict(zip(clases, pesos))\n",
    "\n",
    "    # Entrenar el modelo con pesos\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop],\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Optimizador': optimizer_name,\n",
    "        'Activación': activation_hidden,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Modelo': model\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Configuración de experimentos\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "optimizadores = ['adam', 'sgd']\n",
    "activaciones = ['relu', 'tanh', 'sigmoid']\n",
    "resultados_totales = []\n",
    "\n",
    "# =================================================\n",
    "# 🚀 Pruebas con todas las combinaciones\n",
    "# =================================================\n",
    "for seed in random_states:\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧩 CASO DE PRUEBA (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    for opt in optimizadores:\n",
    "        for act in activaciones:\n",
    "            print(f\"🔹 Entrenando con Optimizador={opt}, Activación={act}...\")\n",
    "            resultados_totales.append(\n",
    "                evaluar_red_neuronal(X_train, X_test, y_train, y_test, opt, act, seed)\n",
    "            )\n",
    "\n",
    "# =================================================\n",
    "# 📊 Resultados finales\n",
    "# =================================================\n",
    "# Crear DataFrame SIN la columna 'Modelo' (para imprimir bien)\n",
    "resultados_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'Modelo'} for r in resultados_totales])\n",
    "\n",
    "# Buscar el mejor modelo según F1-Score\n",
    "mejor_fila = max(resultados_totales, key=lambda x: x['F1-Score'])\n",
    "mejor_modelo = mejor_fila['Modelo']\n",
    "\n",
    "print(\"\\n📊 RESULTADOS DE TODOS LOS MODELOS:\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n🏆 MEJOR MODELO ENCONTRADO:\")\n",
    "print(pd.DataFrame([mejor_fila]).drop(columns=['Modelo']).to_string(index=False))\n",
    "\n",
    "print(\"\\n📐 ARQUITECTURA DEL MEJOR MODELO:\")\n",
    "mejor_modelo.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9b332",
   "metadata": {},
   "source": [
    "#### 3. RN - CC:SI - ED:NO - Outliers:SI - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20da9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=111)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=222)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_rn_3 = data.copy()\n",
    "\n",
    "# 1️⃣ Eliminación de outliers (IQR)\n",
    "num_cols = data_rn_3.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_rn_3[num_cols].quantile(0.25)\n",
    "Q3 = data_rn_3[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_rn_3[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_rn_3[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_rn_3[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_rn_3.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# ⚙️ Función para entrenar y evaluar una red neuronal\n",
    "# =================================================\n",
    "def evaluar_red_neuronal(X_train, X_test, y_train, y_test, optimizer_name, activation_hidden, seed):\n",
    "    \"\"\"Entrena y evalúa una red neuronal con distintos optimizadores y activaciones, usando Early Stopping.\"\"\"\n",
    "    \n",
    "    # Seleccionar optimizador\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizador no soportado.\")\n",
    "\n",
    "    # Crear modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(16, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(8, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compilar modelo\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Entrenar modelo\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Optimizador': optimizer_name,\n",
    "        'Activación': activation_hidden,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Modelo': model\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Configuración de experimentos\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "optimizadores = ['adam', 'sgd']\n",
    "activaciones = ['relu', 'tanh', 'sigmoid']\n",
    "resultados_totales = []\n",
    "\n",
    "# =================================================\n",
    "# 🚀 Pruebas con todas las combinaciones\n",
    "# =================================================\n",
    "for seed in random_states:\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧩 CASO DE PRUEBA (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    for opt in optimizadores:\n",
    "        for act in activaciones:\n",
    "            print(f\"🔹 Entrenando con Optimizador={opt}, Activación={act}...\")\n",
    "            resultados_totales.append(\n",
    "                evaluar_red_neuronal(X_train, X_test, y_train, y_test, opt, act, seed)\n",
    "            )\n",
    "\n",
    "# =================================================\n",
    "# 📊 Resultados finales\n",
    "# =================================================\n",
    "# Crear DataFrame SIN la columna 'Modelo' (para imprimir bien)\n",
    "resultados_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'Modelo'} for r in resultados_totales])\n",
    "\n",
    "# Buscar el mejor modelo según F1-Score\n",
    "mejor_fila = max(resultados_totales, key=lambda x: x['F1-Score'])\n",
    "mejor_modelo = mejor_fila['Modelo']\n",
    "\n",
    "print(\"\\n📊 RESULTADOS DE TODOS LOS MODELOS:\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n🏆 MEJOR MODELO ENCONTRADO:\")\n",
    "print(pd.DataFrame([mejor_fila]).drop(columns=['Modelo']).to_string(index=False))\n",
    "\n",
    "print(\"\\n📐 ARQUITECTURA DEL MEJOR MODELO:\")\n",
    "mejor_modelo.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d2160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbaf166",
   "metadata": {},
   "source": [
    "#### 4. RN - CC:SI - ED:NO - Outliers:SI - Balanceo:SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647375d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=111)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=222)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=333)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "📊 RESULTADOS DE TODOS LOS MODELOS:\n",
      " Random State Optimizador Activación  Accuracy  Precision   Recall  F1-Score\n",
      "          111        adam       relu  0.260382   0.260305 0.260382  0.135434\n",
      "          111        adam       tanh  0.412657   0.350111 0.412657  0.291926\n",
      "          111        adam    sigmoid  0.472643   0.470615 0.472643  0.409539\n",
      "          111         sgd       relu  0.264338   0.069874 0.264338  0.110531\n",
      "          111         sgd       tanh  0.257746   0.066433 0.257746  0.105638\n",
      "          111         sgd    sigmoid  0.264338   0.069874 0.264338  0.110531\n",
      "          222        adam       relu  0.456823   0.405415 0.456823  0.414776\n",
      "          222        adam       tanh  0.400791   0.271534 0.400791  0.274230\n",
      "          222        adam    sigmoid  0.264338   0.069874 0.264338  0.110531\n",
      "          222         sgd       relu  0.264338   0.069874 0.264338  0.110531\n",
      "          222         sgd       tanh  0.264338   0.069874 0.264338  0.110531\n",
      "          222         sgd    sigmoid  0.264338   0.069874 0.264338  0.110531\n",
      "          333        adam       relu  0.463415   0.546040 0.463415  0.459454\n",
      "          333        adam       tanh  0.413316   0.348735 0.413316  0.282717\n",
      "          333        adam    sigmoid  0.472643   0.429853 0.472643  0.407816\n",
      "          333         sgd       relu  0.257746   0.066433 0.257746  0.105638\n",
      "          333         sgd       tanh  0.264338   0.069874 0.264338  0.110531\n",
      "          333         sgd    sigmoid  0.264338   0.069874 0.264338  0.110531\n",
      "\n",
      "🏆 MEJOR MODELO ENCONTRADO:\n",
      " Random State Optimizador Activación  Accuracy  Precision   Recall  F1-Score\n",
      "          333        adam       relu  0.463415    0.54604 0.463415  0.459454\n",
      "\n",
      "📐 ARQUITECTURA DEL MEJOR MODELO:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,046</span> (4.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,046\u001b[0m (4.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">348</span> (1.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m348\u001b[0m (1.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">698</span> (2.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m698\u001b[0m (2.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_rn_4 = data.copy()\n",
    "\n",
    "# 1️⃣ Eliminación de outliers (IQR)\n",
    "num_cols = data_rn_4.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_rn_4[num_cols].quantile(0.25)\n",
    "Q3 = data_rn_4[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_rn_4[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_rn_4[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_rn_4[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_rn_4.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# ⚙️ Función para entrenar y evaluar una red neuronal\n",
    "# =================================================\n",
    "def evaluar_red_neuronal(X_train, X_test, y_train, y_test, optimizer_name, activation_hidden, seed):\n",
    "    \"\"\"Entrena y evalúa una red neuronal con distintos optimizadores y activaciones, usando Early Stopping.\"\"\"\n",
    "    \n",
    "    # Seleccionar optimizador\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizador no soportado.\")\n",
    "\n",
    "    # Crear modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(16, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(8, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compilar modelo\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Calcular pesos de clase automáticamente\n",
    "    clases = np.unique(y_train)\n",
    "    pesos = compute_class_weight('balanced', classes=clases, y=y_train)\n",
    "    class_weights = dict(zip(clases, pesos))\n",
    "\n",
    "    # Entrenar el modelo con pesos\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop],\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Optimizador': optimizer_name,\n",
    "        'Activación': activation_hidden,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Modelo': model\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Configuración de experimentos\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "optimizadores = ['adam', 'sgd']\n",
    "activaciones = ['relu', 'tanh', 'sigmoid']\n",
    "resultados_totales = []\n",
    "\n",
    "# =================================================\n",
    "# 🚀 Pruebas con todas las combinaciones\n",
    "# =================================================\n",
    "for seed in random_states:\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧩 CASO DE PRUEBA (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    for opt in optimizadores:\n",
    "        for act in activaciones:\n",
    "            print(f\"🔹 Entrenando con Optimizador={opt}, Activación={act}...\")\n",
    "            resultados_totales.append(\n",
    "                evaluar_red_neuronal(X_train, X_test, y_train, y_test, opt, act, seed)\n",
    "            )\n",
    "\n",
    "# =================================================\n",
    "# 📊 Resultados finales\n",
    "# =================================================\n",
    "# Crear DataFrame SIN la columna 'Modelo' (para imprimir bien)\n",
    "resultados_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'Modelo'} for r in resultados_totales])\n",
    "\n",
    "# Buscar el mejor modelo según F1-Score\n",
    "mejor_fila = max(resultados_totales, key=lambda x: x['F1-Score'])\n",
    "mejor_modelo = mejor_fila['Modelo']\n",
    "\n",
    "print(\"\\n📊 RESULTADOS DE TODOS LOS MODELOS:\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n🏆 MEJOR MODELO ENCONTRADO:\")\n",
    "print(pd.DataFrame([mejor_fila]).drop(columns=['Modelo']).to_string(index=False))\n",
    "\n",
    "print(\"\\n📐 ARQUITECTURA DEL MEJOR MODELO:\")\n",
    "mejor_modelo.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f474f4cc",
   "metadata": {},
   "source": [
    "#### 5. RN - CC:SI - ED:SI - Outliers:NO - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5898959d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=111)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=222)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=333)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "📊 RESULTADOS DE TODOS LOS MODELOS:\n",
      " Random State Optimizador Activación  Accuracy  Precision   Recall  F1-Score\n",
      "          111        adam       relu  0.998077   0.998091 0.998077  0.998077\n",
      "          111        adam       tanh  0.995513   0.995514 0.995513  0.995513\n",
      "          111        adam    sigmoid  0.992308   0.992331 0.992308  0.992306\n",
      "          111         sgd       relu  1.000000   1.000000 1.000000  1.000000\n",
      "          111         sgd       tanh  0.996795   0.996797 0.996795  0.996795\n",
      "          111         sgd    sigmoid  0.994872   0.994879 0.994872  0.994872\n",
      "          222        adam       relu  0.993590   0.993618 0.993590  0.993591\n",
      "          222        adam       tanh  0.998718   0.998725 0.998718  0.998718\n",
      "          222        adam    sigmoid  0.988462   0.988525 0.988462  0.988464\n",
      "          222         sgd       relu  0.990385   0.990522 0.990385  0.990387\n",
      "          222         sgd       tanh  0.997436   0.997443 0.997436  0.997436\n",
      "          222         sgd    sigmoid  0.992308   0.992315 0.992308  0.992308\n",
      "          333        adam       relu  0.991667   0.991669 0.991667  0.991667\n",
      "          333        adam       tanh  0.994872   0.994879 0.994872  0.994872\n",
      "          333        adam    sigmoid  0.992308   0.992336 0.992308  0.992309\n",
      "          333         sgd       relu  0.993590   0.993597 0.993590  0.993590\n",
      "          333         sgd       tanh  0.998077   0.998079 0.998077  0.998077\n",
      "          333         sgd    sigmoid  0.994872   0.994900 0.994872  0.994872\n",
      "\n",
      "🏆 MEJOR MODELO ENCONTRADO:\n",
      " Random State Optimizador Activación  Accuracy  Precision  Recall  F1-Score\n",
      "          111         sgd       relu       1.0        1.0     1.0       1.0\n",
      "\n",
      "📐 ARQUITECTURA DEL MEJOR MODELO:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_65 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">698</span> (2.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m698\u001b[0m (2.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">348</span> (1.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m348\u001b[0m (1.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">350</span> (1.37 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m350\u001b[0m (1.37 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================================================\n",
    "# 🧠 Copia de los datos\n",
    "# =================================================\n",
    "data_rn_5 = data.copy()\n",
    "\n",
    "X = data_rn_5.drop(\"Workout_Type\", axis=1)\n",
    "y = data_rn_5[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# ⚙️ Función para entrenar y evaluar una red neuronal\n",
    "# =================================================\n",
    "def evaluar_red_neuronal(X_train, X_test, y_train, y_test, optimizer_name, activation_hidden, seed):\n",
    "    \"\"\"Entrena y evalúa una red neuronal con distintos optimizadores y activaciones, usando Early Stopping.\"\"\"\n",
    "    \n",
    "    # ============================\n",
    "    # Normalización de los datos\n",
    "    # ============================\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Seleccionar optimizador\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizador no soportado.\")\n",
    "\n",
    "    # Crear modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(16, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(8, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compilar modelo\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Entrenar modelo\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Optimizador': optimizer_name,\n",
    "        'Activación': activation_hidden,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Modelo': model\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Configuración de experimentos\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "optimizadores = ['adam', 'sgd']\n",
    "activaciones = ['relu', 'tanh', 'sigmoid']\n",
    "resultados_totales = []\n",
    "\n",
    "# =================================================\n",
    "# 🚀 Pruebas con todas las combinaciones\n",
    "# =================================================\n",
    "for seed in random_states:\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧩 CASO DE PRUEBA (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    for opt in optimizadores:\n",
    "        for act in activaciones:\n",
    "            print(f\"🔹 Entrenando con Optimizador={opt}, Activación={act}...\")\n",
    "            resultados_totales.append(\n",
    "                evaluar_red_neuronal(X_train, X_test, y_train, y_test, opt, act, seed)\n",
    "            )\n",
    "\n",
    "# =================================================\n",
    "# 📊 Resultados finales\n",
    "# =================================================\n",
    "resultados_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'Modelo'} for r in resultados_totales])\n",
    "\n",
    "# Buscar el mejor modelo según F1-Score\n",
    "mejor_fila = max(resultados_totales, key=lambda x: x['F1-Score'])\n",
    "mejor_modelo = mejor_fila['Modelo']\n",
    "\n",
    "print(\"\\n📊 RESULTADOS DE TODOS LOS MODELOS:\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n🏆 MEJOR MODELO ENCONTRADO:\")\n",
    "print(pd.DataFrame([mejor_fila]).drop(columns=['Modelo']).to_string(index=False))\n",
    "\n",
    "print(\"\\n📐 ARQUITECTURA DEL MEJOR MODELO:\")\n",
    "mejor_modelo.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2ef48",
   "metadata": {},
   "source": [
    "#### 6. RN - CC:SI - ED:SI - Outliers:NO - Balanceo:SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa25ec36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=111)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=222)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=333)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "📊 RESULTADOS DE TODOS LOS MODELOS:\n",
      " Random State Optimizador Activación  Accuracy  Precision   Recall  F1-Score\n",
      "          111        adam       relu  0.997436   0.997436 0.997436  0.997436\n",
      "          111        adam       tanh  0.996795   0.996797 0.996795  0.996795\n",
      "          111        adam    sigmoid  0.991026   0.991031 0.991026  0.991025\n",
      "          111         sgd       relu  0.996795   0.996809 0.996795  0.996794\n",
      "          111         sgd       tanh  0.991667   0.991870 0.991667  0.991669\n",
      "          111         sgd    sigmoid  0.992949   0.992965 0.992949  0.992949\n",
      "          222        adam       relu  0.991667   0.991683 0.991667  0.991668\n",
      "          222        adam       tanh  0.992308   0.992336 0.992308  0.992309\n",
      "          222        adam    sigmoid  0.990385   0.990429 0.990385  0.990386\n",
      "          222         sgd       relu  0.992308   0.992308 0.992308  0.992308\n",
      "          222         sgd       tanh  0.995513   0.995515 0.995513  0.995513\n",
      "          222         sgd    sigmoid  0.992308   0.992336 0.992308  0.992309\n",
      "          333        adam       relu  0.998077   0.998079 0.998077  0.998077\n",
      "          333        adam       tanh  0.998718   0.998720 0.998718  0.998718\n",
      "          333        adam    sigmoid  0.989744   0.989773 0.989744  0.989745\n",
      "          333         sgd       relu  0.992949   0.992951 0.992949  0.992949\n",
      "          333         sgd       tanh  0.998718   0.998718 0.998718  0.998718\n",
      "          333         sgd    sigmoid  0.993590   0.993618 0.993590  0.993591\n",
      "\n",
      "🏆 MEJOR MODELO ENCONTRADO:\n",
      " Random State Optimizador Activación  Accuracy  Precision   Recall  F1-Score\n",
      "          333         sgd       tanh  0.998718   0.998718 0.998718  0.998718\n",
      "\n",
      "📐 ARQUITECTURA DEL MEJOR MODELO:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_52\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_52\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_156 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_157 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_158 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">698</span> (2.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m698\u001b[0m (2.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">348</span> (1.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m348\u001b[0m (1.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">350</span> (1.37 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m350\u001b[0m (1.37 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================================================\n",
    "# 🧠 Copia de los datos\n",
    "# =================================================\n",
    "data_rn_6 = data.copy()\n",
    "\n",
    "X = data_rn_6.drop(\"Workout_Type\", axis=1)\n",
    "y = data_rn_6[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# ⚙️ Función para entrenar y evaluar una red neuronal\n",
    "# =================================================\n",
    "def evaluar_red_neuronal(X_train, X_test, y_train, y_test, optimizer_name, activation_hidden, seed):\n",
    "    \"\"\"Entrena y evalúa una red neuronal con distintos optimizadores y activaciones, usando Early Stopping.\"\"\"\n",
    "    \n",
    "    # ============================\n",
    "    # Normalización de los datos\n",
    "    # ============================\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Seleccionar optimizador\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizador no soportado.\")\n",
    "\n",
    "    # Crear modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(16, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(8, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compilar modelo\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Calcular pesos de clase automáticamente\n",
    "    clases = np.unique(y_train)\n",
    "    pesos = compute_class_weight('balanced', classes=clases, y=y_train)\n",
    "    class_weights = dict(zip(clases, pesos))\n",
    "\n",
    "    # Entrenar el modelo con pesos\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop],\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Optimizador': optimizer_name,\n",
    "        'Activación': activation_hidden,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Modelo': model\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Configuración de experimentos\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "optimizadores = ['adam', 'sgd']\n",
    "activaciones = ['relu', 'tanh', 'sigmoid']\n",
    "resultados_totales = []\n",
    "\n",
    "# =================================================\n",
    "# 🚀 Pruebas con todas las combinaciones\n",
    "# =================================================\n",
    "for seed in random_states:\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧩 CASO DE PRUEBA (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    for opt in optimizadores:\n",
    "        for act in activaciones:\n",
    "            print(f\"🔹 Entrenando con Optimizador={opt}, Activación={act}...\")\n",
    "            resultados_totales.append(\n",
    "                evaluar_red_neuronal(X_train, X_test, y_train, y_test, opt, act, seed)\n",
    "            )\n",
    "\n",
    "# =================================================\n",
    "# 📊 Resultados finales\n",
    "# =================================================\n",
    "resultados_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'Modelo'} for r in resultados_totales])\n",
    "\n",
    "# Buscar el mejor modelo según F1-Score\n",
    "mejor_fila = max(resultados_totales, key=lambda x: x['F1-Score'])\n",
    "mejor_modelo = mejor_fila['Modelo']\n",
    "\n",
    "print(\"\\n📊 RESULTADOS DE TODOS LOS MODELOS:\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n🏆 MEJOR MODELO ENCONTRADO:\")\n",
    "print(pd.DataFrame([mejor_fila]).drop(columns=['Modelo']).to_string(index=False))\n",
    "\n",
    "print(\"\\n📐 ARQUITECTURA DEL MEJOR MODELO:\")\n",
    "mejor_modelo.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c4a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f08da57",
   "metadata": {},
   "source": [
    "#### 7. RN - CC:SI - ED:SI - Outliers:SI - Balanceo:NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106923aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_rn_7 = data.copy()\n",
    "\n",
    "# 1️⃣ Eliminación de outliers (IQR)\n",
    "num_cols = data_rn_7.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_rn_7[num_cols].quantile(0.25)\n",
    "Q3 = data_rn_7[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_rn_7[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_rn_7[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_rn_7[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_rn_7.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# ⚙️ Función para entrenar y evaluar una red neuronal\n",
    "# =================================================\n",
    "def evaluar_red_neuronal(X_train, X_test, y_train, y_test, optimizer_name, activation_hidden, seed):\n",
    "    \"\"\"Entrena y evalúa una red neuronal con distintos optimizadores y activaciones, usando Early Stopping.\"\"\"\n",
    "    \n",
    "    # ============================\n",
    "    # Normalización de los datos\n",
    "    # ============================\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Seleccionar optimizador\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizador no soportado.\")\n",
    "\n",
    "    # Crear modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(16, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(8, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compilar modelo\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Entrenar modelo\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Optimizador': optimizer_name,\n",
    "        'Activación': activation_hidden,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Modelo': model\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Configuración de experimentos\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "optimizadores = ['adam', 'sgd']\n",
    "activaciones = ['relu', 'tanh', 'sigmoid']\n",
    "resultados_totales = []\n",
    "\n",
    "# =================================================\n",
    "# 🚀 Pruebas con todas las combinaciones\n",
    "# =================================================\n",
    "for seed in random_states:\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧩 CASO DE PRUEBA (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    for opt in optimizadores:\n",
    "        for act in activaciones:\n",
    "            print(f\"🔹 Entrenando con Optimizador={opt}, Activación={act}...\")\n",
    "            resultados_totales.append(\n",
    "                evaluar_red_neuronal(X_train, X_test, y_train, y_test, opt, act, seed)\n",
    "            )\n",
    "\n",
    "# =================================================\n",
    "# 📊 Resultados finales\n",
    "# =================================================\n",
    "resultados_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'Modelo'} for r in resultados_totales])\n",
    "\n",
    "# Buscar el mejor modelo según F1-Score\n",
    "mejor_fila = max(resultados_totales, key=lambda x: x['F1-Score'])\n",
    "mejor_modelo = mejor_fila['Modelo']\n",
    "\n",
    "print(\"\\n📊 RESULTADOS DE TODOS LOS MODELOS:\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n🏆 MEJOR MODELO ENCONTRADO:\")\n",
    "print(pd.DataFrame([mejor_fila]).drop(columns=['Modelo']).to_string(index=False))\n",
    "\n",
    "print(\"\\n📐 ARQUITECTURA DEL MEJOR MODELO:\")\n",
    "mejor_modelo.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1be234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb752b4",
   "metadata": {},
   "source": [
    "#### 8. RN - CC:SI - ED:SI - Outliers:SI - Balanceo:SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1cf8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=111)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=222)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "=================================================\n",
      "🧩 CASO DE PRUEBA (random_state=333)\n",
      "=================================================\n",
      "🔹 Entrenando con Optimizador=adam, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=adam, Activación=sigmoid...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=relu...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=tanh...\n",
      "🔹 Entrenando con Optimizador=sgd, Activación=sigmoid...\n",
      "\n",
      "📊 RESULTADOS DE TODOS LOS MODELOS:\n",
      " Random State Optimizador Activación  Accuracy  Precision   Recall  F1-Score\n",
      "          111        adam       relu  0.984838   0.985275 0.984838  0.984826\n",
      "          111        adam       tanh  0.957152   0.959999 0.957152  0.957094\n",
      "          111        adam    sigmoid  0.958471   0.964569 0.958471  0.958297\n",
      "          111         sgd       relu  0.957811   0.961361 0.957811  0.957533\n",
      "          111         sgd       tanh  0.949901   0.950805 0.949901  0.949880\n",
      "          111         sgd    sigmoid  0.960448   0.964022 0.960448  0.960372\n",
      "          222        adam       relu  0.979565   0.980964 0.979565  0.979561\n",
      "          222        adam       tanh  0.959789   0.962160 0.959789  0.959751\n",
      "          222        adam    sigmoid  0.957811   0.964091 0.957811  0.957627\n",
      "          222         sgd       relu  0.987475   0.987461 0.987475  0.987462\n",
      "          222         sgd       tanh  0.937376   0.939131 0.937376  0.937201\n",
      "          222         sgd    sigmoid  0.958471   0.961329 0.958471  0.958415\n",
      "          333        adam       relu  0.985498   0.985702 0.985498  0.985506\n",
      "          333        adam       tanh  0.940672   0.941562 0.940672  0.940675\n",
      "          333        adam    sigmoid  0.954515   0.961730 0.954515  0.954274\n",
      "          333         sgd       relu  0.988134   0.988291 0.988134  0.988127\n",
      "          333         sgd       tanh  0.955175   0.957175 0.955175  0.955144\n",
      "          333         sgd    sigmoid  0.965722   0.969986 0.965722  0.965638\n",
      "\n",
      "🏆 MEJOR MODELO ENCONTRADO:\n",
      " Random State Optimizador Activación  Accuracy  Precision   Recall  F1-Score\n",
      "          333         sgd       relu  0.988134   0.988291 0.988134  0.988127\n",
      "\n",
      "📐 ARQUITECTURA DEL MEJOR MODELO:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_69\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_69\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_208 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_209 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_210 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_208 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_209 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_210 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">698</span> (2.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m698\u001b[0m (2.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">348</span> (1.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m348\u001b[0m (1.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">350</span> (1.37 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m350\u001b[0m (1.37 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================================================\n",
    "# Copia de los datos\n",
    "# =================================================\n",
    "data_rn_8 = data.copy()\n",
    "\n",
    "# 1️⃣ Eliminación de outliers (IQR)\n",
    "num_cols = data_rn_8.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_rn_8[num_cols].quantile(0.25)\n",
    "Q3 = data_rn_8[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((data_rn_8[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_rn_8[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "data_clean = data_rn_8[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_rn_8.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Reasignar X e y con los datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# =================================================\n",
    "# ⚙️ Función para entrenar y evaluar una red neuronal\n",
    "# =================================================\n",
    "def evaluar_red_neuronal(X_train, X_test, y_train, y_test, optimizer_name, activation_hidden, seed):\n",
    "    \"\"\"Entrena y evalúa una red neuronal con distintos optimizadores y activaciones, usando Early Stopping.\"\"\"\n",
    "    \n",
    "    # ============================\n",
    "    # Normalización de los datos\n",
    "    # ============================\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Seleccionar optimizador\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizador no soportado.\")\n",
    "\n",
    "    # Crear modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(16, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(8, activation=activation_hidden),\n",
    "        Dropout(0.3),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compilar modelo\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Calcular pesos de clase automáticamente\n",
    "    clases = np.unique(y_train)\n",
    "    pesos = compute_class_weight('balanced', classes=clases, y=y_train)\n",
    "    class_weights = dict(zip(clases, pesos))\n",
    "\n",
    "    # Entrenar el modelo con pesos\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop],\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Optimizador': optimizer_name,\n",
    "        'Activación': activation_hidden,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Modelo': model\n",
    "    }\n",
    "\n",
    "# =================================================\n",
    "# 🔁 Configuración de experimentos\n",
    "# =================================================\n",
    "random_states = [111, 222, 333]\n",
    "optimizadores = ['adam', 'sgd']\n",
    "activaciones = ['relu', 'tanh', 'sigmoid']\n",
    "resultados_totales = []\n",
    "\n",
    "# =================================================\n",
    "# 🚀 Pruebas con todas las combinaciones\n",
    "# =================================================\n",
    "for seed in random_states:\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧩 CASO DE PRUEBA (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    for opt in optimizadores:\n",
    "        for act in activaciones:\n",
    "            print(f\"🔹 Entrenando con Optimizador={opt}, Activación={act}...\")\n",
    "            resultados_totales.append(\n",
    "                evaluar_red_neuronal(X_train, X_test, y_train, y_test, opt, act, seed)\n",
    "            )\n",
    "\n",
    "# =================================================\n",
    "# 📊 Resultados finales\n",
    "# =================================================\n",
    "resultados_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'Modelo'} for r in resultados_totales])\n",
    "\n",
    "# Buscar el mejor modelo según F1-Score\n",
    "mejor_fila = max(resultados_totales, key=lambda x: x['F1-Score'])\n",
    "mejor_modelo = mejor_fila['Modelo']\n",
    "\n",
    "print(\"\\n📊 RESULTADOS DE TODOS LOS MODELOS:\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n🏆 MEJOR MODELO ENCONTRADO:\")\n",
    "print(pd.DataFrame([mejor_fila]).drop(columns=['Modelo']).to_string(index=False))\n",
    "\n",
    "print(\"\\n📐 ARQUITECTURA DEL MEJOR MODELO:\")\n",
    "mejor_modelo.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23ecb46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
