{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4340e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# diccionario para guardar todas las métricas\n",
    "metricas = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86804070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Height_m</th>\n",
       "      <th>Max_BPM</th>\n",
       "      <th>Avg_BPM</th>\n",
       "      <th>Resting_BPM</th>\n",
       "      <th>Session_Duration_hours</th>\n",
       "      <th>Calories_Burned</th>\n",
       "      <th>Workout_Type</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.14</td>\n",
       "      <td>101.05</td>\n",
       "      <td>1.95</td>\n",
       "      <td>171.17</td>\n",
       "      <td>130.81</td>\n",
       "      <td>68.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>959.43</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.17</td>\n",
       "      <td>41.63</td>\n",
       "      <td>1.78</td>\n",
       "      <td>167.33</td>\n",
       "      <td>158.46</td>\n",
       "      <td>63.95</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1424.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.07</td>\n",
       "      <td>63.81</td>\n",
       "      <td>1.78</td>\n",
       "      <td>187.86</td>\n",
       "      <td>137.11</td>\n",
       "      <td>60.93</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1766.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.30</td>\n",
       "      <td>59.77</td>\n",
       "      <td>1.78</td>\n",
       "      <td>183.83</td>\n",
       "      <td>120.32</td>\n",
       "      <td>60.01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1028.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.99</td>\n",
       "      <td>57.60</td>\n",
       "      <td>1.56</td>\n",
       "      <td>166.25</td>\n",
       "      <td>151.82</td>\n",
       "      <td>67.97</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1295.80</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Weight_kg  Height_m  Max_BPM  Avg_BPM  Resting_BPM  \\\n",
       "0  21.14     101.05      1.95   171.17   130.81        68.96   \n",
       "1  44.17      41.63      1.78   167.33   158.46        63.95   \n",
       "2  20.07      63.81      1.78   187.86   137.11        60.93   \n",
       "3  36.30      59.77      1.78   183.83   120.32        60.01   \n",
       "4  51.99      57.60      1.56   166.25   151.82        67.97   \n",
       "\n",
       "   Session_Duration_hours  Calories_Burned  Workout_Type  Gender_Female  \\\n",
       "0                    0.97           959.43             2            0.0   \n",
       "1                    1.48          1424.35             0            0.0   \n",
       "2                    1.70          1766.64             0            1.0   \n",
       "3                    0.85          1028.50             1            1.0   \n",
       "4                    1.66          1295.80             3            0.0   \n",
       "\n",
       "   Gender_Male  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. Carga del Conjunto de Datos ---\n",
    "data = pd.read_csv(\"../data/subset/clean_subset_lifestyledata_rows5200_seed5200.csv\")\n",
    "\n",
    "# --- 2. Codificación de Etiquetas (Label Encoding) ---\n",
    "label_encoder = LabelEncoder()\n",
    "# Se transforma la variable objetivo 'Workout_Type' a valores numéricos.\n",
    "data['Workout_Type'] = label_encoder.fit_transform(data['Workout_Type'])\n",
    "\n",
    "# --- 3. Codificación One-Hot (One-Hot Encoding) ---\n",
    "# Se define la lista de columnas categóricas nominales a transformar.\n",
    "nominal_cols = ['Gender']\n",
    "# sparse_output=False: Devuelve una matriz densa (array de NumPy) en lugar de una dispersa.\n",
    "# handle_unknown='ignore': Si aparece una categoría no vista durante la transformación, la ignora.\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# Esto crea nuevas columnas binarias para cada categoría.\n",
    "encoded = ohe.fit_transform(data[nominal_cols])\n",
    "# Se convierte la matriz resultante en un DataFrame con nombres de columna apropiados.\n",
    "encoded_df = pd.DataFrame(encoded, columns=ohe.get_feature_names_out(nominal_cols))\n",
    "\n",
    "# --- 4. Combinación de los Datos Procesados ---\n",
    "# Se elimina la columna original 'Gender' del DataFrame principal.\n",
    "# reset_index(drop=True) asegura que los índices se alineen correctamente para la concatenación.\n",
    "data = data.drop(columns=nominal_cols).reset_index(drop=True)\n",
    "encoded_df = encoded_df.reset_index(drop=True)\n",
    "\n",
    "# Se concatenan el DataFrame original y el nuevo DataFrame con las columnas codificadas.\n",
    "# axis=1 indica que la unión se realiza por columnas.\n",
    "data = pd.concat([data, encoded_df], axis=1)\n",
    "\n",
    "# --- 5. Visualización ---\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3d8ea8",
   "metadata": {},
   "source": [
    "# Árbol de Decisiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b928020a",
   "metadata": {},
   "source": [
    "#### 1. Árbol de Decisiones - CC:SI - ED:NO - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b46c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini\n",
      "Accuracy: 0.7327, Precision: 0.7412, Recall: 0.7327, F1-Score: 0.7350\n",
      "\n",
      "Modelo: Entropía\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "Modelo: Entropía Podado\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini\n",
      "Accuracy: 0.7452, Precision: 0.7431, Recall: 0.7452, F1-Score: 0.7438\n",
      "\n",
      "Modelo: Entropía\n",
      "Accuracy: 0.7875, Precision: 0.7968, Recall: 0.7875, F1-Score: 0.7892\n",
      "\n",
      "Modelo: Entropía Podado\n",
      "Accuracy: 0.7875, Precision: 0.7968, Recall: 0.7875, F1-Score: 0.7892\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini\n",
      "Accuracy: 0.7587, Precision: 0.7538, Recall: 0.7587, F1-Score: 0.7559\n",
      "\n",
      "Modelo: Entropía\n",
      "Accuracy: 0.7837, Precision: 0.8018, Recall: 0.7837, F1-Score: 0.7823\n",
      "\n",
      "Modelo: Entropía Podado\n",
      "Accuracy: 0.7837, Precision: 0.8018, Recall: 0.7837, F1-Score: 0.7823\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_1 = data.copy()\n",
    "X = data_tree_1.drop(\"Workout_Type\", axis=1)\n",
    "y = data_tree_1[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  # tres seeds diferentes\n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # Dividir datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Modelo 1: Árbol con Gini ---\n",
    "    modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=seed)\n",
    "    modelo_gini.fit(X_train, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía ---\n",
    "    modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "    modelo_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=seed)\n",
    "    modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "    # --- Calcular métricas ---\n",
    "    modelos = {\n",
    "        \"Gini\": y_pred_gini,\n",
    "        \"Entropía\": y_pred_entropy,\n",
    "        \"Entropía Podado\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        \n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66526514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fbf08",
   "metadata": {},
   "source": [
    "#### 2. Árbol de Decisiones - CC:SI - ED:NO - Outliers:NO - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c9b6a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Balanced\n",
      "Accuracy: 0.7327, Precision: 0.7412, Recall: 0.7327, F1-Score: 0.7350\n",
      "\n",
      "Modelo: Entropía_Balanced\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "Modelo: Entropía_Podado_Balanced\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Balanced\n",
      "Accuracy: 0.7375, Precision: 0.7338, Recall: 0.7375, F1-Score: 0.7348\n",
      "\n",
      "Modelo: Entropía_Balanced\n",
      "Accuracy: 0.7740, Precision: 0.7726, Recall: 0.7740, F1-Score: 0.7720\n",
      "\n",
      "Modelo: Entropía_Podado_Balanced\n",
      "Accuracy: 0.7740, Precision: 0.7726, Recall: 0.7740, F1-Score: 0.7720\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Balanced\n",
      "Accuracy: 0.7365, Precision: 0.7361, Recall: 0.7365, F1-Score: 0.7243\n",
      "\n",
      "Modelo: Entropía_Balanced\n",
      "Accuracy: 0.7846, Precision: 0.8026, Recall: 0.7846, F1-Score: 0.7833\n",
      "\n",
      "Modelo: Entropía_Podado_Balanced\n",
      "Accuracy: 0.7846, Precision: 0.8026, Recall: 0.7846, F1-Score: 0.7833\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_2 = data.copy()\n",
    "X = data_tree_2.drop(\"Workout_Type\", axis=1)\n",
    "y = data_tree_2[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras con class_weight='balanced'\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  # Tres seeds diferentes\n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # Dividir datos (80/20 estratificado)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Modelo 1: Árbol con Gini (class_weight='balanced') ---\n",
    "    modelo_gini = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_gini.fit(X_train, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía (class_weight='balanced') ---\n",
    "    modelo_entropy = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda (class_weight='balanced') ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=5, # Poda\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "    # --- Calcular métricas ---\n",
    "    modelos = {\n",
    "        \"Gini_Balanced\": y_pred_gini,\n",
    "        \"Entropía_Balanced\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Balanced\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas, usando zero_division=0 para un manejo robusto\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1df9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e13b9",
   "metadata": {},
   "source": [
    "#### 3. Árbol de Decisiones - CC:SI - ED:NO - Outliers:SI - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6028ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Clean\n",
      "Accuracy: 0.7399, Precision: 0.7479, Recall: 0.7399, F1-Score: 0.7403\n",
      "\n",
      "Modelo: Entropía_Clean\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "Modelo: Entropía_Podado_Clean\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Clean\n",
      "Accuracy: 0.7933, Precision: 0.8097, Recall: 0.7933, F1-Score: 0.7919\n",
      "\n",
      "Modelo: Entropía_Clean\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "Modelo: Entropía_Podado_Clean\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Clean\n",
      "Accuracy: 0.7923, Precision: 0.7979, Recall: 0.7923, F1-Score: 0.7928\n",
      "\n",
      "Modelo: Entropía_Clean\n",
      "Accuracy: 0.8200, Precision: 0.8163, Recall: 0.8200, F1-Score: 0.8177\n",
      "\n",
      "Modelo: Entropía_Podado_Clean\n",
      "Accuracy: 0.8180, Precision: 0.8149, Recall: 0.8180, F1-Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_3 = data.copy()\n",
    "\n",
    "# seleccionar solo las columnas numéricas\n",
    "num_cols = data_tree_3.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# calcular Q1, Q3 y el rango intercuartílico (IQR)\n",
    "Q1 = data_tree_3[num_cols].quantile(0.25)\n",
    "Q3 = data_tree_3[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# crear una máscara booleana que identifique las filas SIN outliers\n",
    "mask = ~((data_tree_3[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_tree_3[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# filtrar los datos limpios\n",
    "data_clean = data_tree_3[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_tree_3.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Separar X e y con datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Modelo 1: Árbol con Gini ---\n",
    "    modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=seed)\n",
    "    modelo_gini.fit(X_train, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía ---\n",
    "    modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "    modelo_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=seed)\n",
    "    modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "    # --- Calcular métricas ---\n",
    "    modelos = {\n",
    "        \"Gini_Clean\": y_pred_gini,\n",
    "        \"Entropía_Clean\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Clean\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513b99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fd4e1",
   "metadata": {},
   "source": [
    "#### 4. Árbol de Decisiones - CC:SI - ED:NO - Outliers:SI - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da4a2c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Balanced\n",
      "Accuracy: 0.7745, Precision: 0.7935, Recall: 0.7745, F1-Score: 0.7710\n",
      "\n",
      "Modelo: Entropía_Clean_Balanced\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Balanced\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Balanced\n",
      "Accuracy: 0.7933, Precision: 0.8097, Recall: 0.7933, F1-Score: 0.7919\n",
      "\n",
      "Modelo: Entropía_Clean_Balanced\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Balanced\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Balanced\n",
      "Accuracy: 0.7943, Precision: 0.7994, Recall: 0.7943, F1-Score: 0.7946\n",
      "\n",
      "Modelo: Entropía_Clean_Balanced\n",
      "Accuracy: 0.8190, Precision: 0.8156, Recall: 0.8190, F1-Score: 0.8168\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Balanced\n",
      "Accuracy: 0.8180, Precision: 0.8149, Recall: 0.8180, F1-Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_4 = data.copy()\n",
    "\n",
    "# seleccionar solo las columnas numéricas\n",
    "num_cols = data_tree_4.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# calcular Q1, Q3 y el rango intercuartílico (IQR)\n",
    "Q1 = data_tree_4[num_cols].quantile(0.25)\n",
    "Q3 = data_tree_4[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# crear una máscara booleana que identifique las filas SIN outliers\n",
    "mask = ~((data_tree_4[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_tree_4[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# filtrar los datos limpios\n",
    "data_clean = data_tree_4[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_tree_4.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Separar X e y con datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  #\n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Modelo 1: Árbol con Gini + Balanced ---\n",
    "    modelo_gini = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_gini.fit(X_train, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía + Balanced ---\n",
    "    modelo_entropy = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    modelo_entropy.fit(X_train, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda + Balanced ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=5, # Poda\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "    # --- Calcular métricas ---\n",
    "    modelos = {\n",
    "        \"Gini_Clean_Balanced\": y_pred_gini,\n",
    "        \"Entropía_Clean_Balanced\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Clean_Balanced\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c517ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb43b18",
   "metadata": {},
   "source": [
    "#### 5. Árbol de Decisiones - CC:SI - ED:SI - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d316eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Scaled\n",
      "Accuracy: 0.7327, Precision: 0.7412, Recall: 0.7327, F1-Score: 0.7350\n",
      "\n",
      "Modelo: Entropía_Scaled\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "Modelo: Entropía_Podado_Scaled\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Scaled\n",
      "Accuracy: 0.7452, Precision: 0.7431, Recall: 0.7452, F1-Score: 0.7438\n",
      "\n",
      "Modelo: Entropía_Scaled\n",
      "Accuracy: 0.7875, Precision: 0.7968, Recall: 0.7875, F1-Score: 0.7892\n",
      "\n",
      "Modelo: Entropía_Podado_Scaled\n",
      "Accuracy: 0.7875, Precision: 0.7968, Recall: 0.7875, F1-Score: 0.7892\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Scaled\n",
      "Accuracy: 0.7587, Precision: 0.7538, Recall: 0.7587, F1-Score: 0.7559\n",
      "\n",
      "Modelo: Entropía_Scaled\n",
      "Accuracy: 0.7837, Precision: 0.8018, Recall: 0.7837, F1-Score: 0.7823\n",
      "\n",
      "Modelo: Entropía_Podado_Scaled\n",
      "Accuracy: 0.7837, Precision: 0.8018, Recall: 0.7837, F1-Score: 0.7823\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_5 = data.copy()\n",
    "\n",
    "# Se definen las características (X) y la variable objetivo (y)\n",
    "X = data_tree_5.drop(\"Workout_Type\", axis=1)\n",
    "y = data_tree_5[\"Workout_Type\"]\n",
    "\n",
    "# Definir el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # 1. Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 2. Preprocesamiento: Escalado solo de columnas numéricas (excluyendo 'Gender')\n",
    "    numeric_cols = [col for col in X_train.columns if col not in ['Gender']] \n",
    "\n",
    "    # Hacer copias para el escalado\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    # Escalar\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    # 3. Entrenamiento y Predicción de Modelos\n",
    "    \n",
    "    # --- Modelo 1: Árbol con Gini ---\n",
    "    modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=seed)\n",
    "    modelo_gini.fit(X_train_scaled, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía ---\n",
    "    modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "    modelo_entropy.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=seed)\n",
    "    modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # 4. Calcular métricas\n",
    "    modelos = {\n",
    "        \"Gini_Scaled\": y_pred_gini,\n",
    "        \"Entropía_Scaled\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Scaled\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3e83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6489eb76",
   "metadata": {},
   "source": [
    "#### 6. Árbol de Decisiones - CC:SI - ED:SI - Outliers:NO - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86c9b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Scaled_Balanced\n",
      "Accuracy: 0.7327, Precision: 0.7412, Recall: 0.7327, F1-Score: 0.7350\n",
      "\n",
      "Modelo: Entropía_Scaled_Balanced\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "Modelo: Entropía_Podado_Scaled_Balanced\n",
      "Accuracy: 0.7779, Precision: 0.7923, Recall: 0.7779, F1-Score: 0.7804\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Scaled_Balanced\n",
      "Accuracy: 0.7375, Precision: 0.7338, Recall: 0.7375, F1-Score: 0.7348\n",
      "\n",
      "Modelo: Entropía_Scaled_Balanced\n",
      "Accuracy: 0.7740, Precision: 0.7726, Recall: 0.7740, F1-Score: 0.7720\n",
      "\n",
      "Modelo: Entropía_Podado_Scaled_Balanced\n",
      "Accuracy: 0.7740, Precision: 0.7726, Recall: 0.7740, F1-Score: 0.7720\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Scaled_Balanced\n",
      "Accuracy: 0.7365, Precision: 0.7361, Recall: 0.7365, F1-Score: 0.7243\n",
      "\n",
      "Modelo: Entropía_Scaled_Balanced\n",
      "Accuracy: 0.7846, Precision: 0.8026, Recall: 0.7846, F1-Score: 0.7833\n",
      "\n",
      "Modelo: Entropía_Podado_Scaled_Balanced\n",
      "Accuracy: 0.7846, Precision: 0.8026, Recall: 0.7846, F1-Score: 0.7833\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_6 = data.copy()\n",
    "\n",
    "# Se definen las características (X) y la variable objetivo (y)\n",
    "X = data_tree_6.drop(\"Workout_Type\", axis=1)\n",
    "y = data_tree_6[\"Workout_Type\"]\n",
    "\n",
    "# Definir el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # 1. Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 2. Preprocesamiento: Escalado solo de columnas numéricas\n",
    "    numeric_cols = [col for col in X_train.columns if col not in ['Gender']] # Se asume 'Gender' es la única no numérica relevante aquí\n",
    "\n",
    "    # Hacer copias para el escalado\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    # Escalar\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    # 3. Entrenamiento y Predicción de Modelos (con class_weight='balanced')\n",
    "\n",
    "    # --- Modelo 1: Árbol con Gini + Balanced ---\n",
    "    modelo_gini = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_gini.fit(X_train_scaled, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía + Balanced ---\n",
    "    modelo_entropy = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda + Balanced ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=5, # Poda\n",
    "        random_state=seed,\n",
    "        class_weight='balanced' \n",
    "    )\n",
    "    modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # 4. Calcular métricas\n",
    "    modelos = {\n",
    "        \"Gini_Scaled_Balanced\": y_pred_gini,\n",
    "        \"Entropía_Scaled_Balanced\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Scaled_Balanced\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d16c0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23e255",
   "metadata": {},
   "source": [
    "#### 7. Árbol de Decisiones - CC:SI - ED:SI - Outliers:SI - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f175ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled\n",
      "Accuracy: 0.7399, Precision: 0.7479, Recall: 0.7399, F1-Score: 0.7403\n",
      "\n",
      "Modelo: Entropía_Clean_Scaled\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Scaled\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled\n",
      "Accuracy: 0.7933, Precision: 0.8097, Recall: 0.7933, F1-Score: 0.7919\n",
      "\n",
      "Modelo: Entropía_Clean_Scaled\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Scaled\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled\n",
      "Accuracy: 0.7923, Precision: 0.7979, Recall: 0.7923, F1-Score: 0.7928\n",
      "\n",
      "Modelo: Entropía_Clean_Scaled\n",
      "Accuracy: 0.8200, Precision: 0.8163, Recall: 0.8200, F1-Score: 0.8177\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Scaled\n",
      "Accuracy: 0.8180, Precision: 0.8149, Recall: 0.8180, F1-Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_7 = data.copy()\n",
    "\n",
    "# seleccionar solo las columnas numéricas\n",
    "num_cols = data_tree_7.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# calcular Q1, Q3 y el rango intercuartílico (IQR)\n",
    "Q1 = data_tree_7[num_cols].quantile(0.25)\n",
    "Q3 = data_tree_7[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# crear una máscara booleana que identifique las filas SIN outliers\n",
    "mask = ~((data_tree_7[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_tree_7[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# filtrar los datos limpios\n",
    "data_clean = data_tree_7[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_tree_7.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# Separar X e y con datos limpios\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# Definir el escalador\n",
    "scaler = StandardScaler()\n",
    "# Definir columnas a escalar (asumiendo 'Gender' es la única no numérica en X)\n",
    "numeric_cols = [col for col in X.columns if col not in ['Gender']]\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  # Tres seeds diferentes\n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # 1. Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 2. Preprocesamiento: Escalado\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    # Ajustar y transformar solo las columnas numéricas\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "\n",
    "    # 3. Entrenamiento y Predicción de Modelos\n",
    "\n",
    "    # --- Modelo 1: Árbol con Gini ---\n",
    "    modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=seed)\n",
    "    modelo_gini.fit(X_train_scaled, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 2: Árbol con Entropía ---\n",
    "    modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "    modelo_entropy.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=seed)\n",
    "    modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # 4. Calcular métricas\n",
    "    modelos = {\n",
    "        \"Gini_Clean_Scaled\": y_pred_gini,\n",
    "        \"Entropía_Clean_Scaled\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Clean_Scaled\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52a3bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc5a64",
   "metadata": {},
   "source": [
    "#### 8. Árbol de Decisiones - CC:SI - ED:SI - Outliers:SI - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e235d4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 1 (random_state=111) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7745, Precision: 0.7935, Recall: 0.7745, F1-Score: 0.7710\n",
      "\n",
      "Modelo: Entropía_Clean_Scaled_Balanced\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Scaled_Balanced\n",
      "Accuracy: 0.8042, Precision: 0.8154, Recall: 0.8042, F1-Score: 0.8054\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 2 (random_state=222) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7933, Precision: 0.8097, Recall: 0.7933, F1-Score: 0.7919\n",
      "\n",
      "Modelo: Entropía_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7982, Precision: 0.8104, Recall: 0.7982, F1-Score: 0.8004\n",
      "\n",
      "=========== 🧠 CASO DE PRUEBA 3 (random_state=333) ===========\n",
      "\n",
      "Modelo: Gini_Clean_Scaled_Balanced\n",
      "Accuracy: 0.7943, Precision: 0.7994, Recall: 0.7943, F1-Score: 0.7946\n",
      "\n",
      "Modelo: Entropía_Clean_Scaled_Balanced\n",
      "Accuracy: 0.8190, Precision: 0.8156, Recall: 0.8190, F1-Score: 0.8168\n",
      "\n",
      "Modelo: Entropía_Podado_Clean_Scaled_Balanced\n",
      "Accuracy: 0.8180, Precision: 0.8149, Recall: 0.8180, F1-Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Datos base\n",
    "# ================================================================\n",
    "data_tree_8 = data.copy()\n",
    "\n",
    "# 1. Eliminar outliers (IQR)\n",
    "num_cols = data_tree_8.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = data_tree_8[num_cols].quantile(0.25)\n",
    "Q3 = data_tree_8[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "mask = ~((data_tree_8[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_tree_8[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "data_clean = data_tree_8[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_tree_8.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# 2. Separar X e y\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# Definir el escalador y las columnas numéricas (excluyendo 'Gender')\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = [col for col in X.columns if col not in ['Gender']]\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]  \n",
    "resultados = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=========== 🧠 CASO DE PRUEBA {i} (random_state={seed}) ===========\")\n",
    "\n",
    "    # 1. Dividir datos (80/20 estratificado con el seed actual)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 2. Aplicar Escalado (fit/transform en train, transform en test)\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "\n",
    "    # 3. Entrenamiento y Predicción de Modelos (con class_weight='balanced')\n",
    "\n",
    "    # --- Modelo 1: Gini + Balanced ---\n",
    "    modelo_gini = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    modelo_gini.fit(X_train_scaled, y_train)\n",
    "    y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 2: Entropía + Balanced ---\n",
    "    modelo_entropy = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    modelo_entropy.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "    # --- Modelo 3: Entropía con poda + Balanced ---\n",
    "    modelo_entropy_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=5, # Poda\n",
    "        random_state=seed,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "    y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # 4. Calcular métricas\n",
    "    modelos = {\n",
    "        \"Gini_Clean_Scaled_Balanced\": y_pred_gini,\n",
    "        \"Entropía_Clean_Scaled_Balanced\": y_pred_entropy,\n",
    "        \"Entropía_Podado_Clean_Scaled_Balanced\": y_pred_entropy_pruned\n",
    "    }\n",
    "\n",
    "    for nombre, y_pred in modelos.items():\n",
    "        # Calcular métricas (usando zero_division=0 por robustez)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Caso\": i,\n",
    "            \"Random State\": seed,\n",
    "            \"Modelo\": nombre,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"\\nModelo: {nombre}\")\n",
    "        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ae62506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a77f2",
   "metadata": {},
   "source": [
    "# K Vecinos Más Cercanos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec0da7f",
   "metadata": {},
   "source": [
    "#### 1. KNN - CC:SI - ED:NO - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8748d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111)\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7365\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.7913\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.7365, Precision: 0.7362, Recall: 0.7365, F1-Score: 0.7362\n",
      "-> Evaluación Manhattan (k=1):\n",
      "Accuracy: 0.7913, Precision: 0.7919, Recall: 0.7913, F1-Score: 0.7916\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222)\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7423\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.7981\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.7423, Precision: 0.7452, Recall: 0.7423, F1-Score: 0.7429\n",
      "-> Evaluación Manhattan (k=1):\n",
      "Accuracy: 0.7981, Precision: 0.8021, Recall: 0.7981, F1-Score: 0.7988\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333)\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7596\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.8115\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1):\n",
      "Accuracy: 0.7596, Precision: 0.7602, Recall: 0.7596, F1-Score: 0.7596\n",
      "-> Evaluación Manhattan (k=1):\n",
      "Accuracy: 0.8115, Precision: 0.8125, Recall: 0.8115, F1-Score: 0.8116\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Preparación de los datos\n",
    "# ================================================================\n",
    "data_knn_1 = data.copy()\n",
    "\n",
    "X = data_knn_1.drop(\"Workout_Type\", axis=1)\n",
    "y = data_knn_1[\"Workout_Type\"]\n",
    "\n",
    "# Definición de la función de evaluación\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo KNN.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Métrica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras\n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed})\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 🔎 Búsqueda de mejores K para el split actual\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"🔹 Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"🔹 Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # 🧠 Evaluación final con los K óptimos\n",
    "    print(\"\\n--- Evaluación Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluación Euclidiana (k={best_k_euclidean}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluación Manhattan (k={best_k_manhattan}):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d2508",
   "metadata": {},
   "source": [
    "#### 2. KNN - CC:SI - ED:NO - Outliers:NO - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "007f3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 1 (random_state=111) - Balanced\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7365\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.7913\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1, weights='distance'):\n",
      "Accuracy: 0.7365, Precision: 0.7362, Recall: 0.7365, F1-Score: 0.7362\n",
      "-> Evaluación Manhattan (k=1, weights='distance'):\n",
      "Accuracy: 0.7913, Precision: 0.7919, Recall: 0.7913, F1-Score: 0.7916\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 2 (random_state=222) - Balanced\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7423\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.7981\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1, weights='distance'):\n",
      "Accuracy: 0.7423, Precision: 0.7452, Recall: 0.7423, F1-Score: 0.7429\n",
      "-> Evaluación Manhattan (k=1, weights='distance'):\n",
      "Accuracy: 0.7981, Precision: 0.8021, Recall: 0.7981, F1-Score: 0.7988\n",
      "\n",
      "=================================================\n",
      "🧠 CASO DE PRUEBA 3 (random_state=333) - Balanced\n",
      "=================================================\n",
      "🔹 Mejor K (Euclidiana): 1 | Max Acc: 0.7596\n",
      "🔹 Mejor K (Manhattan): 1 | Max Acc: 0.8115\n",
      "\n",
      "--- Evaluación Final ---\n",
      "-> Evaluación Euclidiana (k=1, weights='distance'):\n",
      "Accuracy: 0.7596, Precision: 0.7602, Recall: 0.7596, F1-Score: 0.7596\n",
      "-> Evaluación Manhattan (k=1, weights='distance'):\n",
      "Accuracy: 0.8115, Precision: 0.8125, Recall: 0.8115, F1-Score: 0.8116\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 📂 Preparación de los datos\n",
    "# ================================================================\n",
    "data_knn_2 = data.copy()\n",
    "\n",
    "X = data_knn_2.drop(\"Workout_Type\", axis=1)\n",
    "y = data_knn_2[\"Workout_Type\"]\n",
    "\n",
    "# Definición de la función de evaluación\n",
    "def evaluar_modelo(X_train, X_test, y_train, y_test, metric_name, k_value, seed):\n",
    "    \"\"\"Entrena y evalúa un modelo KNN usando weights='distance'.\"\"\"\n",
    "    # weights='distance' prioriza los vecinos más cercanos, actuando como un balanceo ponderado.\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric_name, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Random State': seed,\n",
    "        'Métrica': metric_name,\n",
    "        'k': k_value,\n",
    "        'Weights': 'distance',\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# ================================================================\n",
    "# 🔁 Tres muestras \n",
    "# ================================================================\n",
    "random_states = [111, 222, 333]\n",
    "k_range = range(1, 100)\n",
    "resultados_finales = []\n",
    "\n",
    "for i, seed in enumerate(random_states, start=1):\n",
    "    print(f\"\\n=================================================\")\n",
    "    print(f\"🧠 CASO DE PRUEBA {i} (random_state={seed}) - Balanced\")\n",
    "    print(f\"=================================================\")\n",
    "\n",
    "    # División de datos (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # 🔎 Búsqueda de mejores K para el split actual (usando weights='distance')\n",
    "    accuracies_euclidean = []\n",
    "    accuracies_manhattan = []\n",
    "\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        for k in k_range:\n",
    "            # Importante: Usamos weights='distance' en la búsqueda de K\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights='distance')\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if metric == 'euclidean':\n",
    "                accuracies_euclidean.append(acc)\n",
    "            else:\n",
    "                accuracies_manhattan.append(acc)\n",
    "\n",
    "    # Encontrar el mejor K\n",
    "    best_k_euclidean = k_range[accuracies_euclidean.index(max(accuracies_euclidean))]\n",
    "    best_k_manhattan = k_range[accuracies_manhattan.index(max(accuracies_manhattan))]\n",
    "\n",
    "    print(f\"🔹 Mejor K (Euclidiana): {best_k_euclidean} | Max Acc: {max(accuracies_euclidean):.4f}\")\n",
    "    print(f\"🔹 Mejor K (Manhattan): {best_k_manhattan} | Max Acc: {max(accuracies_manhattan):.4f}\")\n",
    "\n",
    "    # 🧠 Evaluación final con los K óptimos\n",
    "    print(\"\\n--- Evaluación Final ---\")\n",
    "    \n",
    "    # Evaluar Euclidiana\n",
    "    print(f\"-> Evaluación Euclidiana (k={best_k_euclidean}, weights='distance'):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'euclidean', best_k_euclidean, seed)\n",
    "    )\n",
    "    \n",
    "    # Evaluar Manhattan\n",
    "    print(f\"-> Evaluación Manhattan (k={best_k_manhattan}, weights='distance'):\")\n",
    "    resultados_finales.append(\n",
    "        evaluar_modelo(X_train, X_test, y_train, y_test, 'manhattan', best_k_manhattan, seed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la gráfica de knn con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37249453",
   "metadata": {},
   "source": [
    "#### 3. KNN - CC:SI - ED:NO - Outliers:SI - Balanceo: NO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
