{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4340e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# diccionario para guardar todas las métricas\n",
    "metricas = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86804070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Height_m</th>\n",
       "      <th>Max_BPM</th>\n",
       "      <th>Avg_BPM</th>\n",
       "      <th>Resting_BPM</th>\n",
       "      <th>Session_Duration_hours</th>\n",
       "      <th>Calories_Burned</th>\n",
       "      <th>Workout_Type</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.14</td>\n",
       "      <td>101.05</td>\n",
       "      <td>1.95</td>\n",
       "      <td>171.17</td>\n",
       "      <td>130.81</td>\n",
       "      <td>68.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>959.43</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.17</td>\n",
       "      <td>41.63</td>\n",
       "      <td>1.78</td>\n",
       "      <td>167.33</td>\n",
       "      <td>158.46</td>\n",
       "      <td>63.95</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1424.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.07</td>\n",
       "      <td>63.81</td>\n",
       "      <td>1.78</td>\n",
       "      <td>187.86</td>\n",
       "      <td>137.11</td>\n",
       "      <td>60.93</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1766.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.30</td>\n",
       "      <td>59.77</td>\n",
       "      <td>1.78</td>\n",
       "      <td>183.83</td>\n",
       "      <td>120.32</td>\n",
       "      <td>60.01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1028.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.99</td>\n",
       "      <td>57.60</td>\n",
       "      <td>1.56</td>\n",
       "      <td>166.25</td>\n",
       "      <td>151.82</td>\n",
       "      <td>67.97</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1295.80</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Weight_kg  Height_m  Max_BPM  Avg_BPM  Resting_BPM  \\\n",
       "0  21.14     101.05      1.95   171.17   130.81        68.96   \n",
       "1  44.17      41.63      1.78   167.33   158.46        63.95   \n",
       "2  20.07      63.81      1.78   187.86   137.11        60.93   \n",
       "3  36.30      59.77      1.78   183.83   120.32        60.01   \n",
       "4  51.99      57.60      1.56   166.25   151.82        67.97   \n",
       "\n",
       "   Session_Duration_hours  Calories_Burned  Workout_Type  Gender_Female  \\\n",
       "0                    0.97           959.43             2            0.0   \n",
       "1                    1.48          1424.35             0            0.0   \n",
       "2                    1.70          1766.64             0            1.0   \n",
       "3                    0.85          1028.50             1            1.0   \n",
       "4                    1.66          1295.80             3            0.0   \n",
       "\n",
       "   Gender_Male  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. Carga del Conjunto de Datos ---\n",
    "data = pd.read_csv(\"../data/subset/clean_subset_lifestyledata_rows5200_seed5200.csv\")\n",
    "\n",
    "# --- 2. Codificación de Etiquetas (Label Encoding) ---\n",
    "label_encoder = LabelEncoder()\n",
    "# Se transforma la variable objetivo 'Workout_Type' a valores numéricos.\n",
    "data['Workout_Type'] = label_encoder.fit_transform(data['Workout_Type'])\n",
    "\n",
    "# --- 3. Codificación One-Hot (One-Hot Encoding) ---\n",
    "# Se define la lista de columnas categóricas nominales a transformar.\n",
    "nominal_cols = ['Gender']\n",
    "# sparse_output=False: Devuelve una matriz densa (array de NumPy) en lugar de una dispersa.\n",
    "# handle_unknown='ignore': Si aparece una categoría no vista durante la transformación, la ignora.\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# Esto crea nuevas columnas binarias para cada categoría.\n",
    "encoded = ohe.fit_transform(data[nominal_cols])\n",
    "# Se convierte la matriz resultante en un DataFrame con nombres de columna apropiados.\n",
    "encoded_df = pd.DataFrame(encoded, columns=ohe.get_feature_names_out(nominal_cols))\n",
    "\n",
    "# --- 4. Combinación de los Datos Procesados ---\n",
    "# Se elimina la columna original 'Gender' del DataFrame principal.\n",
    "# reset_index(drop=True) asegura que los índices se alineen correctamente para la concatenación.\n",
    "data = data.drop(columns=nominal_cols).reset_index(drop=True)\n",
    "encoded_df = encoded_df.reset_index(drop=True)\n",
    "\n",
    "# Se concatenan el DataFrame original y el nuevo DataFrame con las columnas codificadas.\n",
    "# axis=1 indica que la unión se realiza por columnas.\n",
    "data = pd.concat([data, encoded_df], axis=1)\n",
    "\n",
    "# --- 5. Visualización ---\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b928020a",
   "metadata": {},
   "source": [
    "#### 1. Árbol de Decisiones - CC:SI - ED:NO - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5b46c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas del Modelo Gini:\n",
      "Accuracy: 0.7356, Precision: 0.7395, Recall: 0.7356, F1-Score: 0.7361\n",
      "\n",
      "Métricas del Modelo Entropía:\n",
      "Accuracy: 0.7750, Precision: 0.7953, Recall: 0.7750, F1-Score: 0.7820\n",
      "\n",
      "Métricas del Modelo Entropía Podado:\n",
      "Accuracy: 0.7750, Precision: 0.7953, Recall: 0.7750, F1-Score: 0.7820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# datos a utilizar\n",
    "data_model_1 = data.copy()\n",
    "\n",
    "# Se definen las características (X) y la variable objetivo (y)\n",
    "# X contiene todas las columnas EXCEPTO 'Workout_Type'.\n",
    "X = data_model_1.drop(\"Workout_Type\", axis=1)\n",
    "\n",
    "# y contiene ÚNICAMENTE la columna 'Workout_Type'.\n",
    "y = data_model_1[\"Workout_Type\"]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5200, stratify=y)\n",
    "\n",
    "# Se crea un árbol con el criterio de impureza de Gini y una profundidad máxima de 5\n",
    "modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=5200)\n",
    "# Se entrena el modelo con los datos de entrenamiento\n",
    "modelo_gini.fit(X_train, y_train)\n",
    "\n",
    "# Se crea un árbol con el criterio de Entropía\n",
    "modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=5200)\n",
    "# Se entrena el modelo\n",
    "modelo_entropy.fit(X_train, y_train)\n",
    "\n",
    "# Se crea un árbol con Entropía y una condición de poda adicional\n",
    "modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=5200)\n",
    "# Se entrena el modelo\n",
    "modelo_entropy_pruned.fit(X_train, y_train)\n",
    "\n",
    "# Predecir con el modelo Gini\n",
    "y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "# Predecir con el modelo de Entropía\n",
    "y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "# Predecir con el modelo de Entropía podado\n",
    "y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "# Métricas para el modelo Gini (accuracy, precision, recall, f1-score)\n",
    "accuracy_gini = accuracy_score(y_test, y_pred_gini)\n",
    "precision_gini = precision_score(y_test, y_pred_gini, average='weighted')\n",
    "recall_gini = recall_score(y_test, y_pred_gini, average='weighted')\n",
    "f1_gini = f1_score(y_test, y_pred_gini, average='weighted')\n",
    "\n",
    "# Métricas para el modelo de Entropía (accuracy, precision, recall, f1-score)\n",
    "accuracy_entropy = accuracy_score(y_test, y_pred_entropy)\n",
    "precision_entropy = precision_score(y_test, y_pred_entropy, average='weighted')\n",
    "recall_entropy = recall_score(y_test, y_pred_entropy, average='weighted')\n",
    "f1_entropy = f1_score(y_test, y_pred_entropy, average='weighted')\n",
    "\n",
    "# Métricas para el modelo de Entropía podado (accuracy, precision, recall, f1-score)\n",
    "accuracy_entropy_pruned = accuracy_score(y_test, y_pred_entropy_pruned)\n",
    "precision_entropy_pruned = precision_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "recall_entropy_pruned = recall_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "f1_entropy_pruned = f1_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "\n",
    "# Mostrar las métricas\n",
    "print(\"Métricas del Modelo Gini:\")\n",
    "print(f\"Accuracy: {accuracy_gini:.4f}, Precision: {precision_gini:.4f}, Recall: {recall_gini:.4f}, F1-Score: {f1_gini:.4f}\\n\")\n",
    "print(\"Métricas del Modelo Entropía:\")\n",
    "print(f\"Accuracy: {accuracy_entropy:.4f}, Precision: {precision_entropy:.4f}, Recall: {recall_entropy:.4f}, F1-Score: {f1_entropy:.4f}\\n\")\n",
    "print(\"Métricas del Modelo Entropía Podado:\")\n",
    "print(f\"Accuracy: {accuracy_entropy_pruned:.4f}, Precision: {precision_entropy_pruned:.4f}, Recall: {recall_entropy_pruned:.4f}, F1-Score: {f1_entropy_pruned:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66526514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508aa515",
   "metadata": {},
   "source": [
    "## Conclusión:\n",
    "\n",
    "Se evaluaron tres modelos de árbol de decisión: uno con Gini, otro con entropía y un tercero con entropía podado. Los dos modelos con entropía obtuvieron mejores resultados, con una precisión cercana al 78% y un F1-score de 0.78. Se seleccionó el modelo con entropía podado por ofrecer el mismo nivel de exactitud que el no podado, pero con menor complejidad y mejor capacidad de generalización, logrando un equilibrio óptimo entre rendimiento y simplicidad para predecir el tipo de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fbf08",
   "metadata": {},
   "source": [
    "#### 2. Árbol de Decisiones - CC:SI - ED:NO - Outliers:NO - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c9b6a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas del Modelo Gini:\n",
      "Accuracy: 0.7337, Precision: 0.7392, Recall: 0.7337, F1-Score: 0.7348\n",
      "\n",
      "Métricas del Modelo Entropía:\n",
      "Accuracy: 0.7750, Precision: 0.7953, Recall: 0.7750, F1-Score: 0.7820\n",
      "\n",
      "Métricas del Modelo Entropía Podado:\n",
      "Accuracy: 0.7750, Precision: 0.7953, Recall: 0.7750, F1-Score: 0.7820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# datos a utilizar\n",
    "data_model_2 = data.copy()\n",
    "\n",
    "# Se definen las características (X) y la variable objetivo (y)\n",
    "# X contiene todas las columnas EXCEPTO 'Workout_Type'.\n",
    "X = data_model_2.drop(\"Workout_Type\", axis=1)\n",
    "\n",
    "# y contiene ÚNICAMENTE la columna 'Workout_Type'.\n",
    "y = data_model_2[\"Workout_Type\"]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5200, stratify=y)\n",
    "\n",
    "# Se crea un árbol con el criterio de impureza de Gini y una profundidad máxima de 5\n",
    "modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=5200, class_weight='balanced')\n",
    "# Se entrena el modelo con los datos de entrenamiento\n",
    "modelo_gini.fit(X_train, y_train)\n",
    "\n",
    "# Se crea un árbol con el criterio de Entropía\n",
    "modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=5200, class_weight='balanced')\n",
    "# Se entrena el modelo\n",
    "modelo_entropy.fit(X_train, y_train)\n",
    "\n",
    "# Se crea un árbol con Entropía y una condición de poda adicional\n",
    "modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=5200, class_weight='balanced')\n",
    "# Se entrena el modelo\n",
    "modelo_entropy_pruned.fit(X_train, y_train)\n",
    "    \n",
    "# Predecir con el modelo Gini\n",
    "y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "# Predecir con el modelo de Entropía\n",
    "y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "\n",
    "# Predecir con el modelo de Entropía podado\n",
    "y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "# Métricas para el modelo Gini (accuracy, precision, recall, f1-score)\n",
    "accuracy_gini = accuracy_score(y_test, y_pred_gini)\n",
    "precision_gini = precision_score(y_test, y_pred_gini, average='weighted')\n",
    "recall_gini = recall_score(y_test, y_pred_gini, average='weighted')\n",
    "f1_gini = f1_score(y_test, y_pred_gini, average='weighted')\n",
    "\n",
    "# Métricas para el modelo de Entropía (accuracy, precision, recall, f1-score)\n",
    "accuracy_entropy = accuracy_score(y_test, y_pred_entropy)\n",
    "precision_entropy = precision_score(y_test, y_pred_entropy, average='weighted')\n",
    "recall_entropy = recall_score(y_test, y_pred_entropy, average='weighted')\n",
    "f1_entropy = f1_score(y_test, y_pred_entropy, average='weighted')\n",
    "\n",
    "# Métricas para el modelo de Entropía podado (accuracy, precision, recall, f1-score)\n",
    "accuracy_entropy_pruned = accuracy_score(y_test, y_pred_entropy_pruned)\n",
    "precision_entropy_pruned = precision_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "recall_entropy_pruned = recall_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "f1_entropy_pruned = f1_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "\n",
    "# Mostrar las métricas\n",
    "print(\"Métricas del Modelo Gini:\")\n",
    "print(f\"Accuracy: {accuracy_gini:.4f}, Precision: {precision_gini:.4f}, Recall: {recall_gini:.4f}, F1-Score: {f1_gini:.4f}\\n\")\n",
    "print(\"Métricas del Modelo Entropía:\")\n",
    "print(f\"Accuracy: {accuracy_entropy:.4f}, Precision: {precision_entropy:.4f}, Recall: {recall_entropy:.4f}, F1-Score: {f1_entropy:.4f}\\n\")\n",
    "print(\"Métricas del Modelo Entropía Podado:\")\n",
    "print(f\"Accuracy: {accuracy_entropy_pruned:.4f}, Precision: {precision_entropy_pruned:.4f}, Recall: {recall_entropy_pruned:.4f}, F1-Score: {f1_entropy_pruned:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b1df9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb6cc00",
   "metadata": {},
   "source": [
    "## Conclusión:\n",
    "\n",
    "A pesar de aplicar el balanceo de clases mediante el parámetro class_weight='balanced', los resultados obtenidos fueron muy similares a los del modelo sin balancear. Esto indica que el conjunto de datos ya presentaba una distribución de clases relativamente equilibrada, por lo que el ajuste automático de pesos no generó cambios significativos en las métricas de desempeño. En consecuencia, el modelo mantiene su capacidad predictiva sin necesidad de un rebalanceo adicional, conservando una precisión y un F1-score estables alrededor del 0.78 en el modelo de entropía con podado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e13b9",
   "metadata": {},
   "source": [
    "#### 3. Árbol de Decisiones - CC:SI - ED:NO - Outliers:SI - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6028ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "Métricas del Modelo Gini:\n",
      "Accuracy: 0.7883, Precision: 0.8018, Recall: 0.7883, F1-Score: 0.7908\n",
      "\n",
      "Métricas del Modelo Entropía:\n",
      "Accuracy: 0.7943, Precision: 0.8060, Recall: 0.7943, F1-Score: 0.7945\n",
      "\n",
      "Métricas del Modelo Entropía Podado:\n",
      "Accuracy: 0.7943, Precision: 0.8060, Recall: 0.7943, F1-Score: 0.7945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# datos a utilizar\n",
    "data_model_3 = data.copy()\n",
    "\n",
    "# ==========================\n",
    "# Eliminar outliers (IQR)\n",
    "# ==========================\n",
    "\n",
    "# seleccionar solo las columnas numéricas\n",
    "num_cols = data_model_3.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# calcular Q1, Q3 y el rango intercuartílico (IQR)\n",
    "Q1 = data_model_3[num_cols].quantile(0.25)\n",
    "Q3 = data_model_3[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# crear una máscara booleana que identifique las filas SIN outliers\n",
    "mask = ~((data_model_3[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_model_3[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# filtrar los datos limpios\n",
    "data_clean = data_model_3[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_model_3.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# ==========================\n",
    "# Separar X e y\n",
    "# ==========================\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=5200, stratify=y\n",
    ")\n",
    "\n",
    "# Árbol con criterio Gini\n",
    "modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=5200)\n",
    "modelo_gini.fit(X_train, y_train)\n",
    "\n",
    "# Árbol con criterio Entropía\n",
    "modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=5200)\n",
    "modelo_entropy.fit(X_train, y_train)\n",
    "\n",
    "# Árbol con Entropía y poda\n",
    "modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=5200)\n",
    "modelo_entropy_pruned.fit(X_train, y_train)\n",
    "\n",
    "# predicciones\n",
    "y_pred_gini = modelo_gini.predict(X_test)\n",
    "y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "# métricas\n",
    "accuracy_gini = accuracy_score(y_test, y_pred_gini)\n",
    "precision_gini = precision_score(y_test, y_pred_gini, average='weighted')\n",
    "recall_gini = recall_score(y_test, y_pred_gini, average='weighted')\n",
    "f1_gini = f1_score(y_test, y_pred_gini, average='weighted')\n",
    "\n",
    "accuracy_entropy = accuracy_score(y_test, y_pred_entropy)\n",
    "precision_entropy = precision_score(y_test, y_pred_entropy, average='weighted')\n",
    "recall_entropy = recall_score(y_test, y_pred_entropy, average='weighted')\n",
    "f1_entropy = f1_score(y_test, y_pred_entropy, average='weighted')\n",
    "\n",
    "accuracy_entropy_pruned = accuracy_score(y_test, y_pred_entropy_pruned)\n",
    "precision_entropy_pruned = precision_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "recall_entropy_pruned = recall_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "f1_entropy_pruned = f1_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "\n",
    "# ==========================\n",
    "# Mostrar resultados\n",
    "# ==========================\n",
    "print(\"\\nMétricas del Modelo Gini:\")\n",
    "print(f\"Accuracy: {accuracy_gini:.4f}, Precision: {precision_gini:.4f}, Recall: {recall_gini:.4f}, F1-Score: {f1_gini:.4f}\\n\")\n",
    "\n",
    "print(\"Métricas del Modelo Entropía:\")\n",
    "print(f\"Accuracy: {accuracy_entropy:.4f}, Precision: {precision_entropy:.4f}, Recall: {recall_entropy:.4f}, F1-Score: {f1_entropy:.4f}\\n\")\n",
    "\n",
    "print(\"Métricas del Modelo Entropía Podado:\")\n",
    "print(f\"Accuracy: {accuracy_entropy_pruned:.4f}, Precision: {precision_entropy_pruned:.4f}, Recall: {recall_entropy_pruned:.4f}, F1-Score: {f1_entropy_pruned:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "513b99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf2e0a",
   "metadata": {},
   "source": [
    "## Conclusión:\n",
    "\n",
    "La eliminación de outliers mejoró las métricas del modelo, indicando que los datos atípicos afectaban su desempeño. Al limpiar el conjunto de datos, los árboles de decisión lograron una clasificación más precisa y estable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fd4e1",
   "metadata": {},
   "source": [
    "#### 4. Árbol de Decisiones - CC:SI - ED:NO - Outliers:SI - Balanceo: SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da4a2c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: (5200, 11)\n",
      "Tamaño sin outliers: (5055, 11)\n",
      "\n",
      "Métricas del Modelo Gini:\n",
      "Accuracy: 0.7883, Precision: 0.8018, Recall: 0.7883, F1-Score: 0.7908\n",
      "\n",
      "Métricas del Modelo Entropía:\n",
      "Accuracy: 0.8002, Precision: 0.8114, Recall: 0.8002, F1-Score: 0.8018\n",
      "\n",
      "Métricas del Modelo Entropía Podado:\n",
      "Accuracy: 0.8002, Precision: 0.8114, Recall: 0.8002, F1-Score: 0.8018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# datos a utilizar\n",
    "data_model_4 = data.copy()\n",
    "\n",
    "# ==========================\n",
    "# Eliminar outliers (IQR)\n",
    "# ==========================\n",
    "\n",
    "# seleccionar solo las columnas numéricas\n",
    "num_cols = data_model_4.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# calcular Q1, Q3 y el rango intercuartílico (IQR)\n",
    "Q1 = data_model_4[num_cols].quantile(0.25)\n",
    "Q3 = data_model_4[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# crear una máscara booleana que identifique las filas SIN outliers\n",
    "mask = ~((data_model_4[num_cols] < (Q1 - 1.5 * IQR)) |\n",
    "         (data_model_4[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# filtrar los datos limpios\n",
    "data_clean = data_model_4[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño original:\", data_model_4.shape)\n",
    "print(\"Tamaño sin outliers:\", data_clean.shape)\n",
    "\n",
    "# ==========================\n",
    "# Separar X e y\n",
    "# ==========================\n",
    "X = data_clean.drop(\"Workout_Type\", axis=1)\n",
    "y = data_clean[\"Workout_Type\"]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=5200, stratify=y\n",
    ")\n",
    "\n",
    "# Árbol con criterio Gini\n",
    "modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=5200, class_weight='balanced')\n",
    "modelo_gini.fit(X_train, y_train)\n",
    "\n",
    "# Árbol con criterio Entropía\n",
    "modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=5200, class_weight='balanced')\n",
    "modelo_entropy.fit(X_train, y_train)\n",
    "\n",
    "# Árbol con Entropía y poda\n",
    "modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=5200, class_weight='balanced')\n",
    "modelo_entropy_pruned.fit(X_train, y_train)\n",
    "\n",
    "# predicciones\n",
    "y_pred_gini = modelo_gini.predict(X_test)\n",
    "y_pred_entropy = modelo_entropy.predict(X_test)\n",
    "y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test)\n",
    "\n",
    "# métricas\n",
    "accuracy_gini = accuracy_score(y_test, y_pred_gini)\n",
    "precision_gini = precision_score(y_test, y_pred_gini, average='weighted')\n",
    "recall_gini = recall_score(y_test, y_pred_gini, average='weighted')\n",
    "f1_gini = f1_score(y_test, y_pred_gini, average='weighted')\n",
    "\n",
    "accuracy_entropy = accuracy_score(y_test, y_pred_entropy)\n",
    "precision_entropy = precision_score(y_test, y_pred_entropy, average='weighted')\n",
    "recall_entropy = recall_score(y_test, y_pred_entropy, average='weighted')\n",
    "f1_entropy = f1_score(y_test, y_pred_entropy, average='weighted')\n",
    "\n",
    "accuracy_entropy_pruned = accuracy_score(y_test, y_pred_entropy_pruned)\n",
    "precision_entropy_pruned = precision_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "recall_entropy_pruned = recall_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "f1_entropy_pruned = f1_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "\n",
    "# ==========================\n",
    "# Mostrar resultados\n",
    "# ==========================\n",
    "print(\"\\nMétricas del Modelo Gini:\")\n",
    "print(f\"Accuracy: {accuracy_gini:.4f}, Precision: {precision_gini:.4f}, Recall: {recall_gini:.4f}, F1-Score: {f1_gini:.4f}\\n\")\n",
    "\n",
    "print(\"Métricas del Modelo Entropía:\")\n",
    "print(f\"Accuracy: {accuracy_entropy:.4f}, Precision: {precision_entropy:.4f}, Recall: {recall_entropy:.4f}, F1-Score: {f1_entropy:.4f}\\n\")\n",
    "\n",
    "print(\"Métricas del Modelo Entropía Podado:\")\n",
    "print(f\"Accuracy: {accuracy_entropy_pruned:.4f}, Precision: {precision_entropy_pruned:.4f}, Recall: {recall_entropy_pruned:.4f}, F1-Score: {f1_entropy_pruned:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c517ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf1ff89",
   "metadata": {},
   "source": [
    "## Conclusión:\n",
    "\n",
    "Ahora, con el balanceo de clases y la eliminación de outliers, el modelo mostró una mejora notable en sus métricas.\n",
    "Por ejemplo, el modelo con entropía alcanzó un accuracy de 0.8002, precisión de 0.8114, recall de 0.8002 y un F1-Score de 0.8018, superando los valores anteriores.\n",
    "Esto demuestra que al equilibrar las clases y eliminar datos atípicos, el árbol de decisión logra una clasificación más precisa y estable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb43b18",
   "metadata": {},
   "source": [
    "#### 5. Árbol de Decisiones - CC:SI - ED:SI - Outliers:NO - Balanceo: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d316eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas del Modelo Gini:\n",
      "Accuracy: 0.7356, Precision: 0.7395, Recall: 0.7356, F1-Score: 0.7361\n",
      "\n",
      "Métricas del Modelo Entropía:\n",
      "Accuracy: 0.7750, Precision: 0.7953, Recall: 0.7750, F1-Score: 0.7820\n",
      "\n",
      "Métricas del Modelo Entropía Podado:\n",
      "Accuracy: 0.7750, Precision: 0.7953, Recall: 0.7750, F1-Score: 0.7820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# datos a utilizar\n",
    "data_model_5 = data.copy()\n",
    "\n",
    "# Se definen las características (X) y la variable objetivo (y)\n",
    "# X contiene todas las columnas EXCEPTO 'Workout_Type'.\n",
    "X = data_model_5.drop(\"Workout_Type\", axis=1)\n",
    "\n",
    "# y contiene ÚNICAMENTE la columna 'Workout_Type'.\n",
    "y = data_model_5[\"Workout_Type\"]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5200, stratify=y)\n",
    "\n",
    "# 🔹 Escalado de las características (excepto 'Gender' y 'Workout_Type')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Seleccionar columnas numéricas que no sean categóricas\n",
    "numeric_cols = [col for col in X_train.columns if col not in ['Gender', 'Workout_Type']]\n",
    "\n",
    "# Hacer copias para no perder las columnas categóricas\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Escalar solo las columnas numéricas\n",
    "X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# Se crea un árbol con el criterio de impureza de Gini y una profundidad máxima de 5\n",
    "modelo_gini = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=5200)\n",
    "# Se entrena el modelo con los datos de entrenamiento\n",
    "modelo_gini.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Se crea un árbol con el criterio de Entropía\n",
    "modelo_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=5200)\n",
    "# Se entrena el modelo\n",
    "modelo_entropy.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Se crea un árbol con Entropía y una condición de poda adicional\n",
    "modelo_entropy_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=5200)\n",
    "# Se entrena el modelo\n",
    "modelo_entropy_pruned.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predecir con el modelo Gini\n",
    "y_pred_gini = modelo_gini.predict(X_test_scaled)\n",
    "\n",
    "# Predecir con el modelo de Entropía\n",
    "y_pred_entropy = modelo_entropy.predict(X_test_scaled)\n",
    "\n",
    "# Predecir con el modelo de Entropía podado\n",
    "y_pred_entropy_pruned = modelo_entropy_pruned.predict(X_test_scaled)\n",
    "\n",
    "# Métricas para el modelo Gini (accuracy, precision, recall, f1-score)\n",
    "accuracy_gini = accuracy_score(y_test, y_pred_gini)\n",
    "precision_gini = precision_score(y_test, y_pred_gini, average='weighted')\n",
    "recall_gini = recall_score(y_test, y_pred_gini, average='weighted')\n",
    "f1_gini = f1_score(y_test, y_pred_gini, average='weighted')\n",
    "\n",
    "# Métricas para el modelo de Entropía (accuracy, precision, recall, f1-score)\n",
    "accuracy_entropy = accuracy_score(y_test, y_pred_entropy)\n",
    "precision_entropy = precision_score(y_test, y_pred_entropy, average='weighted')\n",
    "recall_entropy = recall_score(y_test, y_pred_entropy, average='weighted')\n",
    "f1_entropy = f1_score(y_test, y_pred_entropy, average='weighted')\n",
    "\n",
    "# Métricas para el modelo de Entropía podado (accuracy, precision, recall, f1-score)\n",
    "accuracy_entropy_pruned = accuracy_score(y_test, y_pred_entropy_pruned)\n",
    "precision_entropy_pruned = precision_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "recall_entropy_pruned = recall_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "f1_entropy_pruned = f1_score(y_test, y_pred_entropy_pruned, average='weighted')\n",
    "\n",
    "# Mostrar las métricas\n",
    "print(\"Métricas del Modelo Gini:\")\n",
    "print(f\"Accuracy: {accuracy_gini:.4f}, Precision: {precision_gini:.4f}, Recall: {recall_gini:.4f}, F1-Score: {f1_gini:.4f}\\n\")\n",
    "print(\"Métricas del Modelo Entropía:\")\n",
    "print(f\"Accuracy: {accuracy_entropy:.4f}, Precision: {precision_entropy:.4f}, Recall: {recall_entropy:.4f}, F1-Score: {f1_entropy:.4f}\\n\")\n",
    "print(\"Métricas del Modelo Entropía Podado:\")\n",
    "print(f\"Accuracy: {accuracy_entropy_pruned:.4f}, Precision: {precision_entropy_pruned:.4f}, Recall: {recall_entropy_pruned:.4f}, F1-Score: {f1_entropy_pruned:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO guardar métricas en el diccionario\n",
    "# TODO hacer la importancia de variables y gráficar el arbol gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819eb1f",
   "metadata": {},
   "source": [
    "## Conclusión:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
